{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks applications to fraud detection\n",
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are one of the most relevant learning methods currently available, and their widespread application is understood by theoretical robustness, flexible architecture design, and strong expected predictive accuracy.\n",
    "<br>\n",
    "<br>\n",
    "The main objective of this study is to develop a neural network application to fraud detection, and mainly to explore different strategies for hyper-parameter tuning, since this learning method requires a proper definition of a large set of parameters in order to result in a competitive performance.\n",
    "<br>\n",
    "<br>\n",
    "Previously to empirical inquirements, it is necessary to review all details concerning neural networks structure, fitting, and specification, which will base experiments design and tests implementation. So, the theoretical presentation of this notebook will be followed by an empirical stage of tests in which hyper-parameters will be defined to improve neural networks predictive accuracy, after which the best specification obtained should be opposed to alternative learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition and structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks consist on a very intuitive learning method, as they mimic the functioning of the human brain. *Neurons* are represented as units processing outputs from other neurons and then producing inputs for subsequent neurons, and since this processment is performed on the basis of linear combination of inputs, the structure of neural networks is translated essentially in *linear algebra*.\n",
    "<br>\n",
    "<br>\n",
    "A neural network generally is constructed upon multiple distinct and connected neurons, and the basic aspect of the architecture relating them, whether or not a feedforward mechanism as above is at hand, is the existence of **layers of neurons**. A *fully connected* layer has its neurons connected to all neurons from the predecessor and the successor layers. However, neurons from a given layer are not connected to one another. There is three types of layers: i) the **input layer** reflects the inputs $x \\in \\mathbb{R}^p$ to the model, and each neuron consists on a given variable $x_j \\in \\mathbb{R}$; ii) a **hidden layer**, which may be unique or not, has its neurons processing the outputs from the previous layer displaying their own outputs as inputs for neurons in the following layer; iii) finally, the **output layer** reflects the outputs $y \\in \\mathbb{R}^m$ from the model.\n",
    "<br>\n",
    "<br>\n",
    "This simple structure is complexified by ingenious learning algorithms and developed through an endless collection of possible architectures for the models. It may be that it is the combination of an intuitive model with sophisticated ways of designing and estimating it the reason why neural networks perform so well executing complex learning tasks. Mathematically speaking, this empirical fact is sustained by the *universal approximation theorem*, under which any real valued function $f: \\mathbb{R}^p \\rightarrow \\mathbb{R}^m$ can be approximated with an arbitrary level of closeness by neural networks.\n",
    "<br>\n",
    "<br>\n",
    "The **feedforward neural network** described above can be expressed using linear algebra as follows. Considering a neural network with $L - 1$ hidden layers of neurons, besides an input layer with $p$ inputs and an output layer with $m$ outputs, summing up to a model with $L + 1$ layers, the $j$-th **neuron** of layer $l$, with $l \\in \\{0, 1, 2, ..., L\\}$, is given by:\n",
    "\\begin{equation}\n",
    "a_j^l = \\sigma(z_j^l) = \\sigma\\Big(\\sum_{k=1}^{J_{l-1}} w_{jk}^l a_k^{l-1} + b_j^l\\Big)\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $\\sigma(.)$ is the **activation function** which processes the **weighted inputs** $z_j^l$, $k$ refers to neurons in the layer previous to $l$, $J_{l-1}$ is the number of such neurons, $w_{jk}^l$ is the **weight** that connects neuron $k$ of layer $l - 1$ to neuron $j$ of layer $l$, $b_j^l$ is the **bias term**. In matrix notation:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "a^l = \\sigma(z^l) = \\sigma(w^l a^{l-1} + b^l)\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $w^l$ is a $J_lxJ_{l-1}$ matrix of weights, $a^{l-1}$ is a $J_{l-1}x1$ vector of activations from the previouls layer, and $b^l$ is a $J_lx1$ vector of biases.\n",
    "<br>\n",
    "<br>\n",
    "Considering the input layer given by $l = 0$, then $j \\in \\{1, 2, ..., p\\}$ and $a_j^0 = x_j$. The output layer, in its turn, has $J_l = m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fully connected feedforward neural network**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://lh3.googleusercontent.com/iYf1ZKUQiZsOnA7TdXObAYTdhZEgOtKoY5Ljth4lzeCOaL2pR-qwiZhSR4LE7IfEO6j_6VvTnWJ_txeOvTWU9rtg_q-a6dZy0AUWEKxKS1ig8khwOfy8Gx3qzykmtERuHd7NDL-UoBf6wy_0i5izRmNPOg1uSmZI9HXJw52hiH56inRHpFeGrRG1u7936VOo1IXACDvsgg3EdDNo463r2x6IJWz-UKbqhBTubnzdK23tHpAQA1CeTI7T4p2lT1BJAojmIrqFQv9zMGPgf0IfU8nMyvap1swW1dEKDcPbIOGguQmnBRRmaucva-dT4mEAe93wmrB5-8yMiXgnO88FT1f9fdL2Z6KtDztJJt2N9-EIjTzAxlao_b6f63yunjUqCgEzw1bbwaNnuN8XectAm0rAm6aaF51FqdzRYu2hS0fZSm8JkD2RYk1STj3WW1XAr0Dd5qFgJoCi3vRwh4gZM1G0_A09H6nDLjx_dmCeuUtll90pfbBTH0tyMIN4GUt-3HpJZb9KTMG145koF0IgvluoaMIO2mhH0VALFMW8AbWUQcocuORwX4815zDVl6QE-OynbmPrkeU3sEq-CFS7g0QKcOi26cUAqkxUG-PDQpRsDLXRwiv4uG0Y4xi6O8ZmPveINKNpbHoRBEhTUCARfEmS6b0D0BCdIQ7SPk-QlQlVy9bI2VT_jJE-sycMfA=w535-h296-no?authuser=0' style=\"height:250px\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning task is accomplished by the definition of the parameters in the model so as to minimize a **cost function** $C(.)$ that penalizes prediction errors of training data points $(y_{ij} - \\hat{y}_{ij})$ in comparison to the actual value. The training data is given by a collection of $N$ observations $\\{(y_i, x_i)\\}_{i=1}^N$, where $y_i \\in \\mathbb{R}^m$ and $x_i \\in \\mathbb{R}^p$, that can be used for fitting the model to this data, then allowing the generalization of the model to new data points $x^*$. In the context of neural networks, their parameters are **weights** $\\{w_{jk}^l\\}$ and **biases** $\\{b_j^l\\}$, for $j \\in J_l$, $k \\in J_{l-1}$ and $l \\in \\{1, 2, ..., L\\}$.\n",
    "<br>\n",
    "<br>\n",
    "Since the total variation of cost function, given variations in weights and biases, is given by:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\Delta C \\approx \\nabla C \\cdot \\Delta w_k^l = \\frac{\\partial C}{\\partial w_{1k}^l}.\\Delta w_{1k}^l + \\frac{\\partial C}{\\partial w_{2k}^l}.\\Delta w_{2k}^l + ... + \\frac{\\partial C}{\\partial w_{J_lk}^l}.\\Delta w_{J_lk}^l\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\Delta C \\approx \\nabla C \\cdot \\Delta b = \\frac{\\partial C}{\\partial b_1}.\\Delta b_1 + \\frac{\\partial C}{\\partial b_1}.\\Delta b_2 + ... + \\frac{\\partial C}{\\partial b_{J_l}}.\\Delta b_{J_l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "And considering that the goal is to update $w_{jk}^l$ and $b_j^l$ so as to reduce the cost, then a natural guess for updating these parameters from initial values is to induce variations such as:\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\Delta w_{jk}^l = -\\eta \\frac{\\partial C}{\\partial w_{jk}^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\Delta b_j^l = -\\eta \\frac{\\partial C}{\\partial b_j^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $\\eta > 0$ is named the **learning rate**. Consequently, the estimation of parameters of a neural network depends on the following **gradient descent update rule**:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle w_{jk}^l \\rightarrow w_{jk}^{l'} = w_{jk}^l - \\eta\\frac{\\partial C}{\\partial w_{jk}^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle b_j^l \\rightarrow b_j^{l'} = b_j^l - \\eta\\frac{\\partial C}{\\partial b_j^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "The fact that we are trying to reduce $\\Delta C$ by managing the gradient of the cost function $\\nabla C$ leads to the name *gradient descent*.\n",
    "<br>\n",
    "<br>\n",
    "The update rule uses the derivative of $C$ with respect to $w_{jk}^l$ and $b_j^l$. But actually, $C = \\displaystyle \\frac{1}{N}\\sum_{i=1}^N C(x_i)$, where $N$ is the length of the training data. Therefore, the larger the training data, the more complex the estimation will be. The **stochastic gradient descent** overcome this computational issue by randomly selecting $S$ training data points to estimate $C$, resulting in the **stochastic gradient descent update rule**:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle w_{jk}^l \\rightarrow w_{jk}^l{'} = w_{jk}^l - \\frac{\\eta}{S}\\sum_{i=1}^S\\frac{\\partial C(x_{s_i})}{\\partial w_{jk}^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle b_j^l \\rightarrow b_j^{l'} = b_j^l - \\frac{\\eta}{S}\\sum_{i=1}^S\\frac{\\partial C(x_{s_i})}{\\partial b_j^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $S$ is the **mini-batch size** hyper-parameter. When all training data points are used after successive random picked mini-batches, an **epoch of training** is finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backpropagation algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation provides a way of computing $\\partial C(x)/\\partial w$ and $\\partial C(x)/\\partial b$ so that weights and biases can be adjusted appropriately, following gradient descent update rule that tries to minimize overall cost function. Therefore, backpropagation and gradient descent compose the core of neural network fitting.\n",
    "<br>\n",
    "<br>\n",
    "The **backpropagation learning algorithm** relies on fundamental equations that lead to steps that make gradient descent feasible and functional. Its understanding is provided by the equivalence between the fundamental equations and the chain-expression that shows how a change in $w_{jk}^l$ propagates forward until $C$ is affected:\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\frac{\\partial C}{\\partial w_{jk}^l} = \\sum_{mnp...q} \\frac{\\partial C}{\\partial a_m^L}\\frac{\\partial a_m^L}{\\partial a_n^{L-1}}\\frac{\\partial a_n^{L-1}}{\\partial a_p^{L-2}}...\\frac{\\partial a_q^{l+1}}{\\partial a_j^l}\\frac{\\partial a_j^l}{\\partial w_{jk}^l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "To get the backpropagation fundamental equations, an intermediate quantity $\\delta_j^l$ is defined:\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\delta_j^l = \\frac{\\partial C_x}{\\partial z_j^l}\n",
    "\\end{equation}\n",
    "Where $C_x = C(x)$. Thus, $\\delta_j^l$ indicates how changing weighted inputs impacts cost function. The **first backpropagation (BP) equation** considers that $z_j^L$ can only affect $C_x$ by affecting $a_j^L$:\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\label{BP1}\n",
    "    \\displaystyle \\delta_j^L = \\frac{\\partial C_x}{\\partial a_j^L}\\frac{\\partial a_j^L}{\\partial z_j^L} = \\frac{\\partial C_x}{\\partial a_j^L}\\sigma'(z_j^L)\n",
    "\\end{equation}\n",
    "<br>\n",
    "In matrix-form:\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\delta^L = \\nabla_aC_x\\circ\\sigma'(z^L)\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "The **second BP equation** relates $\\delta_j^l$ with $\\delta_k^{l+1}$ and follows from:\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\delta_j^l = \\frac{\\partial C_x}{\\partial z_j^l} = \\sum_k\\frac{\\partial C_x}{\\partial z_k^{l+1}}\\frac{\\partial z_k^{l+1}}{\\partial z_j^l} = \\sum_k \\delta_k^{l+1}\\frac{\\partial z_k^{l+1}}{\\partial z_j^{l}} = \\sum_k \\delta_k^{l+1}w_{kj}^{l+1}\\sigma'(z_j^l)\n",
    "\\end{equation}\n",
    "<br>\n",
    "In matrix-form:\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\delta^l = (w^{l+1})^T\\delta^{l+1}\\circ\\sigma'(z^l)\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "The **third BP equation** defines partial derivatives of $C_x$ with respect to biases of layer $l$ as a function of $\\delta^l$:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\frac{\\partial C_x}{\\partial b_j^l} = \\frac{\\partial C_x}{\\partial z_j^l}\\frac{\\partial z_j^l}{\\partial b_j^l} = \\delta_j^l\\frac{\\partial z_j^l}{\\partial b_j^l} = \\delta_j^l\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "The **fourth BP equation** defines partial derivatives of $C_x$ with respect to weights of layer $l$ as a function of both $\\delta^l$ and $a^{l-1}$:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\frac{\\partial C_x}{\\partial w_{jk}^l} = \\frac{\\partial C_x}{\\partial z_j^l}\\frac{\\partial z_j^l}{\\partial w_{jk}^l} = \\delta_j^l\\frac{\\partial z_j^l}{\\partial w_{jk}^l} = \\delta_j^la_k^{l-1}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Using equations BP1-BP4, one can apply the stochastic gradient descent update rule to estimate $w_{jk}^l$ and $b_j^l$ according to the **backpropagation algorithm**:\n",
    "1. Consider a set of data points $x$, belonging, for instance, to a given mini-batch of size $S$.\n",
    "2. For each input $x$:\n",
    "    * *Input layer activation*: calculate $a^{x,1}$.\n",
    "    * *Feedforward*: for each $l \\in \\{2, 3, ..., L\\}$, compute $z^{x,l} = w^la^{x, l-1} + b^l$ and $a^{x,l} = \\sigma(z^{x,l})$.\n",
    "    * *Output error*: from equation BP1, $\\delta^{x,L} = \\nabla_aC_x\\circ\\sigma'(z^{x,L})$.\n",
    "    * *Backpropagation*: for each $l \\in \\{L-1, L-2, ..., 2\\}$ and from BP2, calculate:\n",
    "    <br>\n",
    "    <br>\n",
    "    \\begin{equation}\n",
    "        \\displaystyle \\delta^{x,l} = (w^{l+1})^T\\delta^{x, l+1}\\circ\\sigma'(z^{x,l})\n",
    "    \\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "3. *Gradient descent*: for each $l \\in \\{L, L-1, ..., 2\\}$, apply update rules using equations BP3 and BP4:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle w^l \\rightarrow w^l - \\frac{\\eta}{S}\\sum_x \\delta^{x,l}(a^{x,l-1})^T\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "    \\displaystyle b^l \\rightarrow b^l - \\frac{\\eta}{S}\\sum_x \\delta^{x,l}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "In addition to this algorithm, two others must be added to implement neural network fitting: one that loops over mini-batches and a second that loops over epochs of training.\n",
    "<br>\n",
    "<br>\n",
    "It should be noticed that dividing terms by $N$ or $S$ is not necessary. Indeed, to implement \\textit{online learning}, in which parameters are updated at real time as new observations come in, there is no way how to precise the number of training data points, thus eliminating $N$ and $S$ scale components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cost functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discussion above has presented an abstract cost function denoted by $C(x)$. Depending on the nature of the response variable vector $y \\in \\mathbb{R}^m$, $C: \\mathbb{R}^p \\rightarrow \\mathbb{R}^m$ can be one among a wide range of functions. If the learning task at hand is a regression one, then $C(.)$ is likely to be the **mean squared error (MSE) function**:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle C(x) = \\sum_{j=1}^m \\frac{1}{2}(y_j(x) - a_j(x))^2\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $y_j(x)$ is the m-th element of $y$ for data point $x$, while $a_j(x)$ is the activation of j-th neuron in the output layer. An alternative to this cost function is the Huber loss, constructed similarly to mean squared error, but treating differently large errors in comparison to smaller ones.\n",
    "<br>\n",
    "<br>\n",
    "A classification task may also use MSE cost function, but equations BP1 and BP4 reveal that **neuron saturation** may occur, a situation under which, irrespective of how large training errors are, weights and biases stop learning, preventing them of correcting their values in such a way as to reduce the errors:\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\frac{\\partial C_x}{\\partial w_{jk}^L} = \\frac{\\partial C_x}{\\partial a_j^L}a_k^{L-1}\\sigma'(z_j^L) = (a_j^L - y_j)a_k^{L-1}\\sigma'(z_j^L)\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "If $a_j^L = \\sigma(z_j^L) \\rightarrow 0$, or $a_j^L = \\sigma(z_j^L) \\rightarrow 1$, and supposing that $y_j(x) = 1$ or $y_j(x) = 0$, respectively, then $\\sigma'(z_j^L) \\rightarrow 0$ and, thus, $\\partial C_x/\\partial w_{jk}^L \\rightarrow 0$. Consequently, some alternatives emerge and may help avoiding the problem of **learning slowdown**. The **cross-entropy** cost function is given by:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle C = -\\frac{1}{N}\\sum_x\\sum_j[y_j\\log(a_j^L) + (1 - y_j)\\log(1 - a_j^L)]\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "The **log-likelihood** cost function, in its turn, follows:\n",
    "\\begin{equation}\n",
    "    \\displaystyle C(x) = -\\log(a_y(x)^L)\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $a_y(x)^L$ is the output layer activation that refers to the correct class for data point $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activation functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was for the cost function, also the activation function $\\sigma(.)$ was not specified in the previous discussion. The **sigmoid function** is a default alternative for $\\sigma(.)$:\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\sigma(z) = \\frac{1}{1 + \\exp(-z)}\n",
    "\\end{equation}\n",
    "<br>\n",
    "This expression has the property that $\\sigma'(z) \\rightarrow 0$ if $\\sigma(z) \\rightarrow -\\infty$ or $\\sigma(z) \\rightarrow \\infty$, which is the main cause for learning slowdown. The combination of log-likelihood cost function and **softmax activation** may also prevent saturation of output layer neurons. This function is given by:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle a_j^L = \\frac{\\exp(z_j^L)}{\\sum_k\\exp(z_k^L)}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Another advantage of this activation is its interpretation of $a_j^L$ as estimated probabilities of $y_j = 1$ (and $y_{-j} = 0$).\n",
    "<br>\n",
    "<br>\n",
    "Two other options are **tanh function** and **rectified linear unit (reLU)**. The first has a format very similar to sigmoid, while the second avoids saturation of neurons (at least for when $\\sigma(z) \\rightarrow \\infty$):\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\tanh(z) = \\displaystyle \\frac{\\exp(z) - \\exp(-z)}{\\exp(z) + \\exp(-z)}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    relu(z) = \\max(0, z)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs when the model fits very well to the training data but fails to generalize to new data points. The larger the number of free parameters a model has the more likely it is to suffer from overfitting. This is specially relevant for neural networks, since there are usually a very large amount of weights and biases, even when only a few hidden layers exist.\n",
    "<br>\n",
    "<br>\n",
    "Besides, estimation is expected to be based on more than one epoch of training. Consequently, when test data accuracy no longer improves, further epochs of training are unnecessary, irrespective of training data accuracy continuing to increase (evidence of overfitting) or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Early stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the final of each epoch of training, predictive accuracy is assessed on *validation data* held out apart from training and test data. If predictive accuracy saturates, training stops even before all predefined epochs of training are executed.\n",
    "<br>\n",
    "<br>\n",
    "Saturation may be defined as predictive accuracy not improving more than some specified threshold for more than a given number of training epochs. Alternatively, saturation may be seen as predictive accuracy not improving over the best so far after a given number of training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weight decay**, or **L2 regularization** modify cost function to penalize the size of weights, working in a continuous manner to reduce how training data affect final outputs. Considering the cross-entropy cost function:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle C = -\\frac{1}{N}\\sum_{xj}[y_j\\log(a_j^L) + (1 - y_j)\\log(1 - a_j^L)] + \\frac{\\lambda}{2N}\\sum_w w^2\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $\\lambda > 0$ is the penalization parameter. L2 penalty makes the weight estimation to consider how to minimize original cost without increasing excessively overall weights size.\n",
    "<br>\n",
    "<br>\n",
    "If $C_0$ is the unregularized cost function, then partial derivatives of $C$ are given by:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\frac{\\partial C}{\\partial w} = \\frac{\\partial C_0}{\\partial w} + \\frac{\\lambda}{N}w\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\frac{\\partial C}{\\partial b} = \\frac{\\partial C_0}{\\partial b}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Where $\\partial C_0/\\partial w$ and $\\partial C_0/\\partial b$ can be calculated through backpropagation following BP1-BP4. Consequently, update rules for stochastic gradient descent changes to:\n",
    "\\begin{equation}\n",
    "    \\displaystyle w \\rightarrow w - \\eta\\frac{\\partial C_0}{\\partial w} - \\frac{\\eta\\lambda}{N}w = \\Big(1 - \\frac{\\eta\\lambda}{N}\\Big)w - \\frac{\\eta}{S}\\sum_x\\frac{\\partial C_x}{\\partial w}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle b \\rightarrow b -\\frac{\\eta}{S}\\sum_x\\frac{\\partial C_x}{\\partial b}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "In the context of neural networks, small weights, as those obtained when using regularized cost functions, imply that small changes in inputs will not affect notably the outputs from the model. Consequently, this means that the estimated model will be less sensitive to local noise, attenuating the effects of overfitting.\n",
    "<br>\n",
    "<br>\n",
    "**L1 regularization** applies similarly to L2 regularization, with the difference being on the penalty term that now follows the L1-norm for vector length:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle C = C_0 + \\frac{\\lambda}{N}\\sum_w|w|\n",
    "\\end{equation}\n",
    "<br>\n",
    "The update rule becomes:\n",
    "\\begin{equation}\n",
    "    \\displaystyle w \\rightarrow w - \\frac{\\eta\\lambda}{N}sign(w) - \\frac{\\eta}{S}\\sum_x\\frac{\\partial C_x}{\\partial w}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Assuming $sign(0) = 0$. Differently from L2 regularization, where shrinkage occurs proportionally to $w$ with L1 regularization $w$ reduces linearly and may even become zero when $w$ assumes a small value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropout layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regularization method applies for a given hidden layer which has a random sample of its neurons temporarily deleted from the neural network. More specifically, at each mini-batch of data, a share of randomly selected neurons of a dropout layer has its activations set to zero, as if those units did not exist. In the next mini-batch, another sample of neurons is disregarded during update, and so on.\n",
    "<br>\n",
    "<br>\n",
    "If $l$ is a dropout layer, then neurons $\\{1, 2, ..., J_l^d\\}$ being dropped out mean not only that their activations $a_j^l$ are set to zero, but also that biases $b_j^l$, weights $w_{jk}^l$ and $w_{j'j}^{l+1}$ (for $j \\in \\{1, 2, ..., J_l^d\\}$) will not be updated in a given mini-batch iteration.\n",
    "<br>\n",
    "<br>\n",
    "Dropout provides regularization as a consequence of its procedure working similarly as if a set of different (complete) neural networks were estimated, and then as if their results were averaged. Averaging relates to regularization since it puts less relevance to each individual estimation that may be influenced by specificities of training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization of weights and biases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One standard way to randomly define initial values for weights and biases is to extract them from independent normal distributions with zero mean and standard deviation equal to 1. Although functional, this method makes the weighted input constructed from this sort of weights and biases to have a normal distribution with an extremely large variance. Therefore, it is pretty likely that $\\sigma(z) \\rightarrow 1$ or $\\sigma(z) \\rightarrow 0$. In either case, $\\sigma'(z) \\rightarrow 0$, if $\\sigma(.)$ is the sigmoid function or has a similar shape, so learning slowdown may be present, not only for weights and biases for output layer, but for any neuron in the network.\n",
    "<br>\n",
    "<br>\n",
    "An alternative strategy to initialize parameters can mitigate learning slowdown for neurons in all layers. For instance, it is possible to change the normal distribution of reference for $w_{jk}^l$ to $N(0, 1/\\sqrt{J_{l-1}})$, where $J_{l-1}$ is the number of neurons in the predecessor layer. As a consequence, the weighted input is still random, but its smaller variance reduce the probability of getting an extremely large value for $|z|$ that would lead to neuron saturation. Since, for a given neuron $j$ in layer $l$, there are multiple weights $w_{jk}^l$ for just one bias $b_j^l$, there is no need for changing initialization of biases in order to correct for neurons saturation. Finally, the main goal of correcting learning slowdown is to reduce the computational cost of neural network estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous discussion on structure and estimation reveals the complexity of specifying neural networks. There is a wide range of possible procedures, and mainly a big collection of hyper-parameters to be pre-defined. Some of the most important ones are:\n",
    "* Number of hidden layers $H$.\n",
    "* Number of neurons in each hidden layer, $J_l$ for $l \\in \\{1, 2, ..., H\\}$.\n",
    "* Number of training epochs.\n",
    "* Learning rate $\\eta$.\n",
    "* Size of mini-batches $S$.\n",
    "* Regularization parameter $\\lambda$.\n",
    "* Share of neurons to be dropped off at each mini-batch iteration, when dropout layers are adopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another decisions that should be made involve:\n",
    "* Cost function $C(x)$.\n",
    "* Activation function $\\sigma(z)$ for each layer (hidden and output).\n",
    "* Distribution of weights and biases for initializing them.\n",
    "* L1 or L2 regularization, or no regularization at all.\n",
    "* Implementation of early stopping, and the definition of its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical stage of this project will precisely explore strategies to specify hyper-parameters and to choose among other options of architecture and estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variations on stochastic gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While gradient descent mainly focuses on the speed of changes in cost function, alternative approaches also consider how the velocity itself is changing. Two interesting alternatives are the **Hessian technique** and the **momentum-based gradient descent**. Both of them consider not only the first order change in cost function, but also the second order, thus refining the information of how cost changes with weights and biases.\n",
    "<br>\n",
    "<br>\n",
    "Focusing on the momentum-based gradient descent, instead of updating weights and biases based solely on gradient of cost, a new variable called *velocity* is inserted into the update rule, controlling the amount of change in $w$:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    v \\rightarrow v' = \\mu v - \\eta\\nabla C\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    w \\rightarrow w' = w + v'\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "The hyper-parameter $\\mu$ can be understood as a parameter of friction. If $\\mu = 1$, then there is no friction, since changes in weights and biases will fully accumulate across iterations. If $\\mu = 0$, then weights and biases will change with no velocity, as occurs with standard gradient descent. In the case of $\\mu \\in (0,1)$, however, the update will be more intense than with standard gradient descent, but will be less prone to suffer from overshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam optimizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate need not to be constant throughout epochs of training. Indeed, on early epochs, when the neural network is getting too wrong, a high learning rate seems a good choice for rapidly adjusting weights and biases. Once learning is getting progressively better, the learning rate can be reduced to avoid overshooting, improving even further the parameters estimation.\n",
    "<br>\n",
    "<br>\n",
    "Adam, which stands for \"adaptive moment estimation\", is an approach to replace a constant configuration of stochastic gradient descent (SGD) for an adaptive one. Adam is more flexible than standard SGD for two main reasons: first, it applies different learning rates for different parameters (weights and biases); second, it makes use of learning rates that evolve throughout estimation.\n",
    "<br>\n",
    "<br>\n",
    "Adam has been shown to improve learning performance by achieving lower training costs at earlier epochs. Besides, it helps reducing the learning task complexity, since learning rate need not to be explicitly defined and its default parameters are expected to perform well in most problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks with more than one hidden layer reproduce the principle under which humans solve tasks (computational or not) by dividing the main problem into several and successive sub-problems. Consequently, a deep neural network is able to learn highly complex target functions. Even though deep neural networks can be trained using gradient-based techniques and the backpropagation algorithm, this approach is not efficient for learning.\n",
    "<br>\n",
    "<br>\n",
    "This because gradient descent applied to neural networks with several distinct hidden layers implies in the **vanishing gradient problem**, under which $\\delta^l = \\nabla_{b^l} C_x$ is likely to be smaller than $\\delta^{l'} = \\nabla_{b^{l'}} C_x$, where $l' > l$, which implies is $\\nabla_{w^l} C_x$ also smaller than $\\nabla_{w^{l'}} C_x$. Therefore, under this problem, weights and biases for neurons in early layers learn slowly than those for later layers. An opposite problem that may occur when the vanishing gradient problem is not present is the **exploding gradient problem**, where parameters in early layers learn very faster than those for early layers.\n",
    "<br>\n",
    "<br>\n",
    "Consequently, neurons from different hidden layers may learn at very different speeds, resulting in the **unstable gradient problem**. To see how bad it is to have early neurons learning very slowly, it is crucial to remember that random initialization may lead to bad results at the same time weights and biases are adjusting themselves too few at each mini-batch and at each epoch. So, it will take too long for the early neurons to capture patterns in training data. Even more, this learning slowdown means that information are being lost as they are not effectively being propagated to neurons in later layers.\n",
    "<br>\n",
    "<br>\n",
    "The difficulty involved in deep learning derives fundamentally from gradient descent method. Even so, some additional techniques may help fitting neural networks with many hidden layers without excessive modifications in the learning algorithm.\n",
    "<br>\n",
    "<br>\n",
    "**Convolutional networks** introduce a different kind of hidden layers that saves the estimation of a large number of parameters. The main novelty with respect to standard neural nets is the replacement of fully connected layers by partially connected ones. **Convolutional layers** explicitly try to capture local or spatial structures. Besides of that, a neural network disposing of convolutional layers is faster to train than standard networks, which helps the fit of models with many hidden layers. Generally, a convolutional layer is followed by a **pooling layer** that works for simplifying the information contained on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further neural networks structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some alternatives to feedforward neural networks that do not propagate forwards the outputs of early neurons as inputs of later neurons. A first class of an alternative construction is **recurrent neural networks (RNNs)**, for which neurons in a given layer depend not only on the activations of neurons from predecessor layers, but also on activations of early models (either those from neurons in predecessor layers, or even those from their own early activations). Therefore, RNNs are very suited for capturing patterns that evolve over time.\n",
    "<br>\n",
    "<br>\n",
    "Learning slowdown tends to be enlarged with RNNs, since this may applies not only across parameters in a given model, but also throughout the whole sequence of models. When **long short-term memory units (LSTMs)** are introduced into RNNs, they help this class of networks to overcome learning slowdown.\n",
    "<br>\n",
    "<br>\n",
    "Another alternative to feedforward networks are **deep belief networks (DBNs)**, which in turn consist on an instance of **generative models**. A DBN model is such that, when learning from data, it automatically creates artificial inputs to expand training data. A second interest characteristic of DBNs is that they can implement unsupervised and semi-supervised learning, i.e., inputs without label can also help the network to learn from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brownlee, Jason. *Gentle Introduction to the Adam Optimization Algorithm for Deep Learning* ([online article](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "<br>\n",
    "Hastie, Tibshirani, Friedman. *The Elements of Statistical Learning*, 2008 (Chapter 11).\n",
    "<br>\n",
    "Nielsen, *Neural Networks and Deep Learning* ([online book](http://neuralnetworksanddeeplearning.com/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
