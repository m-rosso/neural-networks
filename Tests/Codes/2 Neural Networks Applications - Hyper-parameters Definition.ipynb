{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks applications to fraud detection\n",
    "## Hyper-parameters definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are one of the most relevant learning methods currently available, and their widespread application is understood by theoretical robustness, flexible architecture design, and strong expected predictive accuracy.\n",
    "<br>\n",
    "<br>\n",
    "The main objective of this study is to develop a neural network application to fraud detection, and mainly to construct and implement a strategy for hyper-parameter tuning, since this learning method requires a proper definition of a large set of parameters in order to result in a competitive performance.\n",
    "<br>\n",
    "<br>\n",
    "Previously to empirical inquirements, it is necessary to review all details concerning neural networks structure, fitting, and specification, which will base experiments design and tests implementation. So, the theoretical presentation of this notebook will be followed by an empirical stage of tests in which hyper-parameters will be defined to improve neural networks predictive accuracy, after which the best specification obtained should be opposed to alternative learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameters and other definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following attributes of a neural network should be specified in order to optimize predictive accuracy:\n",
    "1. Architecture: number of hidden layers ($L$), number of neurons in each hidden layer ($J_l$).\n",
    "2. Functions: cost function, activation function for neurons in each layer (except for input layer).\n",
    "3. Distribution for weights initialization.\n",
    "4. Learning rate ($\\eta$).\n",
    "5. Fitting hyper-parameters: number of epochs ($T$), mini-batch size ($S$).\n",
    "6. L1 or L2 regularization and its hyper-parameter ($\\lambda$).\n",
    "7. Share of neurons to be dropped out at each mini-batch iteration ($\\rho$).\n",
    "8. Early stopping: minimum change for an improvement ($\\delta$) and tolerated (consecutive) number of epochs without improvement ($P$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy to define architecture and hyper-parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simplification of the learning task: produce random samples of training and validation data.\n",
    "    * **Basic estimation:** using random samples of training and validation data, fit a neural network with a single hidden layer and a single neuron.\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Architecture and fitting hyper-parameters:** using random samples of training and validation data, applying Adam optimizer, and considering suitable values for the remaining hyper-parameters, define appropriate values for:\n",
    "        * Number of hidden layers ($L$).\n",
    "        * Number of neurons in each hidden layer ($J_l$).\n",
    "        * Number of epochs ($T$).\n",
    "        * Mini-batch size ($S$).\n",
    "        * Parameters of early stopping ($\\delta$, $P$).\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Functions:** using random samples of training and validation data, besides architecture and fitting hyper-parameters from above, and considering suitable values for the remaining hyper-parameters, apply Adam optimizer and define the most promising cost and activation functions.\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Dropout parameter ($\\rho$):** using random samples of training and validation data, besides architecture, functions and hyper-parameters from above, apply Adam optimizer and define appropriate values for the share of neurons to be dropped out at each mini-batch iteration. Use performance metrics evaluated at the validation data.\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Regularization parameter ($\\lambda$):** using random samples of training and validation data, besides architecture, functions and hyper-parameters from above, apply Adam optimizer and define appropriate values for regularization parameter $\\lambda$. Use performance metrics evaluated at the validation data.\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Learning rate ($\\eta$):** first, explore different values for the hyper-parameters that constitute Adam, using performance metrics evaluated on validation data as reference. Then, explore different settings for stochastic gradient descent (SGD) optimizer. Finally, oppose the best specification of Adam to the best SGD setting.\n",
    "        * *Strategy for defining $\\eta$ with constant SGD configuration:* starting with a small value, increase it until the threshold $\\eta_0$ is found, above which validation cost starts to oscillate (overshooting). Define appropriate values for learning rate $\\eta$ with $\\lambda = 0$. Then, adjust the regularization parameter $\\lambda$, after which the learning rate $\\eta$ should be redefined, and so on.\n",
    "        * If constant SGD with an optimum value for $\\eta$ outperforms Adam optimizer, review architecture, fitting hyper-parameters and functions.\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Parameters initialization:** oppose default (Glorot Uniform) initialization of parameters with alternative approaches, such as Normal distribution with zero mean and standard deviation equals to the root-squared of the number of neurons in the predecessor layer.\n",
    "    <br>\n",
    "    <br>\n",
    "    * **Review architecture**.\n",
    "    * **Further review:** consider alternatives for hyper-parameters that have shown similar results during initial tests.\n",
    "<br>\n",
    "<br>\n",
    "2. Hyper-parameters definition using the entire training and validation data:\n",
    "    * Given $\\lambda^*$ an appropriate value found during initial trials based on random samples of training and validation data, then grid or random search will be applied over $[\\lambda^* - k_{\\lambda}, \\lambda^* + k_{\\lambda}]$, for $k_{\\lambda} > 0$.\n",
    "    * If constant SGD is applied instead of Adam, then perform grid or random search over $[\\eta^* - k_{\\eta}, \\eta^* + k_{\\eta}]$ $x$ $[\\lambda^* - k_{\\lambda}, \\lambda^* + k_{\\lambda}]$, for $k_{\\eta}, k_{\\lambda} > 0$.\n",
    "    * When implementing grid or random search, architecture and all remaining hyper-parameters will be defined using best values found during initial trials.\n",
    "<br>\n",
    "<br>\n",
    "3. After appropriate values for all hyper-parameters are set, estimation takes place using early stopping to define the number of training epochs. Training will stop once no improvement in performance occurs ($roc\\_auc_1 - roc\\_auc_0 > \\delta = 0$) after $P^*$ epochs of training. Finally, performance metrics are evaluated on the test data, revealing a reliable estimate of predictive accuracy for the neural network model.\n",
    "    * Note, however, that a different strategy would imply in a higher expected test set performance. Similarly to all other hyper-parameters, the number of epochs could be defined using validation data by maximizing a performance metric, for instance. Then, having at hand appropriate values for all hyper-parameters, training and validation data could be combined so model estimation would use a larger set of training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** an interesting alternative strategy to define values for all hyper-parameters would follow this itinerary: choice of functions, architecture and its parameters, fitting hyper-parameters (mini-batch size), dropout parameters, regularization parameter, learning rate (or, more broadly, choice of optimizer), parameters initialization, review of architecture, further review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References for implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mini-batch size definition:\n",
    "    * [Reference](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/) of strategies for defining mini-batch size.\n",
    "    * [Reference](https://medium.com/deep-learning-experiments/effect-of-batch-size-on-neural-net-training-c5ae8516e57) about effects of mini-batch size on neural networks estimation.\n",
    "<br>\n",
    "<br>\n",
    "2. Cost function:\n",
    "    * [Theoretical reference](https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/) concerning cost functions for binary classification tasks.\n",
    "    * [Reference](https://keras.io/api/losses/) of Keras implementation of different cost functions.\n",
    "<br>\n",
    "<br>\n",
    "3. Activation function:\n",
    "    * Theoretical discussion on which activation function to use and pros and cons of different alternatives: [reference 1](https://datascience.aero/aviation-function-deep-learning/), [reference 2](https://towardsdatascience.com/analyzing-different-types-of-activation-functions-in-neural-networks-which-one-to-prefer-e11649256209), [reference 3](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/) and [reference 4](https://towardsdatascience.com/comparison-of-activation-functions-for-deep-neural-networks-706ac4284c8a).\n",
    "    * [Reference](https://keras.io/api/layers/activations/) of Keras implementation of different activation functions.\n",
    "    * References of Keras and Tensorflow implementations of [leaky ReLU](https://keras.io/api/layers/activation_layers/leaky_relu/), [PReLU](https://keras.io/api/layers/activation_layers/prelu/) and [Swish](https://www.tensorflow.org/api_docs/python/tf/keras/activations/swish) activations.\n",
    "    * [Comprehensive list](https://en.wikipedia.org/wiki/Activation_function) of activation functions, including their definitions and properties.\n",
    "<br>\n",
    "<br>\n",
    "4. Regularization:\n",
    "    * [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L2) and [Keras](https://keras.io/api/layers/regularizers/) documentation for regularization.\n",
    "    * [Reference](https://towardsdatascience.com/how-to-implement-custom-regularization-in-tensorflow-keras-4e77be082918) of implementation of L2 regularization.\n",
    "<br>\n",
    "<br>\n",
    "5. Dropout:\n",
    "    * [Tensorflow and Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) of dropout layers.\n",
    "    * [Reference](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/) of implementation of dropout layers.\n",
    "<br>\n",
    "<br>\n",
    "6. Learning rate:\n",
    "    * References for Keras using of optimizers: [general usage](https://keras.io/api/optimizers/), [Adam](https://keras.io/api/optimizers/adam/), [SGD](https://keras.io/api/optimizers/sgd/).\n",
    "    * [Reference](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/) with theoretical and empirical discussions on learning rate settings.\n",
    "    * [Reference](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) of theoretical presentation and implementation guide for Adam.\n",
    "<br>\n",
    "<br>\n",
    "7. Parameters initialization:\n",
    "    * [Keras documentation](https://keras.io/api/layers/initializers/) for weights and biases initialization.\n",
    "    * [Tensorflow and Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/initializers) for weights and biases initializers.\n",
    "    * [Reference](https://jamesmccaffrey.wordpress.com/2017/06/21/neural-network-glorot-initialization/#:~:text=One%20common%20initialization%20scheme%20for,fan%2Dout%20of%20the%20weight.) of default Glorot initialization of parameters.\n",
    "    * [Reference](https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/) for theoretical discussion on weights initialization.\n",
    "<br>\n",
    "<br>\n",
    "8. Early stopping:\n",
    "    * [Keras](https://keras.io/api/callbacks/early_stopping/) and [Tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) documentations for default early stopping callbacks.\n",
    "    * [Reference](https://datascience.stackexchange.com/questions/26833/is-there-away-to-change-the-metric-used-by-the-early-stopping-callback-in-keras) for constructing custom early stopping callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an introductory theoretical discussion, this notebook applies a strategy to define all main hyper-parameters for the estimation of neural network models. A further notebook will present the evolution of performance metrics after successive tuning of different hyper-parameters. Then, models based on alternative learning methods will also be trained, and their performance will later be compared against that for the best neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Functions and classes](#functions_classes)<a href='#functions_classes'></a>.\n",
    "3. [Settings](#settings)<a href='#settings'></a>.\n",
    "4. [Importing data](#imports)<a href='#imports'></a>.\n",
    "    * [Categorical features](#categorical_features)<a href='#categorical_features'></a>.\n",
    "    * [Model assessment](#model_assessment)<a href='#model_assessment'></a>.\n",
    "    * [Classifying features](#classif_feat)<a href='#classif_feat'></a>.\n",
    "<br>\n",
    "<br>\n",
    "5. [Data pre-processing](#data_pre_proc)<a href='#data_pre_proc'></a>.\n",
    "    * [Assessing missing values](#assessing_missing)<a href='#assessing_missing'></a>.\n",
    "    * [Transforming numerical features](#num_transf)<a href='#num_transf'></a>.\n",
    "    * [Transforming categorical features](#categorical_transf)<a href='#categorical_transf'></a>.\n",
    "    * [Datasets structure](#datasets_structure)<a href='#datasets_structure'></a>.\n",
    "<br>\n",
    "<br>\n",
    "6. [Basic estimation](#basic_estimation)<a href='#basic_estimation'></a>.\n",
    "    * [Random samples](#random_samples)<a href='#random_samples'></a>.\n",
    "    * [Basic neural network](#basic_model)<a href='#basic_model'></a>.\n",
    "    * [Variability assessment](#var_assessment)<a href='#var_assessment'></a>.\n",
    "<br>\n",
    "<br>\n",
    "7. [Architecture definition](#architecture)<a href='#architecture'></a>.\n",
    "    * [Neurons for a single hidden layer](#neurons_single_hidden_layer)<a href='#neurons_single_hidden_layer'></a>.\n",
    "    * [Neurons for two hidden layers](#neurons_two_hidden_layers)<a href='#neurons_two_hidden_layers'></a>.\n",
    "    * [Neurons for three hidden layers](#neurons_three_hidden_layers)<a href='#neurons_three_hidden_layers'></a>.\n",
    "<br>\n",
    "<br>\n",
    "8. [Fitting hyper-parameters](#fitting_params)<a href='#fitting_params'></a>.\n",
    "    * [Grid of mini-batch sizes](#grid_mini_batch_sizes)<a href='#grid_mini_batch_sizes'></a>.\n",
    "    * [Velocity approach to mini-batch size definition](#velocity_approach)<a href='#velocity_approach'></a>.\n",
    "    * [Number of epochs](#number_epochs)<a href='#number_epochs'></a>.\n",
    "<br>\n",
    "<br>\n",
    "9. [Functions](#functions)<a href='#functions'></a>.\n",
    "    * [Cost function](#cost_function)<a href='#cost_function'></a>.\n",
    "    * [Activation functions](#activation_functions)<a href='#activation_functions'></a>.\n",
    "<br>\n",
    "<br>\n",
    "10. [Regularization](#regularization)<a href='#regularization'></a>.\n",
    "    * [Assessing overfitting through L2 regularization](#assessing_overfitting_l2)<a href='#assessing_overfitting_l2'></a>.\n",
    "    * [Assessing overfitting through L1 regularization](#assessing_overfitting_l1)<a href='#assessing_overfitting_l1'></a>.\n",
    "    * [Grid of L2 regularization parameters](#grid_l2_regul_params)<a href='#grid_l2_regul_params'></a>.\n",
    "    * [Grid of L1 regularization parameters](#grid_l1_regul_params)<a href='#grid_l1_regul_params'></a>.\n",
    "<br>\n",
    "<br>\n",
    "11. [Dropout](#dropout)<a href='#dropout'></a>.\n",
    "    * [Grid of values for input dropout](#input_dropout)<a href='#input_dropout'></a>.\n",
    "    * [Grid of values for dropout of hidden neurons](#hidden_dropout)<a href='#hidden_dropout'></a>.\n",
    "<br>\n",
    "<br>\n",
    "12. [Learning rate](#learning_rate)<a href='#learning_rate'></a>.\n",
    "    * [Testing Adam hyper-parameters](#adam_params)<a href='#adam_params'></a>.\n",
    "    * [SGD optimizer (no momentum and no decay)](#sgd_opt1)<a href='#sgd_opt1'></a>.\n",
    "    * [SGD optimizer](#sgd_opt2)<a href='#sgd_opt2'></a>.\n",
    "<br>\n",
    "<br>\n",
    "13. [Parameters initialization](#parameters_init)<a href='#parameters_init'></a>.\n",
    "    * [Grid of distributions](#distributions)<a href='#distributions'></a>.\n",
    "<br>\n",
    "<br>\n",
    "14. [Architecture review](#architecture_review)<a href='#architecture_review'></a>.\n",
    "    * [Testing alternative architectures](#testing_architectures)<a href='#testing_architectures'></a>.\n",
    "<br>\n",
    "<br>\n",
    "15. [Further review](#further_review)<a href='#further_review'></a>.\n",
    "    * [Mini-batch size](#mini_batch_size_review)<a href='#mini_batch_size_review'></a>.\n",
    "    * [Input dropout](#input_dropout_review)<a href='#input_dropout_review'></a>.\n",
    "    * [Hidden dropout](#hidden_dropout_review)<a href='#hidden_dropout_review'></a>.\n",
    "    * [Adam hyper-parameters](#adam_params_review)<a href='#adam_params_review'></a>.\n",
    "<br>\n",
    "<br>\n",
    "16. [Grid search for regularization parameter](#regul_param_grid_search)<a href='#regul_param_grid_search'></a>.\n",
    "17. [Final estimation with early stopping](#final_estimation)<a href='#final_estimation'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LeakyReLU, PReLU\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from scipy.stats import uniform, norm, randint\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, auc, precision_recall_curve, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# print(__version__) # requires version >= 1.9.0\n",
    "\n",
    "import cufflinks as cf\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions_classes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import epoch_to_date, text_clean, is_velocity, balanced_sample, get_cat, permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import log_transformation, standard_scale, recreate_missings, impute_missing\n",
    "from transformations import one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nn\n",
    "from keras_nn import KerasNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='settings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare whether to export results:\n",
    "export = True\n",
    "\n",
    "# Define a dataset id:\n",
    "s = 6044\n",
    "\n",
    "# Declare whether to apply logarithmic transformation over numerical data:\n",
    "log_transform = True\n",
    "\n",
    "# Declare whether to standardize numerical data:\n",
    "standardize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train for store 6044:\u001b[0m (35897, 2173).\n",
      "\u001b[1mShape of df_val for store 6044:\u001b[0m (20940, 2173).\n",
      "\u001b[1mShape of df_test for store 6044:\u001b[0m (21791, 2173).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>ZIPFIRST3REPUTATION()</th>\n",
       "      <th>ZIPFIRST5REPUTATION()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>D48D0720681E4F5D9A2767F7174B5FA6-2782006</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.96</td>\n",
       "      <td>A0EB579C0AE0452D9020C91C54565B4F-2782009</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.72</td>\n",
       "      <td>17A1DF0F984E4B34AC512D7E9E23B7BB-2782011</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           0.0                         0.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "\n",
       "   ZIPFIRST3REPUTATION()  ZIPFIRST5REPUTATION()    y  order_amount  \\\n",
       "0               0.000000                    0.0  0.0        156.75   \n",
       "1               0.000992                    0.0  0.0         67.96   \n",
       "2               0.003344                    0.0  0.0        315.72   \n",
       "\n",
       "                                   order_id    status         epoch  store_id  \\\n",
       "0  D48D0720681E4F5D9A2767F7174B5FA6-2782006  APPROVED  1.577751e+12      6044   \n",
       "1  A0EB579C0AE0452D9020C91C54565B4F-2782009  APPROVED  1.577751e+12      6044   \n",
       "2  17A1DF0F984E4B34AC512D7E9E23B7BB-2782011  APPROVED  1.577751e+12      6044   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2019-12-30  \n",
       "1     1.0 2019-12-30  \n",
       "2     1.0 2019-12-30  \n",
       "\n",
       "[3 rows x 2173 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data:\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Features/Datasets/')\n",
    "\n",
    "df_train = pd.read_csv('new_additional_datasets/dataset_' + str(s) + '.csv',\n",
    "                       dtype={'order_id': str, 'store_id': int})\n",
    "df_train.drop_duplicates(['order_id', 'epoch', 'order_amount'], inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train['date'] = df_train.epoch.apply(epoch_to_date)\n",
    "\n",
    "# Dropping original categorical features:\n",
    "cat_vars = get_cat(df_train)\n",
    "c_vars = [c for c in list(df_train.columns) if 'C#' in c]\n",
    "na_vars = ['NA#' + c for c in cat_vars if 'NA#' + c in list(df_train.columns)]\n",
    "\n",
    "df_train = df_train.drop(c_vars, axis=1).drop(na_vars, axis=1)\n",
    "\n",
    "# Splitting data into train and test:\n",
    "df_test = df_train[(df_train.date > datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "df_train = df_train[(df_train.date <= datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "\n",
    "# Splitting data into validation and test:\n",
    "df_val = df_test[df_test.date < datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "df_test = df_test[df_test.date >= datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "\n",
    "print('\\033[1mShape of df_train for store ' + str(s) + ':\\033[0m ' + str(df_train.shape) + '.')\n",
    "print('\\033[1mShape of df_val for store ' + str(s) + ':\\033[0m ' + str(df_val.shape) + '.')\n",
    "print('\\033[1mShape of df_test for store ' + str(s) + ':\\033[0m ' + str(df_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "# Accessory variables:\n",
    "drop_vars = ['y', 'order_amount', 'store_id', 'order_id', 'status', 'epoch', 'date', 'weight']\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values:\n",
    "num_miss_train = df_train.isnull().sum().sum()\n",
    "num_miss_val = df_val.isnull().sum().sum()\n",
    "num_miss_test = df_test.isnull().sum().sum()\n",
    "\n",
    "if num_miss_train > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "if num_miss_val > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (validation data):\\033[0m ' +\n",
    "          str(df_val.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "    \n",
    "if num_miss_test > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of categorical_train (training data):\u001b[0m (35897, 22).\n",
      "\u001b[1mNumber of orders (training data):\u001b[0m 35897.\n",
      "\n",
      "\n",
      "\u001b[1mShape of categorical_val (validation data):\u001b[0m (20940, 22).\n",
      "\u001b[1mNumber of orders (validation data):\u001b[0m 20940.\n",
      "\n",
      "\n",
      "\u001b[1mShape of categorical_test (test data):\u001b[0m (21791, 22).\n",
      "\u001b[1mNumber of orders (test data):\u001b[0m 21791.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGSTATE()</th>\n",
       "      <th>BROWSER()</th>\n",
       "      <th>CREDITCARDBRAND()</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>...</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VISA</td>\n",
       "      <td>BR</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>Fartura</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>D48D0720681E4F5D9A2767F7174B5FA6-2782006</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.96</td>\n",
       "      <td>A0EB579C0AE0452D9020C91C54565B4F-2782009</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VISA</td>\n",
       "      <td>BR</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>Recife</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.72</td>\n",
       "      <td>17A1DF0F984E4B34AC512D7E9E23B7BB-2782011</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>Guarapari</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.15</td>\n",
       "      <td>21CA5C8AA45B400DB55985466AEE0BCD-2782028</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELO/DISCOVER</td>\n",
       "      <td>BR</td>\n",
       "      <td>NANJING DINERS</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>M</td>\n",
       "      <td>Curitiba</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.74</td>\n",
       "      <td>FFC167F3C6C742C9AD26E7E07ED72115-2782055</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577752e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BILLINGCITY() BILLINGSTATE() BROWSER() CREDITCARDBRAND()  \\\n",
       "0           NaN            NaN       NaN              VISA   \n",
       "1           NaN            NaN       NaN        MASTERCARD   \n",
       "2           NaN            NaN       NaN              VISA   \n",
       "3           NaN            NaN       NaN        MASTERCARD   \n",
       "4           NaN            NaN       NaN      ELO/DISCOVER   \n",
       "\n",
       "  CREDITCARDCOUNTRY() CREDITCARDSUBTYPE() EMAILDOMAIN() GENDERBYNAMEPTBR()  \\\n",
       "0                  BR                GOLD   hotmail.com                  F   \n",
       "1                  BR                GOLD     gmail.com                  F   \n",
       "2                  BR             CLASSIC     gmail.com                  F   \n",
       "3                  BR            PLATINUM     gmail.com                  F   \n",
       "4                  BR      NANJING DINERS   hotmail.com                  M   \n",
       "\n",
       "  IPGEOLOCATIONCITY() IPGEOLOCATIONCOUNTRY()  ... SHIPPINGSTATE()  \\\n",
       "0             Fartura                     BR  ...              SP   \n",
       "1           São Paulo                     BR  ...              SP   \n",
       "2              Recife                     BR  ...              AL   \n",
       "3           Guarapari                     BR  ...              RJ   \n",
       "4            Curitiba                     BR  ...              SC   \n",
       "\n",
       "  UTMSOURCELASTCLICK()    y order_amount  \\\n",
       "0                  NaN  0.0       156.75   \n",
       "1                  NaN  0.0        67.96   \n",
       "2                  NaN  0.0       315.72   \n",
       "3                  NaN  0.0       514.15   \n",
       "4                  NaN  0.0        64.74   \n",
       "\n",
       "                                   order_id    status         epoch store_id  \\\n",
       "0  D48D0720681E4F5D9A2767F7174B5FA6-2782006  APPROVED  1.577751e+12     6044   \n",
       "1  A0EB579C0AE0452D9020C91C54565B4F-2782009  APPROVED  1.577751e+12     6044   \n",
       "2  17A1DF0F984E4B34AC512D7E9E23B7BB-2782011  APPROVED  1.577751e+12     6044   \n",
       "3  21CA5C8AA45B400DB55985466AEE0BCD-2782028  APPROVED  1.577751e+12     6044   \n",
       "4  FFC167F3C6C742C9AD26E7E07ED72115-2782055  APPROVED  1.577752e+12     6044   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2019-12-30  \n",
       "1     1.0 2019-12-30  \n",
       "2     1.0 2019-12-30  \n",
       "3     1.0 2019-12-30  \n",
       "4     1.0 2019-12-30  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_train = pd.read_csv('new_additional_datasets/categorical_features/dataset_' + str(s) + '.csv',\n",
    "                      dtype={'order_id': str, 'store_id': int})\n",
    "categorical_train.drop_duplicates(['order_id', 'epoch', 'order_amount'], inplace=True)\n",
    "\n",
    "categorical_train['date'] = categorical_train.epoch.apply(epoch_to_date)\n",
    "\n",
    "# Splitting data into train and test:\n",
    "categorical_test = categorical_train[(categorical_train.date > datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "categorical_train = categorical_train[(categorical_train.date <= datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "\n",
    "# Splitting data into validation and test:\n",
    "categorical_val = categorical_test[categorical_test.date < datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "categorical_test = categorical_test[categorical_test.date >= datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "\n",
    "print('\\033[1mShape of categorical_train (training data):\\033[0m ' + str(categorical_train.shape) + '.')\n",
    "print('\\033[1mNumber of orders (training data):\\033[0m ' + str(categorical_train.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mShape of categorical_val (validation data):\\033[0m ' + str(categorical_val.shape) + '.')\n",
    "print('\\033[1mNumber of orders (validation data):\\033[0m ' + str(categorical_val.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mShape of categorical_test (test data):\\033[0m ' + str(categorical_test.shape) + '.')\n",
    "print('\\033[1mNumber of orders (test data):\\033[0m ' + str(categorical_test.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (training data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      35793\n",
      "BROWSER()                 35689\n",
      "BILLINGSTATE()            32920\n",
      "BILLINGCITY()             32920\n",
      "CREDITCARDSUBTYPE()         642\n",
      "IPGEOLOCATIONCITY()         522\n",
      "IPGEOLOCATIONCOUNTRY()       20\n",
      "GENDERBYNAMEPTBR()           12\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "CREDITCARDCOUNTRY()           0\n",
      "CREDITCARDBRAND()             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (training data):\\033[0m')\n",
    "print(categorical_train.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (validation data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      20896\n",
      "BROWSER()                 20846\n",
      "BILLINGSTATE()            19447\n",
      "BILLINGCITY()             19447\n",
      "CREDITCARDSUBTYPE()         350\n",
      "IPGEOLOCATIONCITY()         274\n",
      "GENDERBYNAMEPTBR()           10\n",
      "IPGEOLOCATIONCOUNTRY()        5\n",
      "CREDITCARDCOUNTRY()           1\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "CREDITCARDBRAND()             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (validation data):\\033[0m')\n",
    "print(categorical_val.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (test data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      21757\n",
      "BROWSER()                 21689\n",
      "BILLINGSTATE()            20084\n",
      "BILLINGCITY()             20084\n",
      "IPGEOLOCATIONCITY()        1927\n",
      "IPGEOLOCATIONCOUNTRY()      492\n",
      "CREDITCARDSUBTYPE()         455\n",
      "CREDITCARDCOUNTRY()           2\n",
      "GENDERBYNAMEPTBR()            1\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "CREDITCARDBRAND()             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (test data):\\033[0m')\n",
    "print(categorical_test.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over categorical features:\n",
    "for f in categorical_train.drop(drop_vars, axis=1).columns:\n",
    "    # Training data\n",
    "    categorical_train[f] = categorical_train[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)\n",
    "    \n",
    "    # Validation data:\n",
    "    categorical_val[f] = categorical_val[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)\n",
    "    \n",
    "    # Test data:\n",
    "    categorical_test[f] = categorical_test[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values:\n",
    "if categorical_train.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(categorical_train.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "if categorical_val.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (validation data):\\033[0m ' +\n",
    "          str(categorical_val.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "    \n",
    "if categorical_test.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(categorical_test.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGSTATE()</th>\n",
       "      <th>BROWSER()</th>\n",
       "      <th>CREDITCARDBRAND()</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>...</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>visa</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>fartura</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>D48D0720681E4F5D9A2767F7174B5FA6-2782006</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.96</td>\n",
       "      <td>A0EB579C0AE0452D9020C91C54565B4F-2782009</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>visa</td>\n",
       "      <td>br</td>\n",
       "      <td>classic</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>recife</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>al</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.72</td>\n",
       "      <td>17A1DF0F984E4B34AC512D7E9E23B7BB-2782011</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>guarapari</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>rj</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.15</td>\n",
       "      <td>21CA5C8AA45B400DB55985466AEE0BCD-2782028</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>elo/discover</td>\n",
       "      <td>br</td>\n",
       "      <td>nanjing_diners</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sc</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.74</td>\n",
       "      <td>FFC167F3C6C742C9AD26E7E07ED72115-2782055</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577752e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BILLINGCITY() BILLINGSTATE() BROWSER() CREDITCARDBRAND()  \\\n",
       "0      na_value       na_value  na_value              visa   \n",
       "1      na_value       na_value  na_value        mastercard   \n",
       "2      na_value       na_value  na_value              visa   \n",
       "3      na_value       na_value  na_value        mastercard   \n",
       "4      na_value       na_value  na_value      elo/discover   \n",
       "\n",
       "  CREDITCARDCOUNTRY() CREDITCARDSUBTYPE() EMAILDOMAIN() GENDERBYNAMEPTBR()  \\\n",
       "0                  br                gold   hotmail.com                  f   \n",
       "1                  br                gold     gmail.com                  f   \n",
       "2                  br             classic     gmail.com                  f   \n",
       "3                  br            platinum     gmail.com                  f   \n",
       "4                  br      nanjing_diners   hotmail.com                  m   \n",
       "\n",
       "  IPGEOLOCATIONCITY() IPGEOLOCATIONCOUNTRY()  ... SHIPPINGSTATE()  \\\n",
       "0             fartura                     br  ...              sp   \n",
       "1           sao_paulo                     br  ...              sp   \n",
       "2              recife                     br  ...              al   \n",
       "3           guarapari                     br  ...              rj   \n",
       "4            curitiba                     br  ...              sc   \n",
       "\n",
       "  UTMSOURCELASTCLICK()    y order_amount  \\\n",
       "0             na_value  0.0       156.75   \n",
       "1             na_value  0.0        67.96   \n",
       "2             na_value  0.0       315.72   \n",
       "3             na_value  0.0       514.15   \n",
       "4             na_value  0.0        64.74   \n",
       "\n",
       "                                   order_id    status         epoch store_id  \\\n",
       "0  D48D0720681E4F5D9A2767F7174B5FA6-2782006  APPROVED  1.577751e+12     6044   \n",
       "1  A0EB579C0AE0452D9020C91C54565B4F-2782009  APPROVED  1.577751e+12     6044   \n",
       "2  17A1DF0F984E4B34AC512D7E9E23B7BB-2782011  APPROVED  1.577751e+12     6044   \n",
       "3  21CA5C8AA45B400DB55985466AEE0BCD-2782028  APPROVED  1.577751e+12     6044   \n",
       "4  FFC167F3C6C742C9AD26E7E07ED72115-2782055  APPROVED  1.577752e+12     6044   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2019-12-30  \n",
       "1     1.0 2019-12-30  \n",
       "2     1.0 2019-12-30  \n",
       "3     1.0 2019-12-30  \n",
       "4     1.0 2019-12-30  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_vars = [c for c in categorical_train.drop(drop_vars, axis=1) if 'NA#' in c]\n",
    "\n",
    "# Loop over categorical features:\n",
    "for f in categorical_train.drop(drop_vars, axis=1).drop(na_vars, axis=1).columns:\n",
    "    # Training data:\n",
    "    categorical_train[f] = categorical_train[f].apply(lambda x: text_clean(str(x)))\n",
    "    \n",
    "    # Validation data:\n",
    "    categorical_val[f] = categorical_val[f].apply(lambda x: text_clean(str(x)))\n",
    "    \n",
    "    # Test data:\n",
    "    categorical_test[f] = categorical_test[f].apply(lambda x: text_clean(str(x)))\n",
    "\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train for store 6044:\u001b[0m (35897, 2187).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>fartura</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>fartura</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>santos</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>classic</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>recife</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>maceio</td>\n",
       "      <td>al</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>guarapari</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>itaperuna</td>\n",
       "      <td>rj</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>nanjing_diners</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_jose</td>\n",
       "      <td>sc</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           0.0                         0.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "3                           0.0                         0.0  ...   \n",
       "4                           0.0                         0.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0                   br                 gold    hotmail.com   \n",
       "1                   br                 gold      gmail.com   \n",
       "2                   br              classic      gmail.com   \n",
       "3                   br             platinum      gmail.com   \n",
       "4                   br       nanjing_diners    hotmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   f              fartura                      br   \n",
       "1                   f            sao_paulo                      br   \n",
       "2                   f               recife                      br   \n",
       "3                   f            guarapari                      br   \n",
       "4                   m             curitiba                      br   \n",
       "\n",
       "   SELLERID()  SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none         fartura               sp              na_value  \n",
       "1        none          santos               sp              na_value  \n",
       "2        none          maceio               al              na_value  \n",
       "3        none       itaperuna               rj              na_value  \n",
       "4        none        sao_jose               sc              na_value  \n",
       "\n",
       "[5 rows x 2187 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data:\n",
    "df_train = df_train.merge(categorical_train[[f for f in categorical_train.columns if (f not in drop_vars) |\n",
    "                                             (f == 'order_id')]],\n",
    "                          on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_train for store ' + str(s) + ':\\033[0m ' + str(df_train.shape) + '.')\n",
    "print('\\n')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_val for store 6044:\u001b[0m (20940, 2187).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>itapecerica_da_serra</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>infinite</td>\n",
       "      <td>karseg.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>campinas</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>campinas</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>mairinque</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>mairinque</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>salvador</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>joao_pessoa</td>\n",
       "      <td>pb</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           1.0                          1.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           1.0                         1.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           1.0                        1.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           1.0                         1.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "3                           0.0                         0.0  ...   \n",
       "4                           0.0                         0.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0                   br                 gold    hotmail.com   \n",
       "1                   br             infinite  karseg.com.br   \n",
       "2                   br                 gold      gmail.com   \n",
       "3                   br             platinum      gmail.com   \n",
       "4                   br             platinum    hotmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   f            sao_paulo                      br   \n",
       "1                   m             campinas                      br   \n",
       "2                   m            sao_paulo                      br   \n",
       "3                   f            mairinque                      br   \n",
       "4                   f             salvador                      br   \n",
       "\n",
       "   SELLERID()        SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none  itapecerica_da_serra               sp              na_value  \n",
       "1        none              campinas               sp              na_value  \n",
       "2        none             sao_paulo               sp              na_value  \n",
       "3        none             mairinque               sp              na_value  \n",
       "4        none           joao_pessoa               pb              na_value  \n",
       "\n",
       "[5 rows x 2187 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data:\n",
    "df_val = df_val.merge(categorical_val[[f for f in categorical_val.columns if (f not in drop_vars) |\n",
    "                                       (f == 'order_id')]],\n",
    "                      on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_val for store ' + str(s) + ':\\033[0m ' + str(df_val.shape) + '.')\n",
    "print('\\n')\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_test for store 6044:\u001b[0m (21791, 2187).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>nanjing</td>\n",
       "      <td>adp.com</td>\n",
       "      <td>m</td>\n",
       "      <td>porto_alegre</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>porto_alegre</td>\n",
       "      <td>rs</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>uol.com.br</td>\n",
       "      <td>f</td>\n",
       "      <td>jundiai</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>jundiai</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>black</td>\n",
       "      <td>uol.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>itanhaem</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>itanhaem</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>santa_maria</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>santa_maria</td>\n",
       "      <td>rs</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           0.0                         0.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "3                           0.0                         0.0  ...   \n",
       "4                           0.0                         0.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0                   br              nanjing        adp.com   \n",
       "1                   br             platinum     uol.com.br   \n",
       "2                   br                black     uol.com.br   \n",
       "3                   br                 gold      gmail.com   \n",
       "4                   br                 gold      gmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   m         porto_alegre                      br   \n",
       "1                   f              jundiai                      br   \n",
       "2                   m             itanhaem                      br   \n",
       "3                   f          santa_maria                      br   \n",
       "4                   m            sao_paulo                      br   \n",
       "\n",
       "   SELLERID()  SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none    porto_alegre               rs              na_value  \n",
       "1        none         jundiai               sp              na_value  \n",
       "2        none        itanhaem               sp              na_value  \n",
       "3        none     santa_maria               rs              na_value  \n",
       "4        none       sao_paulo               sp              na_value  \n",
       "\n",
       "[5 rows x 2187 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data:\n",
    "df_test = df_test.merge(categorical_test[[f for f in categorical_test.columns if (f not in drop_vars) |\n",
    "                                          (f == 'order_id')]],\n",
    "                        on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_test for store ' + str(s) + ':\\033[0m ' + str(df_test.shape) + '.')\n",
    "print('\\n')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "if df_train.isnull().sum().sum() != num_miss_train:\n",
    "    print('\\033[1mInconsistent number of overall missings values (training data)!\\033[0m')\n",
    "    print('\\n')\n",
    "\n",
    "# Assessing missing values (validation data):\n",
    "if df_val.isnull().sum().sum() != num_miss_val:\n",
    "    print('\\033[1mInconsistent number of overall missings values (validation data)!\\033[0m')\n",
    "    print('\\n')\n",
    "    \n",
    "# Assessing missing values (test data):\n",
    "if df_test.isnull().sum().sum() != num_miss_test:\n",
    "    print('\\033[1mInconsistent number of overall missings values (test data)!\\033[0m')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_assessment'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with information on model structure and performance:\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Materiais/Codes/neural_nets/')\n",
    "\n",
    "if 'model_assessment.json' not in os.listdir('Datasets'):\n",
    "    model_assessment = {}\n",
    "\n",
    "else:\n",
    "    with open('Datasets/model_assessment.json') as json_file:\n",
    "        model_assessment = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classif_feat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cont_vars</td>\n",
       "      <td>1619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>missing_vars</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>binary_vars</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cat_vars</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>drop_vars</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class  frequency\n",
       "3     cont_vars       1619\n",
       "1  missing_vars        415\n",
       "2   binary_vars         27\n",
       "0      cat_vars         14\n",
       "4     drop_vars          8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical features:\n",
    "cat_vars = list(categorical_train.drop(drop_vars, axis=1).columns)\n",
    "\n",
    "# Dummy variables indicating missing value status:\n",
    "missing_vars = [c for c in list(df_train.drop(drop_vars, axis=1).columns) if ('NA#' in c)]\n",
    "\n",
    "# Dropping features with no variance:\n",
    "no_variance = [c for c in df_train.drop(drop_vars, axis=1).drop(cat_vars,\n",
    "                                                                axis=1).drop(missing_vars,\n",
    "                                                                             axis=1) if df_train[c].var()==0]\n",
    "\n",
    "if len(no_variance) > 0:\n",
    "    df_train.drop(no_variance, axis=1, inplace=True)\n",
    "    df_val.drop(no_variance, axis=1, inplace=True)\n",
    "    df_test.drop(no_variance, axis=1, inplace=True)\n",
    "\n",
    "# Numerical features:\n",
    "cont_vars = [c for c in  list(df_train.drop(drop_vars, axis=1).columns) if is_velocity(c)]\n",
    "\n",
    "# Binary features:\n",
    "binary_vars = [c for c in list(df_train.drop([c for c in df_train.columns if (c in drop_vars) |\n",
    "                                             (c in cat_vars) | (c in missing_vars) | (c in cont_vars)],\n",
    "                                             axis=1).columns) if set(df_train[c].unique()) == set([0,1])]\n",
    "\n",
    "# Updating the list of numerical features:\n",
    "for c in list(df_train.drop(drop_vars, axis=1).columns):\n",
    "    if (c not in cat_vars) & (c not in missing_vars) & (c not in cont_vars) & (c not in binary_vars):\n",
    "        cont_vars.append(c)\n",
    "\n",
    "# Dataframe presenting the frequency of features by class:\n",
    "feats_assess = pd.DataFrame(data={\n",
    "    'class': ['cat_vars', 'missing_vars', 'binary_vars', 'cont_vars', 'drop_vars'],\n",
    "    'frequency': [len(cat_vars), len(missing_vars), len(binary_vars), len(cont_vars), len(drop_vars)]\n",
    "})\n",
    "feats_assess.sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_pre_proc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_missing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vars = [f for f in df_train.columns if 'NA#' in f]\n",
    "\n",
    "# Loop over variables with missing values:\n",
    "for f in [c for c in missing_vars if c.replace('NA#', '') not in cat_vars]:\n",
    "    if f.replace('NA#', '') in df_train.columns:\n",
    "        # Training data:\n",
    "        df_train[f.replace('NA#', '')] = recreate_missings(df_train[f.replace('NA#', '')], df_train[f])\n",
    "        \n",
    "        # Validation data:\n",
    "        df_val[f.replace('NA#', '')] = recreate_missings(df_val[f.replace('NA#', '')], df_val[f])\n",
    "        \n",
    "        # Test data:\n",
    "        df_test[f.replace('NA#', '')] = recreate_missings(df_test[f.replace('NA#', '')], df_test[f])\n",
    "    else:\n",
    "        df_train.drop([f], axis=1, inplace=True)\n",
    "        \n",
    "        df_val.drop([f], axis=1, inplace=True)\n",
    "        \n",
    "        df_test.drop([f], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all variables with missing value status:\n",
    "df_train.drop([f for f in df_train.columns if 'NA#' in f], axis=1, inplace=True)\n",
    "\n",
    "df_val.drop([f for f in df_val.columns if 'NA#' in f], axis=1, inplace=True)\n",
    "\n",
    "df_test.drop([f for f in df_test.columns if 'NA#' in f], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the frequency of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 389 out of 1668 features (23.32%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 7108 out of 35897 observations (19.8%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CUSTNAVCOUNT(cv,6M)</td>\n",
       "      <td>35601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GDOCUMENT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>35574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>35540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IP(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DOCUMENT(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>GEMAIL(TOTAL_AMOUNT,360)</td>\n",
       "      <td>35387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature  missings\n",
       "training_data                                         \n",
       "0                        CUSTNAVCOUNT(cv,6M)     35601\n",
       "1                 GDOCUMENT(TOTAL_AMOUNT,60)     35574\n",
       "2               GTELEPHONE(TOTAL_AMOUNT,360)     35540\n",
       "3                    NAME(TOTAL_AMOUNT,1440)     35494\n",
       "4                      IP(TOTAL_AMOUNT,1440)     35490\n",
       "5                   EMAIL(TOTAL_AMOUNT,1440)     35482\n",
       "6                DOCUMENT(TOTAL_AMOUNT,1440)     35459\n",
       "7              CREDITCARD(TOTAL_AMOUNT,1440)     35458\n",
       "8               TELEPHONE(TOTAL_AMOUNT,1440)     35447\n",
       "9                   GEMAIL(TOTAL_AMOUNT,360)     35387"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (training data):\n",
    "missings_dict = df_train.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_train = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_train.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_train)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_train.missings > 0)/len(missings_assess_train))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_train.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_train)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_train.missings.mean())/len(df_train))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_train.index.name = 'training_data'\n",
    "missings_assess_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 389 out of 1668 features (23.32%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 4176 out of 20940 observations (19.94%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CUSTNAVCOUNT(cv,6M)</td>\n",
       "      <td>20741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GDOCUMENT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>20731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>20710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>IP(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DOCUMENT(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>FSBZIPPHONE()</td>\n",
       "      <td>20630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  missings\n",
       "val_data                                         \n",
       "0                   CUSTNAVCOUNT(cv,6M)     20741\n",
       "1            GDOCUMENT(TOTAL_AMOUNT,60)     20731\n",
       "2          GTELEPHONE(TOTAL_AMOUNT,360)     20710\n",
       "3               NAME(TOTAL_AMOUNT,1440)     20685\n",
       "4              EMAIL(TOTAL_AMOUNT,1440)     20674\n",
       "5         CREDITCARD(TOTAL_AMOUNT,1440)     20658\n",
       "6                 IP(TOTAL_AMOUNT,1440)     20657\n",
       "7           DOCUMENT(TOTAL_AMOUNT,1440)     20657\n",
       "8          TELEPHONE(TOTAL_AMOUNT,1440)     20654\n",
       "9                         FSBZIPPHONE()     20630"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (validation data):\n",
    "missings_dict = df_val.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_val = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_val.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_val)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_val.missings > 0)/len(missings_assess_val))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_val.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_val)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_val.missings.mean())/len(df_val))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_val.index.name = 'val_data'\n",
    "missings_assess_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 389 out of 1668 features (23.32%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 4302 out of 21791 observations (19.74%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GDOCUMENT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>21521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>21512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CUSTNAVCOUNT(cv,6M)</td>\n",
       "      <td>21490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DOCUMENT(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>IP(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>FSBZIPPHONE()</td>\n",
       "      <td>21444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature  missings\n",
       "test_data                                         \n",
       "0             GDOCUMENT(TOTAL_AMOUNT,60)     21521\n",
       "1           GTELEPHONE(TOTAL_AMOUNT,360)     21512\n",
       "2               EMAIL(TOTAL_AMOUNT,1440)     21493\n",
       "3                    CUSTNAVCOUNT(cv,6M)     21490\n",
       "4                NAME(TOTAL_AMOUNT,1440)     21482\n",
       "5           TELEPHONE(TOTAL_AMOUNT,1440)     21476\n",
       "6            DOCUMENT(TOTAL_AMOUNT,1440)     21475\n",
       "7          CREDITCARD(TOTAL_AMOUNT,1440)     21472\n",
       "8                  IP(TOTAL_AMOUNT,1440)     21466\n",
       "9                          FSBZIPPHONE()     21444"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (test data):\n",
    "missings_dict = df_test.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_test = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_test.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_test)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_test.missings > 0)/len(missings_assess_test))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_test.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_test)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_test.missings.mean())/len(df_test))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_test.index.name = 'test_data'\n",
    "missings_assess_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logarithmic transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 11856255.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1619.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 11856255.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 6967103.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1619.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 6967103.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 7177024.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1619.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 7177024.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "# Variables that should not be log-transformed:\n",
    "not_log = [c for c in df_train.columns if c not in cont_vars]\n",
    "\n",
    "if log_transform:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_train = df_train.isnull().sum().sum()\n",
    "    if num_miss_train > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_train) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_train)\n",
    "    df_train = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_train_log = df_train.isnull().sum().sum()\n",
    "    if num_miss_train_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_train_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_train_log != num_miss_train:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\033[1mValidation data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_val = df_val.isnull().sum().sum()\n",
    "    if num_miss_val > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_val) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_val)\n",
    "    df_val = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_val_log = df_val.isnull().sum().sum()\n",
    "    if num_miss_val_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_val_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_val_log != num_miss_val:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "        \n",
    "    print('\\n')\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_test = df_test.isnull().sum().sum()\n",
    "    if num_miss_test > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_test) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_test)\n",
    "    df_test = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_test_log = df_test.isnull().sum().sum()\n",
    "    if num_miss_test_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_test_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_test_log != num_miss_test:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "else:\n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mShape of df_train_scaled (after scaling):\u001b[0m (35897, 1668).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 11856255.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "\u001b[1mShape of df_val_scaled (after scaling):\u001b[0m (20940, 1668).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 6967103.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mShape of df_test_scaled (after scaling):\u001b[0m (21791, 1668).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 7177024.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "# Inputs that should not be standardized:\n",
    "not_stand = [c for c in df_train.columns if c.replace('L#', '') not in cont_vars]\n",
    "\n",
    "if standardize:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "\n",
    "    stand_scale = standard_scale(not_stand = not_stand)\n",
    "    \n",
    "    stand_scale.scale(train = df_train, test = df_val)\n",
    "    \n",
    "    df_train_scaled = stand_scale.train_scaled\n",
    "    print('\\033[1mShape of df_train_scaled (after scaling):\\033[0m ' + str(df_train_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_train = df_train.isnull().sum().sum()\n",
    "    num_miss_train_scaled = df_train_scaled.isnull().sum().sum()\n",
    "    if num_miss_train_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_train_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (training data)!\\033[0m')\n",
    "\n",
    "    if num_miss_train_scaled != num_miss_train:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\033[1mValidation data:\\033[0m')\n",
    "    df_val_scaled = stand_scale.test_scaled\n",
    "    print('\\033[1mShape of df_val_scaled (after scaling):\\033[0m ' + str(df_val_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_val = df_val.isnull().sum().sum()\n",
    "    num_miss_val_scaled = df_val_scaled.isnull().sum().sum()\n",
    "    if num_miss_val_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_val_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (val data)!\\033[0m')\n",
    "\n",
    "    if num_miss_val_scaled != num_miss_val:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "        \n",
    "    print('\\n')\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "    stand_scale.scale(train = df_train, test = df_test)\n",
    "    df_test_scaled = stand_scale.test_scaled\n",
    "    print('\\033[1mShape of df_test_scaled (after scaling):\\033[0m ' + str(df_test_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_test = df_test.isnull().sum().sum()\n",
    "    num_miss_test_scaled = df_test_scaled.isnull().sum().sum()\n",
    "    if num_miss_test_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_test_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (test data)!\\033[0m')\n",
    "\n",
    "    if num_miss_test_scaled != num_miss_test:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "else:\n",
    "    df_train_scaled = df_train.copy()\n",
    "    df_val_scaled = df_val.copy()\n",
    "    df_test_scaled = df_test.copy()\n",
    "    \n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mTREATING MISSING VALUES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 11856255.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 11856255.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 6967103.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 6967103.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 7177024.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 7177024.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mTREATING MISSING VALUES\\033[0m')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTraining data:\\033[0m')\n",
    "num_miss_train = df_train_scaled.isnull().sum().sum()\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' +\n",
    "      str(num_miss_train) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_train_scaled.drop(drop_vars, axis=1):\n",
    "    # Checking if there is missing values for a given feature:\n",
    "    if df_train_scaled[f].isnull().sum() > 0:\n",
    "        check_missing = impute_missing(df_train_scaled[f])\n",
    "        df_train_scaled[f] = check_missing['var']\n",
    "        df_train_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "\n",
    "num_miss_train_treat = int(sum([sum(df_train_scaled[f]) for f in df_train_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_train_treat) + '.')\n",
    "\n",
    "if num_miss_train_treat != num_miss_train:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_train_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train_scaled.isnull().sum().sum()) + '.')\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mValidation data:\\033[0m')\n",
    "num_miss_val = df_val_scaled.isnull().sum().sum()\n",
    "num_miss_val_treat = 0\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' + str(num_miss_val) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_val_scaled.drop(drop_vars, axis=1):\n",
    "    # Check if there is dummy variable of missing value status for training data:\n",
    "    if 'NA#' + f.replace('L#', '') in list(df_train_scaled.columns):\n",
    "        check_missing = impute_missing(df_val_scaled[f])\n",
    "        df_val_scaled[f] = check_missing['var']\n",
    "        df_val_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "    else:\n",
    "        # Checking if there are missings for variables without missings in training data:\n",
    "        if df_val_scaled[f].isnull().sum() > 0:\n",
    "            num_miss_val_treat += df_val_scaled[f].isnull().sum()\n",
    "            df_val_scaled[f].fillna(0, axis=0, inplace=True)\n",
    "\n",
    "num_miss_val_treat += int(sum([sum(df_val_scaled[f]) for f in df_val_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_val_treat) + '.')\n",
    "\n",
    "if num_miss_val_treat != num_miss_val:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_val_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (val data):\\033[0m ' +\n",
    "          str(df_val_scaled.isnull().sum().sum()) + '.')\n",
    "    \n",
    "print('\\n')\n",
    "print('\\033[1mTest data:\\033[0m')\n",
    "num_miss_test = df_test_scaled.isnull().sum().sum()\n",
    "num_miss_test_treat = 0\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' + str(num_miss_test) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_test_scaled.drop(drop_vars, axis=1):\n",
    "    # Check if there is dummy variable of missing value status for training data:\n",
    "    if 'NA#' + f.replace('L#', '') in list(df_train_scaled.columns):\n",
    "        check_missing = impute_missing(df_test_scaled[f])\n",
    "        df_test_scaled[f] = check_missing['var']\n",
    "        df_test_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "    else:\n",
    "        # Checking if there are missings for variables without missings in training data:\n",
    "        if df_test_scaled[f].isnull().sum() > 0:\n",
    "            num_miss_test_treat += df_test_scaled[f].isnull().sum()\n",
    "            df_test_scaled[f].fillna(0, axis=0, inplace=True)\n",
    "\n",
    "num_miss_test_treat += int(sum([sum(df_test_scaled[f]) for f in df_test_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_test_treat) + '.')\n",
    "\n",
    "if num_miss_test_treat != num_miss_test:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_test_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test_scaled.isnull().sum().sum()) + '.')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummies through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of categorical features:\u001b[0m 14.\n",
      "\u001b[1mNumber of overall selected dummies:\u001b[0m 62.\n",
      "\u001b[1mShape of dummies_train for store 6044:\u001b[0m (35897, 62).\n",
      "\u001b[1mShape of dummies_val for store 6044:\u001b[0m (20940, 62).\n",
      "\u001b[1mShape of dummies_test for store 6044:\u001b[0m (21791, 62).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C#BILLINGCITY()#NA_VALUE</th>\n",
       "      <th>C#BILLINGCITY()#SAO_PAULO</th>\n",
       "      <th>C#BILLINGSTATE()#NA_VALUE</th>\n",
       "      <th>C#BILLINGSTATE()#SP</th>\n",
       "      <th>C#CREDITCARDBRAND()#AMERICAN_EXPRESS</th>\n",
       "      <th>C#CREDITCARDBRAND()#ELO/DISCOVER</th>\n",
       "      <th>C#CREDITCARDBRAND()#HIPERCARD</th>\n",
       "      <th>C#CREDITCARDBRAND()#MASTERCARD</th>\n",
       "      <th>C#CREDITCARDBRAND()#VISA</th>\n",
       "      <th>C#CREDITCARDSUBTYPE()#BLACK</th>\n",
       "      <th>...</th>\n",
       "      <th>C#SHIPPINGSTATE()#DF</th>\n",
       "      <th>C#SHIPPINGSTATE()#ES</th>\n",
       "      <th>C#SHIPPINGSTATE()#GO</th>\n",
       "      <th>C#SHIPPINGSTATE()#MG</th>\n",
       "      <th>C#SHIPPINGSTATE()#PE</th>\n",
       "      <th>C#SHIPPINGSTATE()#PR</th>\n",
       "      <th>C#SHIPPINGSTATE()#RJ</th>\n",
       "      <th>C#SHIPPINGSTATE()#RS</th>\n",
       "      <th>C#SHIPPINGSTATE()#SC</th>\n",
       "      <th>C#SHIPPINGSTATE()#SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   C#BILLINGCITY()#NA_VALUE  C#BILLINGCITY()#SAO_PAULO  \\\n",
       "0                         1                          0   \n",
       "1                         1                          0   \n",
       "2                         1                          0   \n",
       "3                         1                          0   \n",
       "4                         1                          0   \n",
       "\n",
       "   C#BILLINGSTATE()#NA_VALUE  C#BILLINGSTATE()#SP  \\\n",
       "0                          1                    0   \n",
       "1                          1                    0   \n",
       "2                          1                    0   \n",
       "3                          1                    0   \n",
       "4                          1                    0   \n",
       "\n",
       "   C#CREDITCARDBRAND()#AMERICAN_EXPRESS  C#CREDITCARDBRAND()#ELO/DISCOVER  \\\n",
       "0                                     0                                 0   \n",
       "1                                     0                                 0   \n",
       "2                                     0                                 0   \n",
       "3                                     0                                 0   \n",
       "4                                     0                                 1   \n",
       "\n",
       "   C#CREDITCARDBRAND()#HIPERCARD  C#CREDITCARDBRAND()#MASTERCARD  \\\n",
       "0                              0                               0   \n",
       "1                              0                               1   \n",
       "2                              0                               0   \n",
       "3                              0                               1   \n",
       "4                              0                               0   \n",
       "\n",
       "   C#CREDITCARDBRAND()#VISA  C#CREDITCARDSUBTYPE()#BLACK  ...  \\\n",
       "0                         1                            0  ...   \n",
       "1                         0                            0  ...   \n",
       "2                         1                            0  ...   \n",
       "3                         0                            0  ...   \n",
       "4                         0                            0  ...   \n",
       "\n",
       "   C#SHIPPINGSTATE()#DF  C#SHIPPINGSTATE()#ES  C#SHIPPINGSTATE()#GO  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#MG  C#SHIPPINGSTATE()#PE  C#SHIPPINGSTATE()#PR  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#RJ  C#SHIPPINGSTATE()#RS  C#SHIPPINGSTATE()#SC  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     1                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   C#SHIPPINGSTATE()#SP  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create object for one-hot encoding:\n",
    "categorical_transf = one_hot_encoding(categorical_features = cat_vars)\n",
    "\n",
    "# Creating dummies:\n",
    "categorical_transf.create_dummies(categorical_train = categorical_train,\n",
    "                                  categorical_test = categorical_val)\n",
    "\n",
    "# Selected dummies:\n",
    "dummy_vars = list(categorical_transf.dummies_train.columns)\n",
    "\n",
    "# Training data:\n",
    "dummies_train = categorical_transf.dummies_train\n",
    "dummies_train.index = df_train_scaled.index\n",
    "\n",
    "# Validation data:\n",
    "dummies_val = categorical_transf.dummies_test\n",
    "dummies_val.index = df_val_scaled.index\n",
    "\n",
    "# Create object for one-hot encoding:\n",
    "categorical_transf = one_hot_encoding(categorical_features = cat_vars)\n",
    "\n",
    "# Creating dummies:\n",
    "categorical_transf.create_dummies(categorical_train = categorical_train,\n",
    "                                  categorical_test = categorical_test)\n",
    "\n",
    "# Test data:\n",
    "dummies_test = categorical_transf.dummies_test\n",
    "dummies_test.index = df_test_scaled.index\n",
    "\n",
    "# Dropping original categorical features:\n",
    "df_train_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "df_val_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "df_test_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "\n",
    "print('\\033[1mNumber of categorical features:\\033[0m {}.'.format(len(categorical_transf.categorical_features)))\n",
    "print('\\033[1mNumber of overall selected dummies:\\033[0m {}.'.format(dummies_train.shape[1]))\n",
    "print('\\033[1mShape of dummies_train for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_train.shape) + '.')\n",
    "print('\\033[1mShape of dummies_val for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_val.shape) + '.')\n",
    "print('\\033[1mShape of dummies_test for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "dummies_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train_scaled for store 6044:\u001b[0m (35897, 2105).\n",
      "\u001b[1mShape of df_val_scaled for store 6044:\u001b[0m (20940, 2105).\n",
      "\u001b[1mShape of df_test_scaled for store 6044:\u001b[0m (21791, 2105).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUREAUBILLCITY()</th>\n",
       "      <th>BUREAUBILLSTATE()</th>\n",
       "      <th>BUREAUEMAIL()</th>\n",
       "      <th>BUREAUPHONE()</th>\n",
       "      <th>BUREAUPHONEAREACODE()</th>\n",
       "      <th>BUREAUSHIPCITY()</th>\n",
       "      <th>BUREAUSHIPSTATE()</th>\n",
       "      <th>CREDITCARDCOUNTRYSAMEASSHIPPING()</th>\n",
       "      <th>EMAILHASFRAUD()</th>\n",
       "      <th>EMAILSAMEAMOUNT()</th>\n",
       "      <th>...</th>\n",
       "      <th>C#SHIPPINGSTATE()#DF</th>\n",
       "      <th>C#SHIPPINGSTATE()#ES</th>\n",
       "      <th>C#SHIPPINGSTATE()#GO</th>\n",
       "      <th>C#SHIPPINGSTATE()#MG</th>\n",
       "      <th>C#SHIPPINGSTATE()#PE</th>\n",
       "      <th>C#SHIPPINGSTATE()#PR</th>\n",
       "      <th>C#SHIPPINGSTATE()#RJ</th>\n",
       "      <th>C#SHIPPINGSTATE()#RS</th>\n",
       "      <th>C#SHIPPINGSTATE()#SC</th>\n",
       "      <th>C#SHIPPINGSTATE()#SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BUREAUBILLCITY()  BUREAUBILLSTATE()  BUREAUEMAIL()  BUREAUPHONE()  \\\n",
       "0               0.0                0.0            0.0            0.0   \n",
       "1               0.0                0.0            0.0            0.0   \n",
       "2               0.0                0.0            0.0            0.0   \n",
       "3               0.0                0.0            0.0            0.0   \n",
       "4               0.0                0.0            0.0            0.0   \n",
       "\n",
       "   BUREAUPHONEAREACODE()  BUREAUSHIPCITY()  BUREAUSHIPSTATE()  \\\n",
       "0                    0.0               0.0                0.0   \n",
       "1                    0.0               0.0                0.0   \n",
       "2                    0.0               0.0                0.0   \n",
       "3                    0.0               0.0                0.0   \n",
       "4                    0.0               0.0                0.0   \n",
       "\n",
       "   CREDITCARDCOUNTRYSAMEASSHIPPING()  EMAILHASFRAUD()  EMAILSAMEAMOUNT()  ...  \\\n",
       "0                                1.0              0.0                0.0  ...   \n",
       "1                                1.0              0.0                0.0  ...   \n",
       "2                                1.0              0.0                0.0  ...   \n",
       "3                                1.0              0.0                0.0  ...   \n",
       "4                                1.0              0.0                0.0  ...   \n",
       "\n",
       "   C#SHIPPINGSTATE()#DF  C#SHIPPINGSTATE()#ES  C#SHIPPINGSTATE()#GO  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#MG  C#SHIPPINGSTATE()#PE  C#SHIPPINGSTATE()#PR  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#RJ  C#SHIPPINGSTATE()#RS  C#SHIPPINGSTATE()#SC  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     1                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   C#SHIPPINGSTATE()#SP  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 2105 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled = pd.concat([df_train_scaled, dummies_train], axis=1)\n",
    "df_val_scaled = pd.concat([df_val_scaled, dummies_val], axis=1)\n",
    "df_test_scaled = pd.concat([df_test_scaled, dummies_test], axis=1)\n",
    "\n",
    "print('\\033[1mShape of df_train_scaled for store ' + str(s) + ':\\033[0m ' + str(df_train_scaled.shape) + '.')\n",
    "print('\\033[1mShape of df_val_scaled for store ' + str(s) + ':\\033[0m ' + str(df_val_scaled.shape) + '.')\n",
    "print('\\033[1mShape of df_test_scaled for store ' + str(s) + ':\\033[0m ' + str(df_test_scaled.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "num_miss_train = df_train_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_train:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "# Assessing missing values (validation data):\n",
    "num_miss_val = df_val_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_val:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (validation data):\\033[0m ' +\n",
    "          str(df_val_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "    \n",
    "# Assessing missing values (test data):\n",
    "num_miss_test = df_test_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_test:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datasets_structure'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking consistency of structure between training and validation dataframes:\n",
    "if len(list(df_train_scaled.columns)) != len(list(df_val_scaled.columns)):\n",
    "    print('\\033[1mProblem - Inconsistent number of columns between dataframes for training and validation data!\\033[0m')\n",
    "\n",
    "else:\n",
    "    consistency_check = 0\n",
    "    \n",
    "    # Loop over variables:\n",
    "    for c in list(df_train_scaled.columns):\n",
    "        if list(df_train_scaled.columns).index(c) != list(df_val_scaled.columns).index(c):\n",
    "            print('\\033[1mProblem - Feature {0} was positioned differently in training and val validation!\\033[0m'.format(c))\n",
    "            consistency_check += 1\n",
    "            \n",
    "    # Reordering columns of val dataframe:\n",
    "    if consistency_check > 0:\n",
    "        ordered_columns = list(df_train_scaled.columns)\n",
    "        df_val_scaled = df_val_scaled[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking consistency of structure between training and test dataframes:\n",
    "if len(list(df_train_scaled.columns)) != len(list(df_test_scaled.columns)):\n",
    "    print('\\033[1mProblem - Inconsistent number of columns between dataframes for training and test data!\\033[0m')\n",
    "\n",
    "else:\n",
    "    consistency_check = 0\n",
    "    \n",
    "    # Loop over variables:\n",
    "    for c in list(df_train_scaled.columns):\n",
    "        if list(df_train_scaled.columns).index(c) != list(df_test_scaled.columns).index(c):\n",
    "            print('\\033[1mProblem - Feature {0} was positioned differently in training and test dataframes!\\033[0m'.format(c))\n",
    "            consistency_check += 1\n",
    "            \n",
    "    # Reordering columns of test dataframe:\n",
    "    if consistency_check > 0:\n",
    "        ordered_columns = list(df_train_scaled.columns)\n",
    "        df_test_scaled = df_test_scaled[ordered_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic_estimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='random_samples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Dictionaries whose keys are classes and values are their shares in the entire data:\n",
    "train_classes = {\n",
    "    0: 1 - df_train_scaled.y.mean(),\n",
    "    1: df_train_scaled.y.mean()\n",
    "}\n",
    "\n",
    "val_classes = {\n",
    "    0: 1 - df_val_scaled.y.mean(),\n",
    "    1: df_val_scaled.y.mean()\n",
    "}\n",
    "\n",
    "# Randomly picked indices for training and validation data:\n",
    "train_sample = balanced_sample(df_train_scaled, categorical_var = 'y',\n",
    "                               classes = train_classes, sample_share = 0.5)\n",
    "val_sample = balanced_sample(df_val_scaled, categorical_var = 'y',\n",
    "                               classes = val_classes, sample_share = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTraining data:\u001b[0m\n",
      "Shape of df_train_scaled: (35897, 2105).\n",
      "Shape of sample_train_scaled: (17948, 2105).\n",
      "Share of class 1 in the entire training data: 0.0153.\n",
      "Share of class 1 in the sample of training data: 0.0153.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "Shape of df_val_scaled: (20940, 2105).\n",
      "Shape of sample_val_scaled: (10469, 2105).\n",
      "Share of class 1 in the entire validation data: 0.0117.\n",
      "Share of class 1 in the sample of validation data: 0.0117.\n"
     ]
    }
   ],
   "source": [
    "# Random samples of training and validation data:\n",
    "sample_train_scaled = df_train_scaled.loc[train_sample, :]\n",
    "sample_val_scaled = df_val_scaled.loc[val_sample, :]\n",
    "\n",
    "print('\\033[1mTraining data:\\033[0m')\n",
    "print('Shape of df_train_scaled: {0}.'.format(df_train_scaled.shape))\n",
    "print('Shape of sample_train_scaled: {0}.'.format(sample_train_scaled.shape))\n",
    "print('Share of class 1 in the entire training data: {0}.'.format(round(df_train_scaled.y.mean(), 4)))\n",
    "print('Share of class 1 in the sample of training data: {0}.'.format(round(sample_train_scaled.y.mean(), 4)))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mValidation data:\\033[0m')\n",
    "print('Shape of df_val_scaled: {0}.'.format(df_val_scaled.shape))\n",
    "print('Shape of sample_val_scaled: {0}.'.format(sample_val_scaled.shape))\n",
    "print('Share of class 1 in the entire validation data: {0}.'.format(round(df_val_scaled.y.mean(), 4)))\n",
    "print('Share of class 1 in the sample of validation data: {0}.'.format(round(sample_val_scaled.y.mean(), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic_model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first estimation seeks to develop codes that should be used during more in-depth tests. Therefore, no hyper-parameter is explored here, besides the fact that the architecture is as simple as possible: just one hidden layer containing a single neuron. The cost function used is the cross-entropy function, while activations for hidden and output neurons are rectified linear unit (ReLu) and sigmoid, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model architecture and hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'neurons': 1, 'activation': 'relu', 'dropout_param': 0}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': 1,\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = None\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the model object:\n",
    "model = Sequential()\n",
    "\n",
    "hidden_layers = [model.add(Dense(units = model_architecture[i]['neurons'],\n",
    "                                 activation = model_architecture[i]['activation'],\n",
    "                                 kernel_regularizer = l2(l = regul_param))) for i in model_architecture.keys()]\n",
    "\n",
    "dropout_layers = [model.add(Dropout(rate = model_architecture[i]['dropout_param'])) for i in\n",
    "                  model_architecture.keys()]\n",
    "\n",
    "# Dropout for the input layer:\n",
    "model.add(Dropout(input_dropout, input_shape=(X_train.shape[1],)))\n",
    "\n",
    "# Hidden layers with dropout:\n",
    "for layer, dropout_layer in zip(hidden_layers, dropout_layers):\n",
    "    layer\n",
    "    dropout_layer\n",
    "\n",
    "# Final layer with one neuron:\n",
    "model.add(Dense(units = 1, activation = output_activation))\n",
    "\n",
    "# Compiling the model to prepare it to be fitted:\n",
    "if default_adam:\n",
    "    model.compile(loss = cost_function, optimizer = 'adam')\n",
    "\n",
    "else:\n",
    "    model.compile(loss = cost_function, optimizer = opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.1320 - val_loss: 0.5213\n",
      "Epoch 2/10\n",
      "561/561 [==============================] - 1s 2ms/step - loss: 0.4036 - val_loss: 0.3113\n",
      "Epoch 3/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.2667 - val_loss: 0.2224\n",
      "Epoch 4/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.2003 - val_loss: 0.1718\n",
      "Epoch 5/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.1611 - val_loss: 0.1402\n",
      "Epoch 6/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.1364 - val_loss: 0.1199\n",
      "Epoch 7/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.1195 - val_loss: 0.1056\n",
      "Epoch 8/10\n",
      "561/561 [==============================] - 1s 1ms/step - loss: 0.1084 - val_loss: 0.0958\n",
      "Epoch 9/10\n",
      "561/561 [==============================] - 1s 2ms/step - loss: 0.1005 - val_loss: 0.0891\n",
      "Epoch 10/10\n",
      "561/561 [==============================] - 1s 2ms/step - loss: 0.0948 - val_loss: 0.0842\n",
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 0.13 minutes.\n",
      "Start time: 2020-12-22, 13:11:24\n",
      "End time: 2020-12-22, 13:11:32\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "model.fit(x = X_train, \n",
    "          y = y_train,\n",
    "          validation_data = (X_val, y_val),\n",
    "          epochs = num_epochs,\n",
    "          batch_size = batch_size,\n",
    "          shuffle = False,\n",
    "          callbacks=None,\n",
    "          verbose = 1\n",
    "          )\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + nn_start_time.strftime('%Y-%m-%d') + ', ' + nn_start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + nn_end_time.strftime('%Y-%m-%d') + ', ' + nn_end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function by training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.132033</td>\n",
       "      <td>0.521250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.403645</td>\n",
       "      <td>0.311269</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.266714</td>\n",
       "      <td>0.222395</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.200348</td>\n",
       "      <td>0.171816</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.161070</td>\n",
       "      <td>0.140236</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss  epoch\n",
       "0  0.132033  0.521250      1\n",
       "1  0.403645  0.311269      2\n",
       "2  0.266714  0.222395      3\n",
       "3  0.200348  0.171816      4\n",
       "4  0.161070  0.140236      5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_costs = pd.DataFrame(model.history.history)\n",
    "model_costs['epoch'] = [i + 1 for i in model_costs.index]\n",
    "model_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "loss = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Training cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "xaxis": "x",
         "y": [
          0.5941327214241028,
          0.4064502716064453,
          0.2986856698989868,
          0.22684162855148315,
          0.18034641444683075,
          0.14770744740962982,
          0.12494876235723495,
          0.11011737585067749,
          0.0988091453909874,
          0.08868993073701859
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "val_loss = %{y:.4f}",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "xaxis": "x",
         "y": [
          0.4779091477394104,
          0.3718430697917938,
          0.25441861152648926,
          0.1997051239013672,
          0.16222701966762543,
          0.14975467324256897,
          0.13247163593769073,
          0.11021939665079117,
          0.10476608574390411,
          0.11251471936702728
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost function by epoch of training"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cost"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"0d891d7d-af83-41ce-b87a-bebc7cd41a71\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"0d891d7d-af83-41ce-b87a-bebc7cd41a71\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '0d891d7d-af83-41ce-b87a-bebc7cd41a71',\n",
       "                        [{\"hovertemplate\": \"loss = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Training cost\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"xaxis\": \"x\", \"y\": [0.5941327214241028, 0.4064502716064453, 0.2986856698989868, 0.22684162855148315, 0.18034641444683075, 0.14770744740962982, 0.12494876235723495, 0.11011737585067749, 0.0988091453909874, 0.08868993073701859], \"yaxis\": \"y\"}, {\"hovertemplate\": \"val_loss = %{y:.4f}\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Validation cost\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"xaxis\": \"x\", \"y\": [0.4779091477394104, 0.3718430697917938, 0.25441861152648926, 0.1997051239013672, 0.16222701966762543, 0.14975467324256897, 0.13247163593769073, 0.11021939665079117, 0.10476608574390411, 0.11251471936702728], \"yaxis\": \"y\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Cost function by epoch of training\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"cost\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0d891d7d-af83-41ce-b87a-bebc7cd41a71');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': False}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.loss, name='Training cost',\n",
    "               hovertemplate =\n",
    "                'loss = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.val_loss, name='Validation cost',\n",
    "               hovertemplate = 'val_loss = %{y:.4f}',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Cost function by epoch of training',\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='cost', secondary_y=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance metrics on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPerformance metrics:\u001b[0m\n",
      "Test ROC-AUC: 0.5518.\n",
      "Test average precision score: 0.0836.\n",
      "Test Brier score: 0.0134.\n"
     ]
    }
   ],
   "source": [
    "val_roc_auc = roc_auc_score(y_val, [p[0] for p in model.predict(X_val)])\n",
    "val_avg_prec_score = average_precision_score(y_val, [p[0] for p in model.predict(X_val)])\n",
    "val_brier_score = brier_score_loss(y_val, [p[0] for p in model.predict(X_val)])\n",
    "\n",
    "print('\\033[1mPerformance metrics:\\033[0m')\n",
    "print('Test ROC-AUC: {0}.'.format(round(val_roc_auc, 4)))\n",
    "print('Test average precision score: {0}.'.format(round(val_avg_prec_score, 4)))\n",
    "print('Test Brier score: {0}.'.format(round(val_brier_score, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'application': 'validation',\n",
    "        'min_cost': model_costs.loss.min(),\n",
    "        'epoch_min_cost': model_costs.loss.idxmin() + 1,\n",
    "        'min_cost': model_costs.val_loss.min(),\n",
    "        'epoch_min_cost': model_costs.val_loss.idxmin() + 1,\n",
    "        'roc_auc': val_roc_auc,\n",
    "        'avg_prec_score': val_avg_prec_score,\n",
    "        'brier_score': val_brier_score\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": \"Basic estimation for codes development.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='var_assessment'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assess how uncertain are performance metrics from neural networks applied to this empirical context, loops of estimations will be executed, so averaging of results is able to provide an estimate for standard deviation of performance metrics evaluated on validation data.\n",
    "<br>\n",
    "<br>\n",
    "In addition to the development of codes for estimation loops, another outcome from this section will be a class $keras\\_nn$ for neural network estimations based on Tensorflow and Keras funcions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1000\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': 1,\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = None\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_roc_auc = []\n",
    "val_avg_prec_score = []\n",
    "val_brier_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mEstimation progress:\u001b[0m [---------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of estimations:\u001b[0m 1000.\n",
      "\n",
      "\n",
      "\u001b[1mValidation ROC-AUC:\u001b[0m\n",
      "Average: 0.6328.\n",
      "Standard deviation : 0.1292.\n",
      "\n",
      "\n",
      "\u001b[1mValidation average precision score:\u001b[0m\n",
      "Average: 0.1003.\n",
      "Standard deviation : 0.0553.\n",
      "\n",
      "\n",
      "\u001b[1mValidation Brier score:\u001b[0m\n",
      "Average: 0.0128.\n",
      "Standard deviation : 0.0014.\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 100.05 minutes.\n",
      "Start time: 2020-12-22, 08:57:32\n",
      "End time: 2020-12-22, 10:37:36\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "bar = progressbar.ProgressBar(maxval=n_estimations,\n",
    "                              widgets=['\\033[1mEstimation progress:\\033[0m ',\n",
    "                              progressbar.Bar('-', '[', ']'), ' ',\n",
    "                              progressbar.Percentage()])\n",
    "\n",
    "bar.start()\n",
    "\n",
    "# Loop over estimations:\n",
    "for t in range(n_estimations):\n",
    "    # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "    model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                     output_activation = output_activation, cost_function = cost_function,\n",
    "                     num_epochs = num_epochs, batch_size = batch_size,\n",
    "                     default_adam = default_adam,\n",
    "                     regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "    # Training the model:\n",
    "    model.run(train_inputs = X_train, train_output = y_train,\n",
    "              val_inputs = X_val, val_output = y_val,\n",
    "              verbose = 0)\n",
    "    \n",
    "    # Performance metrics on validation data:\n",
    "    val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "    \n",
    "    bar.update(t+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "print('\\033[1mNumber of estimations:\\033[0m {0}.'.format(n_estimations))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mValidation ROC-AUC:\\033[0m')\n",
    "print('Average: {0}.'.format(round(np.nanmean(val_roc_auc), 4)))\n",
    "print('Standard deviation : {0}.'.format(round(np.nanstd(val_roc_auc), 4)))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mValidation average precision score:\\033[0m')\n",
    "print('Average: {0}.'.format(round(np.nanmean(val_avg_prec_score), 4)))\n",
    "print('Standard deviation : {0}.'.format(round(np.nanstd(val_avg_prec_score), 4)))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mValidation Brier score:\\033[0m')\n",
    "print('Average: {0}.'.format(round(np.nanmean(val_brier_score), 4)))\n",
    "print('Standard deviation : {0}.'.format(round(np.nanstd(val_brier_score), 4)))\n",
    "print('\\n')\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + nn_start_time.strftime('%Y-%m-%d') + ', ' + nn_start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + nn_end_time.strftime('%Y-%m-%d') + ', ' + nn_end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'validation',\n",
    "        'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(val_brier_score),\n",
    "        'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(val_brier_score)\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": \"Estimation loop for variability assessment.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='architecture'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will try on several distinct designs for the model architecture, using different values for their parameters. The setting for these tests is given by:\n",
    "* Random samples of training and validation data.\n",
    "* Cross-entropy cost function, rectified linear unit and sigmoid activation functions for hidden and output neurons, respectively.\n",
    "* Default mini-batch size (from Tensorflow and Keras) and 10 epochs of training.\n",
    "* Adam optimizer for model estimation (non-fixed and parameter-specific learning rates).\n",
    "* No regularization, no dropout and no early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, only neurons for a single hidden layer will be defined. The designs to be explored are the following, where $J_1$ is the number of neurons in the unique hidden layer:\n",
    "1. Number of neurons between number of inputs and number of outputs:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\alpha*(num\\_inputs + num\\_outputs)\n",
    "\\end{equation}\n",
    "<br>\n",
    "For $\\alpha \\in \\{0.1, 0.2, ..., 0.9\\}$.\n",
    "<br>\n",
    "<br>\n",
    "2. Rule-of-thumb considering the number of observations:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\frac{num\\_obs}{\\alpha*(num\\_inputs + num\\_outputs)}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $\\alpha \\in \\{2, 3, ..., 10\\}$.\n",
    "<br>\n",
    "<br>\n",
    "3. Concave functions of the product between number of inputs and number of outputs:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\sqrt{num\\_inputs*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\log(num\\_inputs*num\\_outputs)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once $J_1$ has been defined, further hidden layers will be tested, and the number of their neurons will follow the same strategy implemented for the initial single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neurons_single_hidden_layer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons for a single hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = None\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hidden layer and J1 between number of inputs and number of outputs:\n",
    "architectures = [{1: {'neurons': int(np.floor((X_train.shape[1] + 1)*q)),\n",
    "                      'activation': 'relu',\n",
    "                      'dropout_param': 0}} for q in [(i + 1)/10 for i in range(10) if (i + 1)/10 < 1]]\n",
    "\n",
    "architectures_def = ['One hidden layer: J1 = (num_inputs + num_outputs)*{0}'.format(q) for q in\n",
    "                     [(i + 1)/10 for i in range(10) if (i + 1)/10 < 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative rule-of-thumb for the J1 in the hidden layer:\n",
    "for q in [2, 4, 6]:\n",
    "    if int(np.floor(X_train.shape[0]/(q*(X_train.shape[1] + 1)))) > 0:\n",
    "        architectures.append({1: {'neurons': int(np.floor(X_train.shape[0]/(q*(X_train.shape[1] + 1)))),\n",
    "                                  'activation': 'relu',\n",
    "                                  'dropout_param': 0}})\n",
    "        architectures_def.append('One hidden layer: J1 = num_obs/({0}*(num_inputs + num_outputs))'.format(q))\n",
    "\n",
    "# Squared-root of the product between the number of inputs and the number of outputs:\n",
    "architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('One hidden layer: J1 = sqrt(num_inputs*num_outputs)')\n",
    "\n",
    "# Natural logarithm of the product between the number of inputs and the number of outputs:\n",
    "architectures.append({1: {'neurons': int(np.log(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('One hidden layer: J1 = log(num_inputs*num_outputs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: {'neurons': 209, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 419, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 629, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 839, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 1049, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 1258, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 1468, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 1678, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 1888, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 4, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 2, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 1, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 7, 'activation': 'relu', 'dropout_param': 0}}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 23.5 minutes.\n",
      "Start time: 2020-12-26, 20:23:46\n",
      "End time: 2020-12-26, 20:47:16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(architectures),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over architectures:\n",
    "for a in range(len(architectures)):\n",
    "# indices = [12,13]\n",
    "# for a in indices:\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = architectures[a], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(architectures[a]),\n",
    "            'num_hidden_neurons': [architectures[a][l]['neurons'] for l in architectures[a].keys()],\n",
    "            'hidden_activations': [architectures[a][l]['activation'] for l in architectures[a].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [architectures[a][l]['dropout_param'] for l in architectures[a].keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": architectures_def[a]\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(a+1)\n",
    "#     test_bar.update(indices.index(a)+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1609025026</td>\n",
       "      <td>J1=sqrt(num_inputs*num_outputs)</td>\n",
       "      <td>45</td>\n",
       "      <td>0.860571</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>0.240236</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>56.479620</td>\n",
       "      <td>7.731185</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1608940658</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.1</td>\n",
       "      <td>209</td>\n",
       "      <td>0.850727</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.224068</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>65.721111</td>\n",
       "      <td>6.337948</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1608942382</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.2</td>\n",
       "      <td>419</td>\n",
       "      <td>0.835747</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.216742</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>48.314574</td>\n",
       "      <td>7.394535</td>\n",
       "      <td>50.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1608945427</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.3</td>\n",
       "      <td>629</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.196370</td>\n",
       "      <td>0.034508</td>\n",
       "      <td>39.630446</td>\n",
       "      <td>5.690637</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1608955195</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.5</td>\n",
       "      <td>1049</td>\n",
       "      <td>0.830936</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.159038</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>43.611771</td>\n",
       "      <td>3.916244</td>\n",
       "      <td>117.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1608970776</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.7</td>\n",
       "      <td>1468</td>\n",
       "      <td>0.829818</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.162789</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>38.765363</td>\n",
       "      <td>6.099423</td>\n",
       "      <td>165.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1608949465</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.4</td>\n",
       "      <td>839</td>\n",
       "      <td>0.828557</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.183143</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>42.062456</td>\n",
       "      <td>5.323730</td>\n",
       "      <td>80.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1608962237</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.6</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.828069</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>0.160903</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>35.748432</td>\n",
       "      <td>5.111314</td>\n",
       "      <td>142.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1608990410</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.8</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.827038</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>46.701436</td>\n",
       "      <td>6.317679</td>\n",
       "      <td>184.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1609001472</td>\n",
       "      <td>J1=(num_inputs+num_outputs)*0.9</td>\n",
       "      <td>1888</td>\n",
       "      <td>0.825239</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.156171</td>\n",
       "      <td>0.030072</td>\n",
       "      <td>43.851261</td>\n",
       "      <td>5.193195</td>\n",
       "      <td>211.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1609025769</td>\n",
       "      <td>J1=log(num_inputs*num_outputs)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.810927</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>0.211897</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>12.248176</td>\n",
       "      <td>6.609672</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1609019638</td>\n",
       "      <td>J1=num_obs/(2*(num_inputs+num_outputs))</td>\n",
       "      <td>4</td>\n",
       "      <td>0.760527</td>\n",
       "      <td>0.095296</td>\n",
       "      <td>0.187775</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>7.980712</td>\n",
       "      <td>4.275049</td>\n",
       "      <td>12.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1609020364</td>\n",
       "      <td>J1=num_obs/(4*(num_inputs+num_outputs))</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704994</td>\n",
       "      <td>0.132196</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.065313</td>\n",
       "      <td>5.332957</td>\n",
       "      <td>2.176018</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1609020994</td>\n",
       "      <td>J1=num_obs/(6*(num_inputs+num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>0.654473</td>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>4.655126</td>\n",
       "      <td>1.934807</td>\n",
       "      <td>9.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                             architecture  num_neurons  \\\n",
       "12    1609025026          J1=sqrt(num_inputs*num_outputs)           45   \n",
       "0     1608940658          J1=(num_inputs+num_outputs)*0.1          209   \n",
       "1     1608942382          J1=(num_inputs+num_outputs)*0.2          419   \n",
       "2     1608945427          J1=(num_inputs+num_outputs)*0.3          629   \n",
       "4     1608955195          J1=(num_inputs+num_outputs)*0.5         1049   \n",
       "6     1608970776          J1=(num_inputs+num_outputs)*0.7         1468   \n",
       "3     1608949465          J1=(num_inputs+num_outputs)*0.4          839   \n",
       "5     1608962237          J1=(num_inputs+num_outputs)*0.6         1258   \n",
       "7     1608990410          J1=(num_inputs+num_outputs)*0.8         1678   \n",
       "8     1609001472          J1=(num_inputs+num_outputs)*0.9         1888   \n",
       "13    1609025769           J1=log(num_inputs*num_outputs)            7   \n",
       "9     1609019638  J1=num_obs/(2*(num_inputs+num_outputs))            4   \n",
       "10    1609020364  J1=num_obs/(4*(num_inputs+num_outputs))            2   \n",
       "11    1609020994  J1=num_obs/(6*(num_inputs+num_outputs))            1   \n",
       "\n",
       "    avg_roc_auc  std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  \\\n",
       "12     0.860571     0.015237  0.240236  0.031074      56.479620    7.731185   \n",
       "0      0.850727     0.012944  0.224068  0.035353      65.721111    6.337948   \n",
       "1      0.835747     0.017298  0.216742  0.029311      48.314574    7.394535   \n",
       "2      0.832776     0.021014  0.196370  0.034508      39.630446    5.690637   \n",
       "4      0.830936     0.019053  0.159038  0.040610      43.611771    3.916244   \n",
       "6      0.829818     0.021406  0.162789  0.026689      38.765363    6.099423   \n",
       "3      0.828557     0.019698  0.183143  0.034401      42.062456    5.323730   \n",
       "5      0.828069     0.023164  0.160903  0.031480      35.748432    5.111314   \n",
       "7      0.827038     0.017709  0.162420  0.025709      46.701436    6.317679   \n",
       "8      0.825239     0.018819  0.156171  0.030072      43.851261    5.193195   \n",
       "13     0.810927     0.066208  0.211897  0.032059      12.248176    6.609672   \n",
       "9      0.760527     0.095296  0.187775  0.043923       7.980712    4.275049   \n",
       "10     0.704994     0.132196  0.142123  0.065313       5.332957    2.176018   \n",
       "11     0.654473     0.140592  0.106717  0.055157       4.655126    1.934807   \n",
       "\n",
       "    running_time  \n",
       "12         12.37  \n",
       "0          28.73  \n",
       "1          50.73  \n",
       "2          67.28  \n",
       "4         117.35  \n",
       "6         165.97  \n",
       "3          80.25  \n",
       "5         142.30  \n",
       "7         184.35  \n",
       "8         211.15  \n",
       "13         11.12  \n",
       "9          12.08  \n",
       "10         10.50  \n",
       "11          9.33  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_neurons = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over architectures with a single hidden layer:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          'Testing architectures. One hidden layer' in model_assessment[e]['comment']]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split('One hidden layer: ')[1].replace(' ', ''))\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'][0])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by architecture with a single hidden layer:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_neurons': num_neurons,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBest architecture based on average ROC_AUC:\u001b[0m\n",
      " Numberofneurons=sqrt(num_inputs*num_outputs).\n",
      "\u001b[1mBest architecture based on std ROC_AUC:\u001b[0m\n",
      " Numberofneurons=(num_inputs+num_outputs)*0.1.\n",
      "\n",
      "\n",
      "\u001b[1mBest architecture based on avg precision score:\u001b[0m\n",
      " Numberofneurons=sqrt(num_inputs*num_outputs).\n",
      "\u001b[1mBest architecture based on avg precision score:\u001b[0m\n",
      " Numberofneurons=(num_inputs+num_outputs)*0.8.\n",
      "\n",
      "\n",
      "\u001b[1mBest architecture based on ratio between avg and std ROC-AUC:\u001b[0m\n",
      " Numberofneurons=(num_inputs+num_outputs)*0.1.\n",
      "\u001b[1mBest architecture based on ratio between avg and std ROC-AUC:\u001b[0m\n",
      " Numberofneurons=sqrt(num_inputs*num_outputs).\n",
      "\n",
      "\n",
      "\u001b[1mBest architecture based on running time:\u001b[0m\n",
      " Numberofneurons=num_obs/(6*(num_inputs+num_outputs)).\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mBest architecture based on average ROC_AUC:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.avg_roc_auc.idxmax(), :].architecture))\n",
    "print('\\033[1mBest architecture based on std ROC_AUC:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.std_roc_auc.idxmin(), :].architecture))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mBest architecture based on avg precision score:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.avg_prec.idxmax(), :].architecture))\n",
    "print('\\033[1mBest architecture based on avg precision score:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.std_prec.idxmin(), :].architecture))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mBest architecture based on ratio between avg and std ROC-AUC:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.ratio_roc_auc.idxmax(), :].architecture))\n",
    "print('\\033[1mBest architecture based on ratio between avg and std ROC-AUC:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.ratio_prec.idxmax(), :].architecture))\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mBest architecture based on running time:\\033[0m\\n {0}.'.format(\n",
    "    metrics.iloc[metrics.running_time.idxmin(), :].architecture))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neurons_two_hidden_layers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons for two hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assessment of results from above has shown that the following rules for defining the number of neurons lead to the best expected outcomes:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J = \\sqrt{num\\_inputs*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Which has the highest average ROC-AUC and average precision score with a reasonable running time. Also:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J = 0.1*(num\\_inputs + num\\_outputs)\n",
    "\\end{equation}\n",
    "<br>\n",
    "Has the second highest average ROC-AUC and average precision score, besides of the lowest standard deviation of ROC-AUC. Consequently, in order to assess impacts on outcomes of the addition of a second hidden layer, two different architectures will be tested:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\sqrt{num\\_inputs*J_2}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = \\sqrt{J_1*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Using both equations:\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = num\\_inputs^{2/3}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = num\\_inputs^{1/3}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "And the alternative:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = (num\\_inputs + J_2)*0.1\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = (J_1 + num\\_outputs)*0.1\n",
    "\\end{equation}\n",
    "<br>\n",
    "Using both equations:\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\frac{0.1*num\\_inputs + 0.01*num\\_outputs}{0.99}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = (J_1 + num\\_outputs)*0.1\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "In addition to these, alternatives that do not define simultaneously $J_1$ and $J_2$ are also going to be tested. While $J_1$ follows picked definitions, $J_2$ is merely given by the following options: $J_2 = J_1/2$ or $J_2 = J_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = None\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden layers and number of neurons between number of inputs and number of outputs:\n",
    "architectures = [{1: {'neurons': int(((0.1*X_train.shape[1]) + (0.01*1))/0.99),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                  2: {'neurons': int((int(((0.1*X_train.shape[1]) + (0.01*1))/0.99) + 1)*0.1),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}]\n",
    "architectures_def = ['Two hidden layers: J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_outputs)*0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squared-root of the product between the number of inputs and the number of outputs:\n",
    "architectures.append({1: {'neurons': int(X_train.shape[1]**(2/3)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(X_train.shape[1]**(1/3)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Two hidden layers: J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + num_outputs)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative presentations of the above architectures:\n",
    "architectures.append({1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1/2)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Two hidden layers: J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2')\n",
    "\n",
    "architectures.append({1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Two hidden layers: J1 = (num_inputs + num_outputs)*0.1, J2 = J1')\n",
    "\n",
    "architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2')\n",
    "\n",
    "architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: {'neurons': 211, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 21, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 163, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 12, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 209, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 104, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 209, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 209, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 45.08 minutes.\n",
      "Start time: 2021-01-02, 15:40:48\n",
      "End time: 2021-01-02, 16:25:53\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(architectures),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over architectures:\n",
    "for a in range(len(architectures)):\n",
    "# indices = [3, 5]\n",
    "# for a in indices:\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = architectures[a], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(architectures[a]),\n",
    "            'num_hidden_neurons': [architectures[a][l]['neurons'] for l in architectures[a].keys()],\n",
    "            'hidden_activations': [architectures[a][l]['activation'] for l in architectures[a].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [architectures[a][l]['dropout_param'] for l in architectures[a].keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg__roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg__avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg__brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": architectures_def[a]\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(a+1)\n",
    "#     test_bar.update(indices.index(a)+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1609598769</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>0.868335</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.262224</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>63.260803</td>\n",
       "      <td>7.967559</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1609025026</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs)</td>\n",
       "      <td>1</td>\n",
       "      <td>[45]</td>\n",
       "      <td>0.860571</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>0.240236</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>56.479620</td>\n",
       "      <td>7.731185</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1609614745</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 45]</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.216020</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>41.268569</td>\n",
       "      <td>9.845743</td>\n",
       "      <td>13.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1608940658</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>0.850727</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.224068</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>65.721111</td>\n",
       "      <td>6.337948</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1608942382</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[419]</td>\n",
       "      <td>0.835747</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.216742</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>48.314574</td>\n",
       "      <td>7.394535</td>\n",
       "      <td>50.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1608945427</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>[629]</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.196370</td>\n",
       "      <td>0.034508</td>\n",
       "      <td>39.630446</td>\n",
       "      <td>5.690637</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1608955195</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[1049]</td>\n",
       "      <td>0.830936</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.159038</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>43.611771</td>\n",
       "      <td>3.916244</td>\n",
       "      <td>117.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1608970776</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>[1468]</td>\n",
       "      <td>0.829818</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.162789</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>38.765363</td>\n",
       "      <td>6.099423</td>\n",
       "      <td>165.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1608949465</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>[839]</td>\n",
       "      <td>0.828557</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.183143</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>42.062456</td>\n",
       "      <td>5.323730</td>\n",
       "      <td>80.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1608962237</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>[1258]</td>\n",
       "      <td>0.828069</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>0.160903</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>35.748432</td>\n",
       "      <td>5.111314</td>\n",
       "      <td>142.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1608990410</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>[1678]</td>\n",
       "      <td>0.827038</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>46.701436</td>\n",
       "      <td>6.317679</td>\n",
       "      <td>184.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1609001472</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>[1888]</td>\n",
       "      <td>0.825239</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.156171</td>\n",
       "      <td>0.030072</td>\n",
       "      <td>43.851261</td>\n",
       "      <td>5.193195</td>\n",
       "      <td>211.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1609596978</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2</td>\n",
       "      <td>2</td>\n",
       "      <td>[209, 104]</td>\n",
       "      <td>0.824862</td>\n",
       "      <td>0.036737</td>\n",
       "      <td>0.175510</td>\n",
       "      <td>0.035546</td>\n",
       "      <td>22.453182</td>\n",
       "      <td>4.937549</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1609025769</td>\n",
       "      <td>J1 = log(num_inputs*num_outputs)</td>\n",
       "      <td>1</td>\n",
       "      <td>[7]</td>\n",
       "      <td>0.810927</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>0.211897</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>12.248176</td>\n",
       "      <td>6.609672</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1609612848</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1, J2 = J1</td>\n",
       "      <td>2</td>\n",
       "      <td>[209, 209]</td>\n",
       "      <td>0.796545</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>0.153939</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>26.545657</td>\n",
       "      <td>7.948292</td>\n",
       "      <td>31.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1609019638</td>\n",
       "      <td>J1 = num_obs/(2*(num_inputs + num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.760527</td>\n",
       "      <td>0.095296</td>\n",
       "      <td>0.187775</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>7.980712</td>\n",
       "      <td>4.275049</td>\n",
       "      <td>12.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1609100516</td>\n",
       "      <td>J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_out...</td>\n",
       "      <td>2</td>\n",
       "      <td>[211, 21]</td>\n",
       "      <td>0.708174</td>\n",
       "      <td>0.107685</td>\n",
       "      <td>0.126954</td>\n",
       "      <td>0.055727</td>\n",
       "      <td>6.576352</td>\n",
       "      <td>2.278163</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1609020364</td>\n",
       "      <td>J1 = num_obs/(4*(num_inputs + num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.704994</td>\n",
       "      <td>0.132196</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.065313</td>\n",
       "      <td>5.332957</td>\n",
       "      <td>2.176018</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1609102271</td>\n",
       "      <td>J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + num_o...</td>\n",
       "      <td>2</td>\n",
       "      <td>[163, 12]</td>\n",
       "      <td>0.668397</td>\n",
       "      <td>0.114250</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>5.850308</td>\n",
       "      <td>1.868074</td>\n",
       "      <td>20.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1609020994</td>\n",
       "      <td>J1 = num_obs/(6*(num_inputs + num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.654473</td>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>4.655126</td>\n",
       "      <td>1.934807</td>\n",
       "      <td>9.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                                       architecture  \\\n",
       "17    1609598769       J1 = sqrt(num_inputs*num_outputs), J2 = J1/2   \n",
       "12    1609025026                  J1 = sqrt(num_inputs*num_outputs)   \n",
       "19    1609614745         J1 = sqrt(num_inputs*num_outputs), J2 = J1   \n",
       "0     1608940658                J1 = (num_inputs + num_outputs)*0.1   \n",
       "1     1608942382                J1 = (num_inputs + num_outputs)*0.2   \n",
       "2     1608945427                J1 = (num_inputs + num_outputs)*0.3   \n",
       "4     1608955195                J1 = (num_inputs + num_outputs)*0.5   \n",
       "6     1608970776                J1 = (num_inputs + num_outputs)*0.7   \n",
       "3     1608949465                J1 = (num_inputs + num_outputs)*0.4   \n",
       "5     1608962237                J1 = (num_inputs + num_outputs)*0.6   \n",
       "7     1608990410                J1 = (num_inputs + num_outputs)*0.8   \n",
       "8     1609001472                J1 = (num_inputs + num_outputs)*0.9   \n",
       "16    1609596978     J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2   \n",
       "13    1609025769                   J1 = log(num_inputs*num_outputs)   \n",
       "18    1609612848       J1 = (num_inputs + num_outputs)*0.1, J2 = J1   \n",
       "9     1609019638        J1 = num_obs/(2*(num_inputs + num_outputs))   \n",
       "14    1609100516  J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_out...   \n",
       "10    1609020364        J1 = num_obs/(4*(num_inputs + num_outputs))   \n",
       "15    1609102271  J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + num_o...   \n",
       "11    1609020994        J1 = num_obs/(6*(num_inputs + num_outputs))   \n",
       "\n",
       "    num_layers num_neurons  avg_roc_auc  std_roc_auc  avg_prec  std_prec  \\\n",
       "17           2    [45, 22]     0.868335     0.013726  0.262224  0.032911   \n",
       "12           1        [45]     0.860571     0.015237  0.240236  0.031074   \n",
       "19           2    [45, 45]     0.851741     0.020639  0.216020  0.021940   \n",
       "0            1       [209]     0.850727     0.012944  0.224068  0.035353   \n",
       "1            1       [419]     0.835747     0.017298  0.216742  0.029311   \n",
       "2            1       [629]     0.832776     0.021014  0.196370  0.034508   \n",
       "4            1      [1049]     0.830936     0.019053  0.159038  0.040610   \n",
       "6            1      [1468]     0.829818     0.021406  0.162789  0.026689   \n",
       "3            1       [839]     0.828557     0.019698  0.183143  0.034401   \n",
       "5            1      [1258]     0.828069     0.023164  0.160903  0.031480   \n",
       "7            1      [1678]     0.827038     0.017709  0.162420  0.025709   \n",
       "8            1      [1888]     0.825239     0.018819  0.156171  0.030072   \n",
       "16           2  [209, 104]     0.824862     0.036737  0.175510  0.035546   \n",
       "13           1         [7]     0.810927     0.066208  0.211897  0.032059   \n",
       "18           2  [209, 209]     0.796545     0.030007  0.153939  0.019368   \n",
       "9            1         [4]     0.760527     0.095296  0.187775  0.043923   \n",
       "14           2   [211, 21]     0.708174     0.107685  0.126954  0.055727   \n",
       "10           1         [2]     0.704994     0.132196  0.142123  0.065313   \n",
       "15           2   [163, 12]     0.668397     0.114250  0.119342  0.063885   \n",
       "11           1         [1]     0.654473     0.140592  0.106717  0.055157   \n",
       "\n",
       "    ratio_roc_auc  ratio_prec  running_time  \n",
       "17      63.260803    7.967559         13.40  \n",
       "12      56.479620    7.731185         12.37  \n",
       "19      41.268569    9.845743         13.47  \n",
       "0       65.721111    6.337948         28.73  \n",
       "1       48.314574    7.394535         50.73  \n",
       "2       39.630446    5.690637         67.28  \n",
       "4       43.611771    3.916244        117.35  \n",
       "6       38.765363    6.099423        165.97  \n",
       "3       42.062456    5.323730         80.25  \n",
       "5       35.748432    5.111314        142.30  \n",
       "7       46.701436    6.317679        184.35  \n",
       "8       43.851261    5.193195        211.15  \n",
       "16      22.453182    4.937549         29.85  \n",
       "13      12.248176    6.609672         11.12  \n",
       "18      26.545657    7.948292         31.60  \n",
       "9        7.980712    4.275049         12.08  \n",
       "14       6.576352    2.278163         27.00  \n",
       "10       5.332957    2.176018         10.50  \n",
       "15       5.850308    1.868074         20.77  \n",
       "11       4.655126    1.934807          9.33  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over architectures:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing architectures. One hidden layer' in model_assessment[e]['comment']) |\n",
    "          ('Testing architectures. Two hidden layers' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by architecture with two hidden layers:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='neurons_three_hidden_layers'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons for three hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second assessment of results has shown that the following rule for defining the number of neurons using two hidden layers imply the best results:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J = \\sqrt{num\\_inputs*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "The best specification so far applies this rule for neurons ($J_1$) in the first hidden layer, while the number of neurons in the second hidden layer is given by $J_2 = J_1/2$. However, another formulations will also be tested here. So, these are the architectures for experiments:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\sqrt{num\\_inputs*J_2}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = \\sqrt{J_1*J_3}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_3 = \\sqrt{J_2*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Solving the system:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = num\\_inputs^{3/4}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = num\\_inputs^{1/2}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_3 = num\\_inputs^{1/4}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Additionally, the following specifications will also be used:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\sqrt{num\\_inputs*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = J_1/2\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_3 = J_1/4\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "And:\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_1 = \\sqrt{num\\_inputs*num\\_outputs}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_2 = J_1\n",
    "\\end{equation}\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle J_3 = J_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = None\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squared-root of the product between the number of inputs and the number of outputs:\n",
    "architectures = [{1: {'neurons': int(X_train.shape[1]**(3/4)),\n",
    "                      'activation': 'relu',\n",
    "                      'dropout_param': 0},\n",
    "                  2: {'neurons': int(X_train.shape[1]**(1/2)),\n",
    "                      'activation': 'relu',\n",
    "                      'dropout_param': 0},\n",
    "                  3: {'neurons': int(X_train.shape[1]**(1/4)),\n",
    "                      'activation': 'relu',\n",
    "                      'dropout_param': 0}}]\n",
    "architectures_def = ['Three hidden layers: J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + J3), J3 = sqrt(J2 + num_outputs)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative presentations of the above architectures:\n",
    "architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      3: {'neurons': int(np.sqrt(X_train.shape[1]*1)/4),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Three hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2, J3 = J1/4')\n",
    "\n",
    "architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      3: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}})\n",
    "architectures_def.append('Three hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1, J3 = J1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: {'neurons': 309, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  3: {'neurons': 6, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'relu', 'dropout_param': 0},\n",
       "  3: {'neurons': 11, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  3: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 74.62 minutes.\n",
      "Start time: 2021-01-04, 23:07:22\n",
      "End time: 2021-01-05, 00:21:59\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(architectures_def),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over architectures:\n",
    "for a in range(len(architectures)):\n",
    "# indices = [3, 5]\n",
    "# for a in indices:\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = architectures[a], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(architectures[a]),\n",
    "            'num_hidden_neurons': [architectures[a][l]['neurons'] for l in architectures[a].keys()],\n",
    "            'hidden_activations': [architectures[a][l]['activation'] for l in architectures[a].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [architectures[a][l]['dropout_param'] for l in architectures[a].keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg__roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg__avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg__brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": architectures_def[a]\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(a+1)\n",
    "#     test_bar.update(indices.index(a)+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1609598769</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>0.868335</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.262224</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>63.260803</td>\n",
       "      <td>7.967559</td>\n",
       "      <td>13.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1609025026</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs)</td>\n",
       "      <td>1</td>\n",
       "      <td>[45]</td>\n",
       "      <td>0.860571</td>\n",
       "      <td>0.015237</td>\n",
       "      <td>0.240236</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>56.479620</td>\n",
       "      <td>7.731185</td>\n",
       "      <td>12.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1609614745</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 45]</td>\n",
       "      <td>0.851741</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.216020</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>41.268569</td>\n",
       "      <td>9.845743</td>\n",
       "      <td>13.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1608940658</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>0.850727</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.224068</td>\n",
       "      <td>0.035353</td>\n",
       "      <td>65.721111</td>\n",
       "      <td>6.337948</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1609815126</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[45, 22, 11]</td>\n",
       "      <td>0.844691</td>\n",
       "      <td>0.022947</td>\n",
       "      <td>0.197475</td>\n",
       "      <td>0.038794</td>\n",
       "      <td>36.809745</td>\n",
       "      <td>5.090319</td>\n",
       "      <td>14.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1608942382</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>[419]</td>\n",
       "      <td>0.835747</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.216742</td>\n",
       "      <td>0.029311</td>\n",
       "      <td>48.314574</td>\n",
       "      <td>7.394535</td>\n",
       "      <td>50.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1608945427</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>[629]</td>\n",
       "      <td>0.832776</td>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.196370</td>\n",
       "      <td>0.034508</td>\n",
       "      <td>39.630446</td>\n",
       "      <td>5.690637</td>\n",
       "      <td>67.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1609816012</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1, J3...</td>\n",
       "      <td>3</td>\n",
       "      <td>[45, 45, 45]</td>\n",
       "      <td>0.831545</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.043264</td>\n",
       "      <td>20.481481</td>\n",
       "      <td>3.930913</td>\n",
       "      <td>15.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1608955195</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[1049]</td>\n",
       "      <td>0.830936</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.159038</td>\n",
       "      <td>0.040610</td>\n",
       "      <td>43.611771</td>\n",
       "      <td>3.916244</td>\n",
       "      <td>117.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1608970776</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>[1468]</td>\n",
       "      <td>0.829818</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.162789</td>\n",
       "      <td>0.026689</td>\n",
       "      <td>38.765363</td>\n",
       "      <td>6.099423</td>\n",
       "      <td>165.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1608949465</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>[839]</td>\n",
       "      <td>0.828557</td>\n",
       "      <td>0.019698</td>\n",
       "      <td>0.183143</td>\n",
       "      <td>0.034401</td>\n",
       "      <td>42.062456</td>\n",
       "      <td>5.323730</td>\n",
       "      <td>80.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1608962237</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>[1258]</td>\n",
       "      <td>0.828069</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>0.160903</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>35.748432</td>\n",
       "      <td>5.111314</td>\n",
       "      <td>142.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1608990410</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>[1678]</td>\n",
       "      <td>0.827038</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.162420</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>46.701436</td>\n",
       "      <td>6.317679</td>\n",
       "      <td>184.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1609001472</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>[1888]</td>\n",
       "      <td>0.825239</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.156171</td>\n",
       "      <td>0.030072</td>\n",
       "      <td>43.851261</td>\n",
       "      <td>5.193195</td>\n",
       "      <td>211.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1609596978</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2</td>\n",
       "      <td>2</td>\n",
       "      <td>[209, 104]</td>\n",
       "      <td>0.824862</td>\n",
       "      <td>0.036737</td>\n",
       "      <td>0.175510</td>\n",
       "      <td>0.035546</td>\n",
       "      <td>22.453182</td>\n",
       "      <td>4.937549</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1609025769</td>\n",
       "      <td>J1 = log(num_inputs*num_outputs)</td>\n",
       "      <td>1</td>\n",
       "      <td>[7]</td>\n",
       "      <td>0.810927</td>\n",
       "      <td>0.066208</td>\n",
       "      <td>0.211897</td>\n",
       "      <td>0.032059</td>\n",
       "      <td>12.248176</td>\n",
       "      <td>6.609672</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1609612848</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1, J2 = J1</td>\n",
       "      <td>2</td>\n",
       "      <td>[209, 209]</td>\n",
       "      <td>0.796545</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>0.153939</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>26.545657</td>\n",
       "      <td>7.948292</td>\n",
       "      <td>31.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1609019638</td>\n",
       "      <td>J1 = num_obs/(2*(num_inputs + num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.760527</td>\n",
       "      <td>0.095296</td>\n",
       "      <td>0.187775</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>7.980712</td>\n",
       "      <td>4.275049</td>\n",
       "      <td>12.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1609100516</td>\n",
       "      <td>J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_out...</td>\n",
       "      <td>2</td>\n",
       "      <td>[211, 21]</td>\n",
       "      <td>0.708174</td>\n",
       "      <td>0.107685</td>\n",
       "      <td>0.126954</td>\n",
       "      <td>0.055727</td>\n",
       "      <td>6.576352</td>\n",
       "      <td>2.278163</td>\n",
       "      <td>27.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1609020364</td>\n",
       "      <td>J1 = num_obs/(4*(num_inputs + num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.704994</td>\n",
       "      <td>0.132196</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.065313</td>\n",
       "      <td>5.332957</td>\n",
       "      <td>2.176018</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1609102271</td>\n",
       "      <td>J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + num_o...</td>\n",
       "      <td>2</td>\n",
       "      <td>[163, 12]</td>\n",
       "      <td>0.668397</td>\n",
       "      <td>0.114250</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>5.850308</td>\n",
       "      <td>1.868074</td>\n",
       "      <td>20.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1609020994</td>\n",
       "      <td>J1 = num_obs/(6*(num_inputs + num_outputs))</td>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.654473</td>\n",
       "      <td>0.140592</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>4.655126</td>\n",
       "      <td>1.934807</td>\n",
       "      <td>9.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1609812442</td>\n",
       "      <td>J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + J3), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[309, 45, 6]</td>\n",
       "      <td>0.621042</td>\n",
       "      <td>0.147158</td>\n",
       "      <td>0.057626</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>4.220253</td>\n",
       "      <td>1.467587</td>\n",
       "      <td>44.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                                       architecture  \\\n",
       "17    1609598769       J1 = sqrt(num_inputs*num_outputs), J2 = J1/2   \n",
       "12    1609025026                  J1 = sqrt(num_inputs*num_outputs)   \n",
       "19    1609614745         J1 = sqrt(num_inputs*num_outputs), J2 = J1   \n",
       "0     1608940658                J1 = (num_inputs + num_outputs)*0.1   \n",
       "21    1609815126  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2, ...   \n",
       "1     1608942382                J1 = (num_inputs + num_outputs)*0.2   \n",
       "2     1608945427                J1 = (num_inputs + num_outputs)*0.3   \n",
       "22    1609816012  J1 = sqrt(num_inputs*num_outputs), J2 = J1, J3...   \n",
       "4     1608955195                J1 = (num_inputs + num_outputs)*0.5   \n",
       "6     1608970776                J1 = (num_inputs + num_outputs)*0.7   \n",
       "3     1608949465                J1 = (num_inputs + num_outputs)*0.4   \n",
       "5     1608962237                J1 = (num_inputs + num_outputs)*0.6   \n",
       "7     1608990410                J1 = (num_inputs + num_outputs)*0.8   \n",
       "8     1609001472                J1 = (num_inputs + num_outputs)*0.9   \n",
       "16    1609596978     J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2   \n",
       "13    1609025769                   J1 = log(num_inputs*num_outputs)   \n",
       "18    1609612848       J1 = (num_inputs + num_outputs)*0.1, J2 = J1   \n",
       "9     1609019638        J1 = num_obs/(2*(num_inputs + num_outputs))   \n",
       "14    1609100516  J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_out...   \n",
       "10    1609020364        J1 = num_obs/(4*(num_inputs + num_outputs))   \n",
       "15    1609102271  J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + num_o...   \n",
       "11    1609020994        J1 = num_obs/(6*(num_inputs + num_outputs))   \n",
       "20    1609812442  J1 = sqrt(num_inputs*J2), J2 = sqrt(J1 + J3), ...   \n",
       "\n",
       "    num_layers   num_neurons  avg_roc_auc  std_roc_auc  avg_prec  std_prec  \\\n",
       "17           2      [45, 22]     0.868335     0.013726  0.262224  0.032911   \n",
       "12           1          [45]     0.860571     0.015237  0.240236  0.031074   \n",
       "19           2      [45, 45]     0.851741     0.020639  0.216020  0.021940   \n",
       "0            1         [209]     0.850727     0.012944  0.224068  0.035353   \n",
       "21           3  [45, 22, 11]     0.844691     0.022947  0.197475  0.038794   \n",
       "1            1         [419]     0.835747     0.017298  0.216742  0.029311   \n",
       "2            1         [629]     0.832776     0.021014  0.196370  0.034508   \n",
       "22           3  [45, 45, 45]     0.831545     0.040600  0.170068  0.043264   \n",
       "4            1        [1049]     0.830936     0.019053  0.159038  0.040610   \n",
       "6            1        [1468]     0.829818     0.021406  0.162789  0.026689   \n",
       "3            1         [839]     0.828557     0.019698  0.183143  0.034401   \n",
       "5            1        [1258]     0.828069     0.023164  0.160903  0.031480   \n",
       "7            1        [1678]     0.827038     0.017709  0.162420  0.025709   \n",
       "8            1        [1888]     0.825239     0.018819  0.156171  0.030072   \n",
       "16           2    [209, 104]     0.824862     0.036737  0.175510  0.035546   \n",
       "13           1           [7]     0.810927     0.066208  0.211897  0.032059   \n",
       "18           2    [209, 209]     0.796545     0.030007  0.153939  0.019368   \n",
       "9            1           [4]     0.760527     0.095296  0.187775  0.043923   \n",
       "14           2     [211, 21]     0.708174     0.107685  0.126954  0.055727   \n",
       "10           1           [2]     0.704994     0.132196  0.142123  0.065313   \n",
       "15           2     [163, 12]     0.668397     0.114250  0.119342  0.063885   \n",
       "11           1           [1]     0.654473     0.140592  0.106717  0.055157   \n",
       "20           3  [309, 45, 6]     0.621042     0.147158  0.057626  0.039266   \n",
       "\n",
       "    ratio_roc_auc  ratio_prec  running_time  \n",
       "17      63.260803    7.967559         13.40  \n",
       "12      56.479620    7.731185         12.37  \n",
       "19      41.268569    9.845743         13.47  \n",
       "0       65.721111    6.337948         28.73  \n",
       "21      36.809745    5.090319         14.75  \n",
       "1       48.314574    7.394535         50.73  \n",
       "2       39.630446    5.690637         67.28  \n",
       "22      20.481481    3.930913         15.12  \n",
       "4       43.611771    3.916244        117.35  \n",
       "6       38.765363    6.099423        165.97  \n",
       "3       42.062456    5.323730         80.25  \n",
       "5       35.748432    5.111314        142.30  \n",
       "7       46.701436    6.317679        184.35  \n",
       "8       43.851261    5.193195        211.15  \n",
       "16      22.453182    4.937549         29.85  \n",
       "13      12.248176    6.609672         11.12  \n",
       "18      26.545657    7.948292         31.60  \n",
       "9        7.980712    4.275049         12.08  \n",
       "14       6.576352    2.278163         27.00  \n",
       "10       5.332957    2.176018         10.50  \n",
       "15       5.850308    1.868074         20.77  \n",
       "11       4.655126    1.934807          9.33  \n",
       "20       4.220253    1.467587         44.73  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over architectures:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing architectures. One hidden layer' in model_assessment[e]['comment']) |\n",
    "          ('Testing architectures. Two hidden layers' in model_assessment[e]['comment']) |\n",
    "          ('Testing architectures. Three hidden layers' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by architecture with three hidden layers:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fitting_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a first inquirement into architecture definition, this section will try on several distinct values for fitting hyper-parameters: mini-batch size ($S$) and number of epochs ($T$). The setting for these tests is given by:\n",
    "* Random samples of training and validation data.\n",
    "* Cross-entropy cost function, rectified linear unit and sigmoid activation functions for hidden and output neurons, respectively.\n",
    "* *After tests for number of neurons and number of hidden layers, the architecture will be given by two hidden layers with the following number of neurons:*\n",
    "    * $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "    * $J_2 = J_1/2$.\n",
    "<br>\n",
    "<br>\n",
    "* Adam optimizer for model estimation (non-fixed and parameter-specific learning rates).\n",
    "* No regularization, no dropout and no early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mini-batch size**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy for experiments involves two tests:\n",
    "1. **Grid of mini-batch sizes:** a grid of different values will be sequentially tested, where all numbers are powers of 2: $S \\in [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]$. At each iteration, a collection of 100 estimations will be executed, so average and standard deviation of performance metrics can be stored, in addition to running time.\n",
    "2. **Velocity approach to mini-batch size definition**: for different values, validation performance will be plotted against aggregated running time at each epoch of training. The best mini-batch size $S^*$ according to this approach is that one which achieves its highest improvement in validation performance at the minimum running time. Only 1 estimation will take place here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of epochs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping will be used during final estimation where performance metrics are to be assessed using test data. Here, a study will help to understand which values may be appropriate for the number of epochs $T$, as a relatively large number of epochs, $T = 500$, are set for a single estimation. Then, model costs and performance metrics will be plotted against epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grid_mini_batch_sizes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid of mini-batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch_sizes = [2**i for i in range(1, 11)]\n",
    "mini_batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 237.02 minutes.\n",
      "Start time: 2021-01-06, 20:14:43\n",
      "End time: 2021-01-07, 00:11:44\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(mini_batch_sizes),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for b in range(len(mini_batch_sizes)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = mini_batch_sizes[b],\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': mini_batch_sizes[b],\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing values for mini-batch size using powers of 2.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(b+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>batch_sizes</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1609988509</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>0.825623</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.217563</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>71.549261</td>\n",
       "      <td>13.766690</td>\n",
       "      <td>5.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1609988822</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.825585</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.224429</td>\n",
       "      <td>0.016805</td>\n",
       "      <td>72.387168</td>\n",
       "      <td>13.355286</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1609988133</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>256</td>\n",
       "      <td>0.823035</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>0.202985</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>58.803477</td>\n",
       "      <td>13.214244</td>\n",
       "      <td>6.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1609986526</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>32</td>\n",
       "      <td>0.816262</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>0.183668</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>42.278426</td>\n",
       "      <td>6.451349</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1609987211</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>64</td>\n",
       "      <td>0.812532</td>\n",
       "      <td>0.013973</td>\n",
       "      <td>0.184694</td>\n",
       "      <td>0.018250</td>\n",
       "      <td>58.149015</td>\n",
       "      <td>10.120042</td>\n",
       "      <td>8.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1609987713</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>128</td>\n",
       "      <td>0.811479</td>\n",
       "      <td>0.018083</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>44.875439</td>\n",
       "      <td>10.946804</td>\n",
       "      <td>6.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1609985481</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>16</td>\n",
       "      <td>0.786144</td>\n",
       "      <td>0.026773</td>\n",
       "      <td>0.125664</td>\n",
       "      <td>0.039055</td>\n",
       "      <td>29.363367</td>\n",
       "      <td>3.217615</td>\n",
       "      <td>17.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1609983695</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.742617</td>\n",
       "      <td>0.049855</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>14.895576</td>\n",
       "      <td>2.746016</td>\n",
       "      <td>29.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1609980669</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.737145</td>\n",
       "      <td>0.057025</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.024682</td>\n",
       "      <td>12.926707</td>\n",
       "      <td>2.160003</td>\n",
       "      <td>50.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1609974883</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.719575</td>\n",
       "      <td>0.053166</td>\n",
       "      <td>0.038943</td>\n",
       "      <td>0.015230</td>\n",
       "      <td>13.534499</td>\n",
       "      <td>2.556971</td>\n",
       "      <td>96.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "8    1609988509  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "9    1609988822  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "7    1609988133  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4    1609986526  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5    1609987211  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "6    1609987713  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3    1609985481  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2    1609983695  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1    1609980669  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "0    1609974883  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "   num_layers num_neurons  batch_sizes  avg_roc_auc  std_roc_auc  avg_prec  \\\n",
       "8           2    [45, 22]          512     0.825623     0.011539  0.217563   \n",
       "9           2    [45, 22]         1024     0.825585     0.011405  0.224429   \n",
       "7           2    [45, 22]          256     0.823035     0.013996  0.202985   \n",
       "4           2    [45, 22]           32     0.816262     0.019307  0.183668   \n",
       "5           2    [45, 22]           64     0.812532     0.013973  0.184694   \n",
       "6           2    [45, 22]          128     0.811479     0.018083  0.194542   \n",
       "3           2    [45, 22]           16     0.786144     0.026773  0.125664   \n",
       "2           2    [45, 22]            8     0.742617     0.049855  0.066218   \n",
       "1           2    [45, 22]            4     0.737145     0.057025  0.053312   \n",
       "0           2    [45, 22]            2     0.719575     0.053166  0.038943   \n",
       "\n",
       "   std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "8  0.015804      71.549261   13.766690          5.20  \n",
       "9  0.016805      72.387168   13.355286          4.70  \n",
       "7  0.015361      58.803477   13.214244          6.27  \n",
       "4  0.028470      42.278426    6.451349         11.40  \n",
       "5  0.018250      58.149015   10.120042          8.35  \n",
       "6  0.017772      44.875439   10.946804          6.98  \n",
       "3  0.039055      29.363367    3.217615         17.42  \n",
       "2  0.024114      14.895576    2.746016         29.75  \n",
       "1  0.024682      12.926707    2.160003         50.43  \n",
       "0  0.015230      13.534499    2.556971         96.42  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing values for mini-batch size using powers of 2.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by mini-batch size:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'batch_sizes': batch_sizes,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='velocity_approach'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity approach to mini-batch size definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_batch_sizes = [2**i for i in range(1, 11)]\n",
    "mini_batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 4.72 minutes.\n",
      "Start time: 2021-01-10, 17:15:29\n",
      "End time: 2021-01-10, 17:20:13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(mini_batch_sizes),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for b in range(len(mini_batch_sizes)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "    epoch_performance = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = mini_batch_sizes[b],\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "        \n",
    "        # Running time and performance metrics on validation data by epoch of training:\n",
    "        epoch_performance.append(model.epoch_performance)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': mini_batch_sizes[b],\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score),\n",
    "            'avg_epoch_performance': {\n",
    "                'roc_auc': [sum(l)/len(l) for l in zip(*[d['epochroc_auc'] for d in epoch_performance])],\n",
    "                'avg_prec_score': [sum(l)/len(l) for l in zip(*[d['epochavg_prec_score'] for d in\n",
    "                                                                epoch_performance])],\n",
    "                'brier_score': [sum(l)/len(l) for l in zip(*[d['epochbrier_score'] for d in\n",
    "                                                             epoch_performance])],\n",
    "                'running_time': [sum(l)/len(l) for l in zip(*[d['running_time'] for d in epoch_performance])]\n",
    "            }\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Velocity approach to mini-batch size definition.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(b+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>batch_sizes</th>\n",
       "      <th>time_max_roc_auc</th>\n",
       "      <th>time_max_avg_prec</th>\n",
       "      <th>time_max_diff_roc_auc</th>\n",
       "      <th>time_max_diff_avg_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.787965</td>\n",
       "      <td>2.787965</td>\n",
       "      <td>0.892296</td>\n",
       "      <td>0.892296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>512</td>\n",
       "      <td>3.081902</td>\n",
       "      <td>3.081902</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>1.526358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>256</td>\n",
       "      <td>6.944381</td>\n",
       "      <td>6.944381</td>\n",
       "      <td>1.018974</td>\n",
       "      <td>1.891033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>64</td>\n",
       "      <td>7.641162</td>\n",
       "      <td>7.641162</td>\n",
       "      <td>2.115796</td>\n",
       "      <td>3.771834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>128</td>\n",
       "      <td>7.330622</td>\n",
       "      <td>7.330622</td>\n",
       "      <td>2.779716</td>\n",
       "      <td>4.328759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>32</td>\n",
       "      <td>8.348578</td>\n",
       "      <td>8.348578</td>\n",
       "      <td>4.049817</td>\n",
       "      <td>5.859880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>8</td>\n",
       "      <td>20.819293</td>\n",
       "      <td>20.819293</td>\n",
       "      <td>4.921750</td>\n",
       "      <td>4.921750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>4</td>\n",
       "      <td>32.816411</td>\n",
       "      <td>21.917382</td>\n",
       "      <td>6.840339</td>\n",
       "      <td>6.840339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>16</td>\n",
       "      <td>11.863147</td>\n",
       "      <td>10.700609</td>\n",
       "      <td>8.165246</td>\n",
       "      <td>10.700609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'architecture': {'num_hidden_layers': 2, 'num...</td>\n",
       "      <td>2</td>\n",
       "      <td>40.473972</td>\n",
       "      <td>61.520196</td>\n",
       "      <td>12.640060</td>\n",
       "      <td>61.520196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       estimation_id  batch_sizes  \\\n",
       "9  {'architecture': {'num_hidden_layers': 2, 'num...         1024   \n",
       "8  {'architecture': {'num_hidden_layers': 2, 'num...          512   \n",
       "7  {'architecture': {'num_hidden_layers': 2, 'num...          256   \n",
       "5  {'architecture': {'num_hidden_layers': 2, 'num...           64   \n",
       "6  {'architecture': {'num_hidden_layers': 2, 'num...          128   \n",
       "4  {'architecture': {'num_hidden_layers': 2, 'num...           32   \n",
       "2  {'architecture': {'num_hidden_layers': 2, 'num...            8   \n",
       "1  {'architecture': {'num_hidden_layers': 2, 'num...            4   \n",
       "3  {'architecture': {'num_hidden_layers': 2, 'num...           16   \n",
       "0  {'architecture': {'num_hidden_layers': 2, 'num...            2   \n",
       "\n",
       "   time_max_roc_auc  time_max_avg_prec  time_max_diff_roc_auc  \\\n",
       "9          2.787965           2.787965               0.892296   \n",
       "8          3.081902           3.081902               0.998291   \n",
       "7          6.944381           6.944381               1.018974   \n",
       "5          7.641162           7.641162               2.115796   \n",
       "6          7.330622           7.330622               2.779716   \n",
       "4          8.348578           8.348578               4.049817   \n",
       "2         20.819293          20.819293               4.921750   \n",
       "1         32.816411          21.917382               6.840339   \n",
       "3         11.863147          10.700609               8.165246   \n",
       "0         40.473972          61.520196              12.640060   \n",
       "\n",
       "   time_max_diff_avg_prec  \n",
       "9                0.892296  \n",
       "8                1.526358  \n",
       "7                1.891033  \n",
       "5                3.771834  \n",
       "6                4.328759  \n",
       "4                5.859880  \n",
       "2                4.921750  \n",
       "1                6.840339  \n",
       "3               10.700609  \n",
       "0               61.520196  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "batch_sizes = []\n",
    "time_max_roc_auc = []\n",
    "time_max_avg_prec = []\n",
    "time_max_diff_roc_auc = []\n",
    "time_max_diff_avg_prec = []\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if ('Velocity' in model_assessment[e]['comment'])]:\n",
    "    agg_times = list(np.cumsum(e['performance_metrics']['avg_epoch_performance']['running_time']))\n",
    "    roc_auc = e['performance_metrics']['avg_epoch_performance']['roc_auc']\n",
    "    avg_prec = e['performance_metrics']['avg_epoch_performance']['avg_prec_score']\n",
    "    diff_roc_auc = list(np.diff(roc_auc, prepend=np.NaN))\n",
    "    diff_avg_prec = list(np.diff(avg_prec, prepend=np.NaN))\n",
    "    \n",
    "    max_roc_auc = np.nanmax(roc_auc)\n",
    "    max_avg_prec = np.nanmax(avg_prec)\n",
    "    max_diff_roc_auc = np.nanmax(diff_roc_auc)\n",
    "    max_diff_avg_prec = np.nanmax(diff_avg_prec)\n",
    "\n",
    "    estimation_ids.append(e)\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    time_max_roc_auc.append(agg_times[roc_auc.index(max_roc_auc)])\n",
    "    time_max_avg_prec.append(agg_times[avg_prec.index(max_avg_prec)])\n",
    "    time_max_diff_roc_auc.append(agg_times[diff_roc_auc.index(max_diff_roc_auc)])\n",
    "    time_max_diff_avg_prec.append(agg_times[diff_avg_prec.index(max_diff_avg_prec)])\n",
    "    \n",
    "# Dataframe with performance metrics by mini-batch size:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'batch_sizes': batch_sizes,\n",
    "    'time_max_roc_auc': time_max_roc_auc,\n",
    "    'time_max_avg_prec': time_max_avg_prec,\n",
    "    'time_max_diff_roc_auc': time_max_diff_roc_auc,\n",
    "    'time_max_diff_avg_prec': time_max_diff_avg_prec\n",
    "})\n",
    "\n",
    "metrics.sort_values('time_max_diff_roc_auc', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='number_epochs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Results from tests for mini-batch size have indicated $S = 512$ as an appropriate value for this current learning task.* Besides, all further [settings](#fitting_params)<a href='#fitting_params'></a> previously discussed also apply here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 500\n",
    "es_param = None\n",
    "batch_size = 512\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 12.07 minutes.\n",
      "Start time: 2021-01-12, 12:26:38\n",
      "End time: 2021-01-12, 12:38:42\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "epoch_costs = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "val_roc_auc = []\n",
    "val_avg_prec_score = []\n",
    "val_brier_score = []\n",
    "epoch_performance = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for t in range(n_estimations):\n",
    "    # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "    model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                     output_activation = output_activation, cost_function = cost_function,\n",
    "                     num_epochs = num_epochs, batch_size = batch_size,\n",
    "                     default_adam = default_adam,\n",
    "                     regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "    # Training the model:\n",
    "    model.run(train_inputs = X_train, train_output = y_train,\n",
    "              val_inputs = X_val, val_output = y_val,\n",
    "              verbose = 0)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "\n",
    "    # Cost function by training epoch:\n",
    "    model_costs = model.model_costs\n",
    "    epoch_costs.append({'epoch': list(model_costs['epoch']),\n",
    "                        'loss': list(model_costs['loss']),\n",
    "                        'val_loss': list(model_costs['val_loss'])})\n",
    "\n",
    "    min_cost.append(model_costs.loss.min())\n",
    "    epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "    min_cost.append(model_costs.val_loss.min())\n",
    "    epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Running time and performance metrics on validation data by epoch of training:\n",
    "    epoch_performance.append(model.epoch_performance)\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'validation',\n",
    "        'epoch_costs': epoch_costs,\n",
    "        'avg_epoch_costs': {\n",
    "            'epoch': [sum(l)/len(l) for l in zip(*[d['epoch'] for d in epoch_costs])],\n",
    "            'loss': [sum(l)/len(l) for l in zip(*[d['loss'] for d in epoch_costs])],\n",
    "            'val_loss': [sum(l)/len(l) for l in zip(*[d['val_loss'] for d in epoch_costs])]\n",
    "        },\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(val_brier_score),\n",
    "        'std__roc_auc': np.nanstd(val_roc_auc),\n",
    "        'std__avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "        'std__brier_score': np.nanstd(val_brier_score),\n",
    "        'avg_epoch_performance': {\n",
    "            'roc_auc': [sum(l)/len(l) for l in zip(*[d['epochroc_auc'] for d in epoch_performance])],\n",
    "            'avg_prec_score': [sum(l)/len(l) for l in zip(*[d['epochavg_prec_score'] for d in\n",
    "                                                            epoch_performance])],\n",
    "            'brier_score': [sum(l)/len(l) for l in zip(*[d['epochbrier_score'] for d in\n",
    "                                                         epoch_performance])],\n",
    "            'running_time': [sum(l)/len(l) for l in zip(*[d['running_time'] for d in epoch_performance])]\n",
    "        }\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": '{0}. Assessing number of epochs by using a large value for it.'.format(model_architecture_def)\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [model_assessment[e] for e in model_assessment.keys() if\n",
    "            'Assessing number of epochs' in model_assessment[e]['comment']][0]\n",
    "\n",
    "# Cost function by training epoch:\n",
    "model_costs = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'loss': outcomes['performance_metrics']['avg_epoch_costs']['loss'],\n",
    "    'val_loss': outcomes['performance_metrics']['avg_epoch_costs']['val_loss']\n",
    "})\n",
    "\n",
    "epoch_performances = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'roc_auc': outcomes['performance_metrics']['avg_epoch_performance']['roc_auc'],\n",
    "    'avg_prec_score': outcomes['performance_metrics']['avg_epoch_performance']['avg_prec_score']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "loss = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Training cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "xaxis": "x",
         "y": [
          0.24477717280387878,
          0.06811131536960602,
          0.08548329770565033,
          0.08370263129472733,
          0.058369021862745285,
          0.05214221403002739,
          0.04953069984912872,
          0.04680463671684265,
          0.044182371348142624,
          0.041782476007938385,
          0.03773241490125656,
          0.035368554294109344,
          0.03440040722489357,
          0.031311217695474625,
          0.029856093227863312,
          0.028979068621993065,
          0.028283243998885155,
          0.026233552023768425,
          0.025212915614247322,
          0.02409248612821102,
          0.022900499403476715,
          0.0220304224640131,
          0.019830267876386642,
          0.01939256489276886,
          0.01899617165327072,
          0.01874668523669243,
          0.017597712576389313,
          0.0170671958476305,
          0.0164014995098114,
          0.015921708196401596,
          0.015122726559638977,
          0.01484921108931303,
          0.014240144751966,
          0.014008657075464725,
          0.013291832990944386,
          0.013000469654798508,
          0.012543916702270508,
          0.012020232155919075,
          0.011386502534151077,
          0.011305599473416805,
          0.010701444000005722,
          0.010536410845816135,
          0.009999439120292664,
          0.009695104323327541,
          0.009055109694600105,
          0.008715144358575344,
          0.008373654447495937,
          0.008191730827093124,
          0.007784673944115639,
          0.0076202391646802425,
          0.0073576089926064014,
          0.007270934525877237,
          0.007012750953435898,
          0.0067321183159947395,
          0.006473727524280548,
          0.006368528585880995,
          0.006073545664548874,
          0.005950694438070059,
          0.00571691058576107,
          0.005603264085948467,
          0.005245264619588852,
          0.005136491730809212,
          0.004867557901889086,
          0.004763577599078417,
          0.004598515573889017,
          0.004564597271382809,
          0.0044902777299284935,
          0.004343083593994379,
          0.004279251676052809,
          0.004142159596085548,
          0.004100983031094074,
          0.003988777287304401,
          0.003910996485501528,
          0.003771281335502863,
          0.0036349317524582148,
          0.003439616411924362,
          0.0033009489998221397,
          0.003099786816164851,
          0.003076001536101103,
          0.002951560541987419,
          0.003054801607504487,
          0.0028771841898560524,
          0.0027276375330984592,
          0.002540233079344034,
          0.0024521024897694588,
          0.002405685605481267,
          0.002305080648511648,
          0.0021342518739402294,
          0.0021335980854928493,
          0.002006778959184885,
          0.002000249922275543,
          0.0017310153925791383,
          0.0016169744776561856,
          0.0016101900255307555,
          0.0015814320649951696,
          0.00158692488912493,
          0.0014194948598742485,
          0.0014265242498368025,
          0.012696928344666958,
          0.002678269287571311,
          0.020288141444325447,
          0.18568289279937744,
          0.19276969134807587,
          0.12716278433799744,
          0.04404478147625923,
          0.04939469322562218,
          0.035081785172224045,
          0.02937379479408264,
          0.027624689042568207,
          0.025479784235358238,
          0.023307709023356438,
          0.021677380427718163,
          0.01990352012217045,
          0.018488792702555656,
          0.01754876598715782,
          0.016158342361450195,
          0.015435109846293926,
          0.014567211270332336,
          0.013858936727046967,
          0.013093473389744759,
          0.01239316537976265,
          0.011797488667070866,
          0.011077183298766613,
          0.010601431131362915,
          0.010154117830097675,
          0.009720981121063232,
          0.009335963986814022,
          0.009024553000926971,
          0.008741027675569057,
          0.008456856943666935,
          0.008234580047428608,
          0.007877446711063385,
          0.007588163949549198,
          0.008091123774647713,
          0.0070833307690918446,
          0.006652412470430136,
          0.00664158072322607,
          0.007203616667538881,
          0.006208500359207392,
          0.0058098589070141315,
          0.005542527884244919,
          0.005597855430096388,
          0.005624840967357159,
          0.006191416643559933,
          0.005236805882304907,
          0.0047203549183905125,
          0.004442019388079643,
          0.004301406908780336,
          0.004081333987414837,
          0.003964852541685104,
          0.0038029092829674482,
          0.0036803402472287416,
          0.00361206685192883,
          0.0034845841582864523,
          0.0033415008801966906,
          0.0032669659703969955,
          0.0031945351511240005,
          0.0030117800924926996,
          0.0028751487843692303,
          0.0027209522668272257,
          0.0027338755317032337,
          0.002600868931040168,
          0.0025402421597391367,
          0.002494171727448702,
          0.002420606091618538,
          0.00236816075630486,
          0.0022854104172438383,
          0.0022639427334070206,
          0.0021902078296989202,
          0.002175100613385439,
          0.0020813788287341595,
          0.002036268590018153,
          0.001983714522793889,
          0.0019526882097125053,
          0.0019038469763472676,
          0.0018566582584753633,
          0.0018393597565591335,
          0.00175278983078897,
          0.0017332758288830519,
          0.0017000716179609299,
          0.0017145434394478798,
          0.0015302901156246662,
          0.0014879517257213593,
          0.0013623692793771625,
          0.0013861560728400946,
          0.0012540578609332442,
          0.0012498523574322462,
          0.0012037974083796144,
          0.0012319913366809487,
          0.0010672956705093384,
          0.0009582113125361502,
          0.0008168754284270108,
          0.0007547496352344751,
          0.000750901410356164,
          0.0006996159208938479,
          0.0006661131046712399,
          0.000632587936706841,
          0.0006120189209468663,
          0.0006130337715148926,
          0.0005658981972374022,
          0.0005456377984955907,
          0.0005550090572796762,
          0.0005297622410580516,
          0.0005233939737081528,
          0.0005024438141845167,
          0.00048274570144712925,
          0.00044823193456977606,
          0.0004596470098476857,
          0.00042459406540729105,
          0.0004396597796585411,
          0.00040279875975102186,
          0.0003725608403328806,
          0.0003456824051681906,
          0.0003341937845107168,
          0.0003555430448614061,
          0.0003139588516205549,
          0.00028132242732681334,
          0.000322032836265862,
          0.00040263222763314843,
          0.000659600947983563,
          0.0030960177537053823,
          0.06226714327931404,
          0.16884368658065796,
          0.1288999319076538,
          0.054231613874435425,
          0.014905441552400589,
          0.010433271527290344,
          0.008237795904278755,
          0.007414720486849546,
          0.006518910638988018,
          0.005666585173457861,
          0.005064345896244049,
          0.00455495435744524,
          0.004134991206228733,
          0.0037668447475880384,
          0.0034871643874794245,
          0.003240986494347453,
          0.002993194852024317,
          0.0027900689747184515,
          0.002626248635351658,
          0.0024483189918100834,
          0.0023127298336476088,
          0.0021804976277053356,
          0.002007525647059083,
          0.0018476975383237004,
          0.0017106544692069292,
          0.0016130144940689206,
          0.0014676015125587583,
          0.0013681829441338778,
          0.0012487651547417045,
          0.0011756994063034654,
          0.0010793437249958515,
          0.0010201784316450357,
          0.0009401037241332233,
          0.0008903489797376096,
          0.0008285403600893915,
          0.0007821047911420465,
          0.0007320429431274533,
          0.0006973735871724784,
          0.000656464253552258,
          0.0006356833619065583,
          0.0006003814633004367,
          0.0005766174872405827,
          0.0005465916474349797,
          0.0005237457808107138,
          0.0005025725695304573,
          0.00048080048873089254,
          0.0004620800318662077,
          0.0004483081866055727,
          0.00042861432302743196,
          0.0004123681574128568,
          0.0003965345968026668,
          0.0003837888070847839,
          0.00036569731310009956,
          0.00035176522214896977,
          0.00034119075280614197,
          0.0003319647803436965,
          0.0003171768330503255,
          0.0003047455393243581,
          0.0002953929069917649,
          0.0002904346911236644,
          0.0002771391300484538,
          0.00026724234339781106,
          0.00025891372933983803,
          0.0002513834333512932,
          0.00024285531253553927,
          0.00022946852550376207,
          0.00022011998225934803,
          0.00020617691916413605,
          0.00019787138444371521,
          0.0001893390726763755,
          0.00018016441026702523,
          0.0001715237449388951,
          0.0001633984938962385,
          0.00015782486298121512,
          0.0001530651788925752,
          0.00014784153609070927,
          0.00014118153194431216,
          0.0001372745755361393,
          0.00013274885714054108,
          0.0001243111619260162,
          0.00011287403322057799,
          0.00010781000310089439,
          0.00010172222391702235,
          9.719203080749139e-05,
          9.219132334692404e-05,
          8.86301277205348e-05,
          8.499695832142606e-05,
          8.182737656170502e-05,
          7.845950312912464e-05,
          7.560435187770054e-05,
          7.269308844115585e-05,
          7.044531957944855e-05,
          6.816262612119317e-05,
          6.597298488486558e-05,
          6.402705184882507e-05,
          6.095883873058483e-05,
          5.815004260512069e-05,
          5.6019413023022935e-05,
          5.442670590127818e-05,
          5.260546458885074e-05,
          5.12396109115798e-05,
          4.970302325091325e-05,
          4.841231930186041e-05,
          4.699494093074463e-05,
          4.591252945829183e-05,
          4.4651937059825286e-05,
          4.352222822490148e-05,
          4.235524102114141e-05,
          4.109338624402881e-05,
          4.0101524064084515e-05,
          3.910916711902246e-05,
          3.802391802310012e-05,
          3.6943576560588554e-05,
          3.5904900869354606e-05,
          3.4855969715863466e-05,
          3.398709304747172e-05,
          3.328528691781685e-05,
          3.232707240385935e-05,
          3.147998359054327e-05,
          3.06609072140418e-05,
          2.9872717277612537e-05,
          2.9144173822714947e-05,
          2.8387850761646405e-05,
          2.7651714844978414e-05,
          2.697229319892358e-05,
          2.622981082822662e-05,
          2.5543422452756204e-05,
          2.495412809366826e-05,
          2.4299550204887055e-05,
          2.370641777815763e-05,
          2.3079212041920982e-05,
          2.256417428725399e-05,
          2.2012347471900284e-05,
          2.146905717381742e-05,
          2.0970228433725424e-05,
          2.040925573965069e-05,
          1.9884351786458865e-05,
          1.9430184693192132e-05,
          1.891642386908643e-05,
          1.8468897906132042e-05,
          1.800302015908528e-05,
          1.7569827832630835e-05,
          1.7137484974227846e-05,
          1.6747566405683756e-05,
          1.637128480069805e-05,
          1.598723974893801e-05,
          1.5645862731616944e-05,
          1.5241918845276814e-05,
          1.4882089089951478e-05,
          1.4522820492857136e-05,
          1.4219116565072909e-05,
          1.3893157301936299e-05,
          1.3619119272334501e-05,
          1.3259947081678547e-05,
          1.2992397387279198e-05,
          1.2671161130128894e-05,
          1.2411423995217774e-05,
          1.2114557648601476e-05,
          1.1860319318657275e-05,
          1.1605407962633763e-05,
          1.1328771506669e-05,
          1.1045032806578092e-05,
          1.07996220322093e-05,
          1.0538924470893107e-05,
          1.0324211871193256e-05,
          1.0068192750622984e-05,
          9.807677997741848e-06,
          9.643359589972533e-06,
          9.386425517732278e-06,
          9.18394925975008e-06,
          8.988406079879496e-06,
          8.768327461439185e-06,
          8.562419679947197e-06,
          8.365529538423289e-06,
          8.192220775526948e-06,
          8.018668268050533e-06,
          7.844156243663747e-06,
          7.677376743231434e-06,
          7.490611551475013e-06,
          7.314231879718136e-06,
          7.169815489760367e-06,
          6.9913776314933784e-06,
          6.847220902272966e-06,
          6.694157491438091e-06,
          6.53216511636856e-06,
          6.360169209074229e-06,
          6.238877176656388e-06,
          6.0793945522163995e-06,
          5.948485977569362e-06,
          5.817090823256876e-06,
          5.708512162527768e-06,
          5.564561433857307e-06,
          5.419031367637217e-06,
          5.287115527607966e-06,
          5.14612202096032e-06,
          5.057030648458749e-06,
          4.928755515720695e-06,
          4.82094264953048e-06,
          4.713541784440167e-06,
          4.611810254573356e-06,
          4.514379270403879e-06,
          4.431532943272032e-06,
          4.324228939367458e-06,
          4.208879545331001e-06,
          4.124424776819069e-06,
          4.026938768220134e-06,
          3.949564415961504e-06,
          3.854208443954121e-06,
          3.7848003557883203e-06,
          3.686246600409504e-06,
          3.594279860408278e-06,
          3.544868150129332e-06,
          3.46797241945751e-06,
          3.372891114850063e-06,
          3.308274926894228e-06,
          3.227238494218909e-06,
          3.153220632157172e-06,
          3.0835378765914356e-06,
          3.0185876767063746e-06,
          2.9432412702590227e-06,
          2.8911751996929524e-06,
          2.8173969894851325e-06,
          2.7551452603802318e-06,
          2.695839157240698e-06,
          2.6313368834962603e-06,
          2.5749361611815402e-06,
          2.5144599931081757e-06,
          2.4549503905291203e-06,
          2.40235840465175e-06,
          2.3578495529363863e-06,
          2.298078243256896e-06,
          2.2503925265482394e-06,
          2.198753691118327e-06,
          2.151616627088515e-06,
          2.1039825242041843e-06,
          2.0642946765292436e-06,
          2.0124091406614752e-06,
          1.9632545900094556e-06,
          1.919873739097966e-06,
          1.8883237089539762e-06,
          1.8465419771018787e-06,
          1.8037835616269149e-06,
          1.7628917703405023e-06,
          1.717576651572017e-06,
          1.6904155017982703e-06,
          1.6420410702266963e-06,
          1.6128952893268433e-06,
          1.5797468222444877e-06,
          1.545109057587979e-06,
          1.5096543393156026e-06,
          1.4755374877495342e-06,
          1.4481099697150057e-06,
          1.4157208170217928e-06,
          1.3823089375364361e-06,
          1.3545294450523215e-06,
          1.326092842646176e-06,
          1.2968871487828437e-06,
          1.2738939858536469e-06,
          1.2479100632845075e-06,
          1.219143427988456e-06,
          1.1925445733140805e-06,
          1.166476522485027e-06,
          1.139846403930278e-06,
          1.1242574373682146e-06,
          1.0949471516141784e-06,
          1.0731123438745271e-06,
          1.0525047855480807e-06,
          1.0274860642311978e-06,
          1.0125482958756038e-06,
          9.896369874695665e-07,
          9.697881750980741e-07,
          9.508171388006303e-07,
          9.333224397778395e-07,
          9.115327657127636e-07,
          8.933147910283878e-07,
          8.787901037976553e-07,
          8.633153925075021e-07,
          8.399437092521111e-07,
          8.247537834904506e-07
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "val_loss = %{y:.4f}",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "xaxis": "x",
         "y": [
          0.12495018541812897,
          0.06989356130361557,
          0.0652560293674469,
          0.06654969602823257,
          0.06514935940504074,
          0.06388038396835327,
          0.0637611672282219,
          0.06256065517663956,
          0.0631280392408371,
          0.06150833144783974,
          0.061584338545799255,
          0.06121031567454338,
          0.061395205557346344,
          0.06087050959467888,
          0.06082826852798462,
          0.061099544167518616,
          0.060878630727529526,
          0.0605696365237236,
          0.0607684887945652,
          0.06074950471520424,
          0.06050499156117439,
          0.06124543398618698,
          0.060801707208156586,
          0.06108374893665314,
          0.061397019773721695,
          0.061561040580272675,
          0.062049660831689835,
          0.06233809143304825,
          0.06281475722789764,
          0.06318206340074539,
          0.06369207799434662,
          0.0641411617398262,
          0.06473743915557861,
          0.06486285477876663,
          0.06587184220552444,
          0.06606604903936386,
          0.06680488586425781,
          0.06728903204202652,
          0.0682358667254448,
          0.0687197744846344,
          0.0695795938372612,
          0.07037686556577682,
          0.07106860727071762,
          0.0720786452293396,
          0.07295933365821838,
          0.07380273938179016,
          0.0740223228931427,
          0.0752478614449501,
          0.07604437321424484,
          0.07674206793308258,
          0.07743656635284424,
          0.07835857570171356,
          0.07901928573846817,
          0.08020133525133133,
          0.08027129620313644,
          0.08122796565294266,
          0.08234386891126633,
          0.08330143243074417,
          0.08317584544420242,
          0.08471373468637466,
          0.08620326966047287,
          0.08654267340898514,
          0.08802586793899536,
          0.08808872103691101,
          0.08933267742395401,
          0.0892803743481636,
          0.09066556394100189,
          0.09143435955047607,
          0.09148699790239334,
          0.09288015961647034,
          0.09409159421920776,
          0.09279133379459381,
          0.09595280140638351,
          0.09602466225624084,
          0.0966498926281929,
          0.09716524928808212,
          0.09904228150844574,
          0.09918558597564697,
          0.1001557856798172,
          0.10075734555721283,
          0.10121932625770569,
          0.10230981558561325,
          0.10413600504398346,
          0.10462751239538193,
          0.10588517040014267,
          0.10439170151948929,
          0.10690253227949142,
          0.10747924447059631,
          0.10865097492933273,
          0.10948564112186432,
          0.10911419987678528,
          0.11143632978200912,
          0.11207439005374908,
          0.11216221004724503,
          0.11333492398262024,
          0.11335441470146179,
          0.11487951129674911,
          0.11515985429286957,
          0.12046610563993454,
          0.11832582205533981,
          0.34946051239967346,
          0.11994977295398712,
          0.10445600748062134,
          0.09183643013238907,
          0.08389678597450256,
          0.07782869040966034,
          0.07165232300758362,
          0.0694577619433403,
          0.06890715658664703,
          0.06794696301221848,
          0.06743248552083969,
          0.0667920932173729,
          0.06658349186182022,
          0.06612695008516312,
          0.06581006199121475,
          0.06567231565713882,
          0.06552460044622421,
          0.06597232073545456,
          0.06635980308055878,
          0.0668783038854599,
          0.06827443093061447,
          0.06893753260374069,
          0.06994341313838959,
          0.07098285108804703,
          0.0717136412858963,
          0.07270678132772446,
          0.07352222502231598,
          0.07420985400676727,
          0.07510463148355484,
          0.07606165111064911,
          0.07703029364347458,
          0.07804112136363983,
          0.07900311052799225,
          0.08029812574386597,
          0.08105440437793732,
          0.0819818526506424,
          0.08338267356157303,
          0.08506027609109879,
          0.08537103235721588,
          0.08644925802946091,
          0.08743561059236526,
          0.08842199295759201,
          0.08927687257528305,
          0.09055547416210175,
          0.09106539934873581,
          0.09192216396331787,
          0.09295469522476196,
          0.09367235749959946,
          0.09471110999584198,
          0.09562740474939346,
          0.09639479219913483,
          0.0971299484372139,
          0.0978977307677269,
          0.09871053695678711,
          0.09961888939142227,
          0.10032675415277481,
          0.10169973969459534,
          0.10259759426116943,
          0.1034012958407402,
          0.10418941080570221,
          0.10490038990974426,
          0.10596922785043716,
          0.10655489563941956,
          0.10742330551147461,
          0.10802669078111649,
          0.10874325037002563,
          0.1092909500002861,
          0.11028758436441422,
          0.1107436940073967,
          0.1119486540555954,
          0.1123802661895752,
          0.11319362372159958,
          0.11369544267654419,
          0.1145172044634819,
          0.11492330580949783,
          0.11575829237699509,
          0.11617624759674072,
          0.11714500188827515,
          0.11756893992424011,
          0.11859775334596634,
          0.11874507367610931,
          0.12008809298276901,
          0.12084405869245529,
          0.12169093638658524,
          0.12248466908931732,
          0.1234363242983818,
          0.12418176233768463,
          0.12536659836769104,
          0.12580053508281708,
          0.12675237655639648,
          0.12729674577713013,
          0.12851470708847046,
          0.1290569007396698,
          0.1297989934682846,
          0.13036474585533142,
          0.13118790090084076,
          0.13174037635326385,
          0.13249671459197998,
          0.1329057812690735,
          0.13374561071395874,
          0.13424751162528992,
          0.13463559746742249,
          0.13521550595760345,
          0.13578274846076965,
          0.13616178929805756,
          0.13700103759765625,
          0.1375609040260315,
          0.13782019913196564,
          0.13823606073856354,
          0.13853220641613007,
          0.1392301768064499,
          0.13971908390522003,
          0.14028088748455048,
          0.14056004583835602,
          0.14065062999725342,
          0.14156979322433472,
          0.14227744936943054,
          0.14334653317928314,
          0.14340618252754211,
          0.14444340765476227,
          0.15874125063419342,
          0.19218242168426514,
          0.21105550229549408,
          0.17008551955223083,
          0.12695865333080292,
          0.11100449413061142,
          0.10843145847320557,
          0.10831251740455627,
          0.10922824591398239,
          0.11023984849452972,
          0.11089589446783066,
          0.11178549379110336,
          0.11274503171443939,
          0.11354846507310867,
          0.11466526240110397,
          0.1156172826886177,
          0.11626375466585159,
          0.11729060113430023,
          0.11820748448371887,
          0.11885958164930344,
          0.11977913230657578,
          0.12056037038564682,
          0.12112850695848465,
          0.1220041960477829,
          0.12279380112886429,
          0.12357386946678162,
          0.12457685172557831,
          0.12528903782367706,
          0.12626852095127106,
          0.12699921429157257,
          0.12773065268993378,
          0.1286410242319107,
          0.12941691279411316,
          0.1301734745502472,
          0.1307654231786728,
          0.1315508633852005,
          0.13226629793643951,
          0.1329595297574997,
          0.13348855078220367,
          0.13417914509773254,
          0.134675532579422,
          0.13543546199798584,
          0.1358477920293808,
          0.1365986168384552,
          0.1372324675321579,
          0.13772766292095184,
          0.13840624690055847,
          0.13896149396896362,
          0.13935445249080658,
          0.14010834693908691,
          0.14044588804244995,
          0.14118942618370056,
          0.14147624373435974,
          0.14221590757369995,
          0.1427062302827835,
          0.14336523413658142,
          0.14363645017147064,
          0.14437535405158997,
          0.1448153853416443,
          0.14541764557361603,
          0.14571541547775269,
          0.14644914865493774,
          0.146674245595932,
          0.14727181196212769,
          0.14760524034500122,
          0.14821264147758484,
          0.14860419929027557,
          0.1491820216178894,
          0.1495600789785385,
          0.15002773702144623,
          0.1504303216934204,
          0.1509145200252533,
          0.15128053724765778,
          0.1517947018146515,
          0.1521824151277542,
          0.1527230143547058,
          0.15295377373695374,
          0.15358930826187134,
          0.1542513072490692,
          0.15482844412326813,
          0.15488401055335999,
          0.15566913783550262,
          0.1559145301580429,
          0.15641121566295624,
          0.1568451225757599,
          0.1572497934103012,
          0.15758788585662842,
          0.1580338180065155,
          0.15845705568790436,
          0.15876834094524384,
          0.15922491252422333,
          0.1595212072134018,
          0.1598551869392395,
          0.16019506752490997,
          0.16059067845344543,
          0.1608666032552719,
          0.16128794848918915,
          0.16166725754737854,
          0.16210295259952545,
          0.16246990859508514,
          0.16274413466453552,
          0.16313113272190094,
          0.16341644525527954,
          0.1638147234916687,
          0.16401846706867218,
          0.16437262296676636,
          0.16470186412334442,
          0.16496288776397705,
          0.1653221696615219,
          0.16561049222946167,
          0.1659483164548874,
          0.16621585190296173,
          0.16666921973228455,
          0.16696122288703918,
          0.16727277636528015,
          0.16755411028862,
          0.1678408682346344,
          0.16813376545906067,
          0.16856783628463745,
          0.1688002198934555,
          0.1691703349351883,
          0.1694321632385254,
          0.16971366107463837,
          0.16998912394046783,
          0.1703641414642334,
          0.17059648036956787,
          0.17097491025924683,
          0.17124655842781067,
          0.1715162694454193,
          0.1717880368232727,
          0.17212864756584167,
          0.17240917682647705,
          0.17266851663589478,
          0.17295728623867035,
          0.17332254350185394,
          0.1734629124403,
          0.1738869696855545,
          0.17406730353832245,
          0.17447899281978607,
          0.17466644942760468,
          0.17497320473194122,
          0.17522799968719482,
          0.1755937933921814,
          0.17584149539470673,
          0.17610755562782288,
          0.17626099288463593,
          0.1766631007194519,
          0.17690156400203705,
          0.1772126704454422,
          0.17746470868587494,
          0.17773739993572235,
          0.17800575494766235,
          0.17825929820537567,
          0.17849016189575195,
          0.17886075377464294,
          0.17907492816448212,
          0.17937569320201874,
          0.17958109080791473,
          0.17993012070655823,
          0.1801680028438568,
          0.1804116666316986,
          0.1806376427412033,
          0.18097063899040222,
          0.18116913735866547,
          0.18151751160621643,
          0.1817135512828827,
          0.18203702569007874,
          0.18224038183689117,
          0.1825629621744156,
          0.18264736235141754,
          0.18298158049583435,
          0.18323922157287598,
          0.18356482684612274,
          0.18378473818302155,
          0.1841140240430832,
          0.18432515859603882,
          0.18464677035808563,
          0.18476079404354095,
          0.18509425222873688,
          0.18536190688610077,
          0.18564704060554504,
          0.18591128289699554,
          0.18619810044765472,
          0.1864476203918457,
          0.18668128550052643,
          0.18693791329860687,
          0.18727971613407135,
          0.18748238682746887,
          0.18779030442237854,
          0.18802599608898163,
          0.18837077915668488,
          0.18854880332946777,
          0.18890975415706635,
          0.18910838663578033,
          0.1894623339176178,
          0.1896677315235138,
          0.18994265794754028,
          0.19027337431907654,
          0.1904943883419037,
          0.19075942039489746,
          0.1910264790058136,
          0.19129450619220734,
          0.19147859513759613,
          0.19181863963603973,
          0.1921093910932541,
          0.19235940277576447,
          0.19263480603694916,
          0.19286701083183289,
          0.19316677749156952,
          0.19342131912708282,
          0.19376489520072937,
          0.19394747912883759,
          0.19420456886291504,
          0.194472074508667,
          0.1948220133781433,
          0.19500242173671722,
          0.19532163441181183,
          0.19553379714488983,
          0.19581691920757294,
          0.19608891010284424,
          0.1963394582271576,
          0.1966194212436676,
          0.19689704477787018,
          0.19710485637187958,
          0.19734428822994232,
          0.19760656356811523,
          0.1978735327720642,
          0.19813477993011475,
          0.19843478500843048,
          0.19865043461322784,
          0.19886605441570282,
          0.1991860568523407,
          0.19945278763771057,
          0.19968079030513763,
          0.19987927377223969,
          0.2001650184392929,
          0.2004116028547287,
          0.20074063539505005,
          0.20101696252822876,
          0.20133069157600403,
          0.20152905583381653,
          0.20185749232769012,
          0.20206734538078308,
          0.2024957537651062,
          0.20272590219974518,
          0.203060582280159,
          0.2033074051141739,
          0.20358821749687195,
          0.20386601984500885,
          0.204151451587677,
          0.20447075366973877,
          0.2047109752893448,
          0.2050098031759262,
          0.2052813172340393,
          0.20561961829662323,
          0.20585185289382935,
          0.20612585544586182,
          0.20638830959796906,
          0.2066890001296997,
          0.20688195526599884,
          0.20718346536159515,
          0.20745500922203064,
          0.20774902403354645,
          0.20802606642246246,
          0.20830141007900238,
          0.2086312621831894,
          0.2088478058576584,
          0.2091633379459381,
          0.2094295769929886,
          0.2097456157207489,
          0.2099848836660385,
          0.2102482169866562,
          0.21051165461540222,
          0.21081887185573578,
          0.2110794484615326,
          0.2113897055387497,
          0.21155861020088196,
          0.211958646774292,
          0.2121812254190445,
          0.21249371767044067
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost function by epoch of training"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cost"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"6c493878-d4d1-4adc-bd0b-59553b0b1d0f\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"6c493878-d4d1-4adc-bd0b-59553b0b1d0f\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '6c493878-d4d1-4adc-bd0b-59553b0b1d0f',\n",
       "                        [{\"hovertemplate\": \"loss = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Training cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0], \"xaxis\": \"x\", \"y\": [0.24477717280387878, 0.06811131536960602, 0.08548329770565033, 0.08370263129472733, 0.058369021862745285, 0.05214221403002739, 0.04953069984912872, 0.04680463671684265, 0.044182371348142624, 0.041782476007938385, 0.03773241490125656, 0.035368554294109344, 0.03440040722489357, 0.031311217695474625, 0.029856093227863312, 0.028979068621993065, 0.028283243998885155, 0.026233552023768425, 0.025212915614247322, 0.02409248612821102, 0.022900499403476715, 0.0220304224640131, 0.019830267876386642, 0.01939256489276886, 0.01899617165327072, 0.01874668523669243, 0.017597712576389313, 0.0170671958476305, 0.0164014995098114, 0.015921708196401596, 0.015122726559638977, 0.01484921108931303, 0.014240144751966, 0.014008657075464725, 0.013291832990944386, 0.013000469654798508, 0.012543916702270508, 0.012020232155919075, 0.011386502534151077, 0.011305599473416805, 0.010701444000005722, 0.010536410845816135, 0.009999439120292664, 0.009695104323327541, 0.009055109694600105, 0.008715144358575344, 0.008373654447495937, 0.008191730827093124, 0.007784673944115639, 0.0076202391646802425, 0.0073576089926064014, 0.007270934525877237, 0.007012750953435898, 0.0067321183159947395, 0.006473727524280548, 0.006368528585880995, 0.006073545664548874, 0.005950694438070059, 0.00571691058576107, 0.005603264085948467, 0.005245264619588852, 0.005136491730809212, 0.004867557901889086, 0.004763577599078417, 0.004598515573889017, 0.004564597271382809, 0.0044902777299284935, 0.004343083593994379, 0.004279251676052809, 0.004142159596085548, 0.004100983031094074, 0.003988777287304401, 0.003910996485501528, 0.003771281335502863, 0.0036349317524582148, 0.003439616411924362, 0.0033009489998221397, 0.003099786816164851, 0.003076001536101103, 0.002951560541987419, 0.003054801607504487, 0.0028771841898560524, 0.0027276375330984592, 0.002540233079344034, 0.0024521024897694588, 0.002405685605481267, 0.002305080648511648, 0.0021342518739402294, 0.0021335980854928493, 0.002006778959184885, 0.002000249922275543, 0.0017310153925791383, 0.0016169744776561856, 0.0016101900255307555, 0.0015814320649951696, 0.00158692488912493, 0.0014194948598742485, 0.0014265242498368025, 0.012696928344666958, 0.002678269287571311, 0.020288141444325447, 0.18568289279937744, 0.19276969134807587, 0.12716278433799744, 0.04404478147625923, 0.04939469322562218, 0.035081785172224045, 0.02937379479408264, 0.027624689042568207, 0.025479784235358238, 0.023307709023356438, 0.021677380427718163, 0.01990352012217045, 0.018488792702555656, 0.01754876598715782, 0.016158342361450195, 0.015435109846293926, 0.014567211270332336, 0.013858936727046967, 0.013093473389744759, 0.01239316537976265, 0.011797488667070866, 0.011077183298766613, 0.010601431131362915, 0.010154117830097675, 0.009720981121063232, 0.009335963986814022, 0.009024553000926971, 0.008741027675569057, 0.008456856943666935, 0.008234580047428608, 0.007877446711063385, 0.007588163949549198, 0.008091123774647713, 0.0070833307690918446, 0.006652412470430136, 0.00664158072322607, 0.007203616667538881, 0.006208500359207392, 0.0058098589070141315, 0.005542527884244919, 0.005597855430096388, 0.005624840967357159, 0.006191416643559933, 0.005236805882304907, 0.0047203549183905125, 0.004442019388079643, 0.004301406908780336, 0.004081333987414837, 0.003964852541685104, 0.0038029092829674482, 0.0036803402472287416, 0.00361206685192883, 0.0034845841582864523, 0.0033415008801966906, 0.0032669659703969955, 0.0031945351511240005, 0.0030117800924926996, 0.0028751487843692303, 0.0027209522668272257, 0.0027338755317032337, 0.002600868931040168, 0.0025402421597391367, 0.002494171727448702, 0.002420606091618538, 0.00236816075630486, 0.0022854104172438383, 0.0022639427334070206, 0.0021902078296989202, 0.002175100613385439, 0.0020813788287341595, 0.002036268590018153, 0.001983714522793889, 0.0019526882097125053, 0.0019038469763472676, 0.0018566582584753633, 0.0018393597565591335, 0.00175278983078897, 0.0017332758288830519, 0.0017000716179609299, 0.0017145434394478798, 0.0015302901156246662, 0.0014879517257213593, 0.0013623692793771625, 0.0013861560728400946, 0.0012540578609332442, 0.0012498523574322462, 0.0012037974083796144, 0.0012319913366809487, 0.0010672956705093384, 0.0009582113125361502, 0.0008168754284270108, 0.0007547496352344751, 0.000750901410356164, 0.0006996159208938479, 0.0006661131046712399, 0.000632587936706841, 0.0006120189209468663, 0.0006130337715148926, 0.0005658981972374022, 0.0005456377984955907, 0.0005550090572796762, 0.0005297622410580516, 0.0005233939737081528, 0.0005024438141845167, 0.00048274570144712925, 0.00044823193456977606, 0.0004596470098476857, 0.00042459406540729105, 0.0004396597796585411, 0.00040279875975102186, 0.0003725608403328806, 0.0003456824051681906, 0.0003341937845107168, 0.0003555430448614061, 0.0003139588516205549, 0.00028132242732681334, 0.000322032836265862, 0.00040263222763314843, 0.000659600947983563, 0.0030960177537053823, 0.06226714327931404, 0.16884368658065796, 0.1288999319076538, 0.054231613874435425, 0.014905441552400589, 0.010433271527290344, 0.008237795904278755, 0.007414720486849546, 0.006518910638988018, 0.005666585173457861, 0.005064345896244049, 0.00455495435744524, 0.004134991206228733, 0.0037668447475880384, 0.0034871643874794245, 0.003240986494347453, 0.002993194852024317, 0.0027900689747184515, 0.002626248635351658, 0.0024483189918100834, 0.0023127298336476088, 0.0021804976277053356, 0.002007525647059083, 0.0018476975383237004, 0.0017106544692069292, 0.0016130144940689206, 0.0014676015125587583, 0.0013681829441338778, 0.0012487651547417045, 0.0011756994063034654, 0.0010793437249958515, 0.0010201784316450357, 0.0009401037241332233, 0.0008903489797376096, 0.0008285403600893915, 0.0007821047911420465, 0.0007320429431274533, 0.0006973735871724784, 0.000656464253552258, 0.0006356833619065583, 0.0006003814633004367, 0.0005766174872405827, 0.0005465916474349797, 0.0005237457808107138, 0.0005025725695304573, 0.00048080048873089254, 0.0004620800318662077, 0.0004483081866055727, 0.00042861432302743196, 0.0004123681574128568, 0.0003965345968026668, 0.0003837888070847839, 0.00036569731310009956, 0.00035176522214896977, 0.00034119075280614197, 0.0003319647803436965, 0.0003171768330503255, 0.0003047455393243581, 0.0002953929069917649, 0.0002904346911236644, 0.0002771391300484538, 0.00026724234339781106, 0.00025891372933983803, 0.0002513834333512932, 0.00024285531253553927, 0.00022946852550376207, 0.00022011998225934803, 0.00020617691916413605, 0.00019787138444371521, 0.0001893390726763755, 0.00018016441026702523, 0.0001715237449388951, 0.0001633984938962385, 0.00015782486298121512, 0.0001530651788925752, 0.00014784153609070927, 0.00014118153194431216, 0.0001372745755361393, 0.00013274885714054108, 0.0001243111619260162, 0.00011287403322057799, 0.00010781000310089439, 0.00010172222391702235, 9.719203080749139e-05, 9.219132334692404e-05, 8.86301277205348e-05, 8.499695832142606e-05, 8.182737656170502e-05, 7.845950312912464e-05, 7.560435187770054e-05, 7.269308844115585e-05, 7.044531957944855e-05, 6.816262612119317e-05, 6.597298488486558e-05, 6.402705184882507e-05, 6.095883873058483e-05, 5.815004260512069e-05, 5.6019413023022935e-05, 5.442670590127818e-05, 5.260546458885074e-05, 5.12396109115798e-05, 4.970302325091325e-05, 4.841231930186041e-05, 4.699494093074463e-05, 4.591252945829183e-05, 4.4651937059825286e-05, 4.352222822490148e-05, 4.235524102114141e-05, 4.109338624402881e-05, 4.0101524064084515e-05, 3.910916711902246e-05, 3.802391802310012e-05, 3.6943576560588554e-05, 3.5904900869354606e-05, 3.4855969715863466e-05, 3.398709304747172e-05, 3.328528691781685e-05, 3.232707240385935e-05, 3.147998359054327e-05, 3.06609072140418e-05, 2.9872717277612537e-05, 2.9144173822714947e-05, 2.8387850761646405e-05, 2.7651714844978414e-05, 2.697229319892358e-05, 2.622981082822662e-05, 2.5543422452756204e-05, 2.495412809366826e-05, 2.4299550204887055e-05, 2.370641777815763e-05, 2.3079212041920982e-05, 2.256417428725399e-05, 2.2012347471900284e-05, 2.146905717381742e-05, 2.0970228433725424e-05, 2.040925573965069e-05, 1.9884351786458865e-05, 1.9430184693192132e-05, 1.891642386908643e-05, 1.8468897906132042e-05, 1.800302015908528e-05, 1.7569827832630835e-05, 1.7137484974227846e-05, 1.6747566405683756e-05, 1.637128480069805e-05, 1.598723974893801e-05, 1.5645862731616944e-05, 1.5241918845276814e-05, 1.4882089089951478e-05, 1.4522820492857136e-05, 1.4219116565072909e-05, 1.3893157301936299e-05, 1.3619119272334501e-05, 1.3259947081678547e-05, 1.2992397387279198e-05, 1.2671161130128894e-05, 1.2411423995217774e-05, 1.2114557648601476e-05, 1.1860319318657275e-05, 1.1605407962633763e-05, 1.1328771506669e-05, 1.1045032806578092e-05, 1.07996220322093e-05, 1.0538924470893107e-05, 1.0324211871193256e-05, 1.0068192750622984e-05, 9.807677997741848e-06, 9.643359589972533e-06, 9.386425517732278e-06, 9.18394925975008e-06, 8.988406079879496e-06, 8.768327461439185e-06, 8.562419679947197e-06, 8.365529538423289e-06, 8.192220775526948e-06, 8.018668268050533e-06, 7.844156243663747e-06, 7.677376743231434e-06, 7.490611551475013e-06, 7.314231879718136e-06, 7.169815489760367e-06, 6.9913776314933784e-06, 6.847220902272966e-06, 6.694157491438091e-06, 6.53216511636856e-06, 6.360169209074229e-06, 6.238877176656388e-06, 6.0793945522163995e-06, 5.948485977569362e-06, 5.817090823256876e-06, 5.708512162527768e-06, 5.564561433857307e-06, 5.419031367637217e-06, 5.287115527607966e-06, 5.14612202096032e-06, 5.057030648458749e-06, 4.928755515720695e-06, 4.82094264953048e-06, 4.713541784440167e-06, 4.611810254573356e-06, 4.514379270403879e-06, 4.431532943272032e-06, 4.324228939367458e-06, 4.208879545331001e-06, 4.124424776819069e-06, 4.026938768220134e-06, 3.949564415961504e-06, 3.854208443954121e-06, 3.7848003557883203e-06, 3.686246600409504e-06, 3.594279860408278e-06, 3.544868150129332e-06, 3.46797241945751e-06, 3.372891114850063e-06, 3.308274926894228e-06, 3.227238494218909e-06, 3.153220632157172e-06, 3.0835378765914356e-06, 3.0185876767063746e-06, 2.9432412702590227e-06, 2.8911751996929524e-06, 2.8173969894851325e-06, 2.7551452603802318e-06, 2.695839157240698e-06, 2.6313368834962603e-06, 2.5749361611815402e-06, 2.5144599931081757e-06, 2.4549503905291203e-06, 2.40235840465175e-06, 2.3578495529363863e-06, 2.298078243256896e-06, 2.2503925265482394e-06, 2.198753691118327e-06, 2.151616627088515e-06, 2.1039825242041843e-06, 2.0642946765292436e-06, 2.0124091406614752e-06, 1.9632545900094556e-06, 1.919873739097966e-06, 1.8883237089539762e-06, 1.8465419771018787e-06, 1.8037835616269149e-06, 1.7628917703405023e-06, 1.717576651572017e-06, 1.6904155017982703e-06, 1.6420410702266963e-06, 1.6128952893268433e-06, 1.5797468222444877e-06, 1.545109057587979e-06, 1.5096543393156026e-06, 1.4755374877495342e-06, 1.4481099697150057e-06, 1.4157208170217928e-06, 1.3823089375364361e-06, 1.3545294450523215e-06, 1.326092842646176e-06, 1.2968871487828437e-06, 1.2738939858536469e-06, 1.2479100632845075e-06, 1.219143427988456e-06, 1.1925445733140805e-06, 1.166476522485027e-06, 1.139846403930278e-06, 1.1242574373682146e-06, 1.0949471516141784e-06, 1.0731123438745271e-06, 1.0525047855480807e-06, 1.0274860642311978e-06, 1.0125482958756038e-06, 9.896369874695665e-07, 9.697881750980741e-07, 9.508171388006303e-07, 9.333224397778395e-07, 9.115327657127636e-07, 8.933147910283878e-07, 8.787901037976553e-07, 8.633153925075021e-07, 8.399437092521111e-07, 8.247537834904506e-07], \"yaxis\": \"y\"}, {\"hovertemplate\": \"val_loss = %{y:.4f}\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Validation cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0], \"xaxis\": \"x\", \"y\": [0.12495018541812897, 0.06989356130361557, 0.0652560293674469, 0.06654969602823257, 0.06514935940504074, 0.06388038396835327, 0.0637611672282219, 0.06256065517663956, 0.0631280392408371, 0.06150833144783974, 0.061584338545799255, 0.06121031567454338, 0.061395205557346344, 0.06087050959467888, 0.06082826852798462, 0.061099544167518616, 0.060878630727529526, 0.0605696365237236, 0.0607684887945652, 0.06074950471520424, 0.06050499156117439, 0.06124543398618698, 0.060801707208156586, 0.06108374893665314, 0.061397019773721695, 0.061561040580272675, 0.062049660831689835, 0.06233809143304825, 0.06281475722789764, 0.06318206340074539, 0.06369207799434662, 0.0641411617398262, 0.06473743915557861, 0.06486285477876663, 0.06587184220552444, 0.06606604903936386, 0.06680488586425781, 0.06728903204202652, 0.0682358667254448, 0.0687197744846344, 0.0695795938372612, 0.07037686556577682, 0.07106860727071762, 0.0720786452293396, 0.07295933365821838, 0.07380273938179016, 0.0740223228931427, 0.0752478614449501, 0.07604437321424484, 0.07674206793308258, 0.07743656635284424, 0.07835857570171356, 0.07901928573846817, 0.08020133525133133, 0.08027129620313644, 0.08122796565294266, 0.08234386891126633, 0.08330143243074417, 0.08317584544420242, 0.08471373468637466, 0.08620326966047287, 0.08654267340898514, 0.08802586793899536, 0.08808872103691101, 0.08933267742395401, 0.0892803743481636, 0.09066556394100189, 0.09143435955047607, 0.09148699790239334, 0.09288015961647034, 0.09409159421920776, 0.09279133379459381, 0.09595280140638351, 0.09602466225624084, 0.0966498926281929, 0.09716524928808212, 0.09904228150844574, 0.09918558597564697, 0.1001557856798172, 0.10075734555721283, 0.10121932625770569, 0.10230981558561325, 0.10413600504398346, 0.10462751239538193, 0.10588517040014267, 0.10439170151948929, 0.10690253227949142, 0.10747924447059631, 0.10865097492933273, 0.10948564112186432, 0.10911419987678528, 0.11143632978200912, 0.11207439005374908, 0.11216221004724503, 0.11333492398262024, 0.11335441470146179, 0.11487951129674911, 0.11515985429286957, 0.12046610563993454, 0.11832582205533981, 0.34946051239967346, 0.11994977295398712, 0.10445600748062134, 0.09183643013238907, 0.08389678597450256, 0.07782869040966034, 0.07165232300758362, 0.0694577619433403, 0.06890715658664703, 0.06794696301221848, 0.06743248552083969, 0.0667920932173729, 0.06658349186182022, 0.06612695008516312, 0.06581006199121475, 0.06567231565713882, 0.06552460044622421, 0.06597232073545456, 0.06635980308055878, 0.0668783038854599, 0.06827443093061447, 0.06893753260374069, 0.06994341313838959, 0.07098285108804703, 0.0717136412858963, 0.07270678132772446, 0.07352222502231598, 0.07420985400676727, 0.07510463148355484, 0.07606165111064911, 0.07703029364347458, 0.07804112136363983, 0.07900311052799225, 0.08029812574386597, 0.08105440437793732, 0.0819818526506424, 0.08338267356157303, 0.08506027609109879, 0.08537103235721588, 0.08644925802946091, 0.08743561059236526, 0.08842199295759201, 0.08927687257528305, 0.09055547416210175, 0.09106539934873581, 0.09192216396331787, 0.09295469522476196, 0.09367235749959946, 0.09471110999584198, 0.09562740474939346, 0.09639479219913483, 0.0971299484372139, 0.0978977307677269, 0.09871053695678711, 0.09961888939142227, 0.10032675415277481, 0.10169973969459534, 0.10259759426116943, 0.1034012958407402, 0.10418941080570221, 0.10490038990974426, 0.10596922785043716, 0.10655489563941956, 0.10742330551147461, 0.10802669078111649, 0.10874325037002563, 0.1092909500002861, 0.11028758436441422, 0.1107436940073967, 0.1119486540555954, 0.1123802661895752, 0.11319362372159958, 0.11369544267654419, 0.1145172044634819, 0.11492330580949783, 0.11575829237699509, 0.11617624759674072, 0.11714500188827515, 0.11756893992424011, 0.11859775334596634, 0.11874507367610931, 0.12008809298276901, 0.12084405869245529, 0.12169093638658524, 0.12248466908931732, 0.1234363242983818, 0.12418176233768463, 0.12536659836769104, 0.12580053508281708, 0.12675237655639648, 0.12729674577713013, 0.12851470708847046, 0.1290569007396698, 0.1297989934682846, 0.13036474585533142, 0.13118790090084076, 0.13174037635326385, 0.13249671459197998, 0.1329057812690735, 0.13374561071395874, 0.13424751162528992, 0.13463559746742249, 0.13521550595760345, 0.13578274846076965, 0.13616178929805756, 0.13700103759765625, 0.1375609040260315, 0.13782019913196564, 0.13823606073856354, 0.13853220641613007, 0.1392301768064499, 0.13971908390522003, 0.14028088748455048, 0.14056004583835602, 0.14065062999725342, 0.14156979322433472, 0.14227744936943054, 0.14334653317928314, 0.14340618252754211, 0.14444340765476227, 0.15874125063419342, 0.19218242168426514, 0.21105550229549408, 0.17008551955223083, 0.12695865333080292, 0.11100449413061142, 0.10843145847320557, 0.10831251740455627, 0.10922824591398239, 0.11023984849452972, 0.11089589446783066, 0.11178549379110336, 0.11274503171443939, 0.11354846507310867, 0.11466526240110397, 0.1156172826886177, 0.11626375466585159, 0.11729060113430023, 0.11820748448371887, 0.11885958164930344, 0.11977913230657578, 0.12056037038564682, 0.12112850695848465, 0.1220041960477829, 0.12279380112886429, 0.12357386946678162, 0.12457685172557831, 0.12528903782367706, 0.12626852095127106, 0.12699921429157257, 0.12773065268993378, 0.1286410242319107, 0.12941691279411316, 0.1301734745502472, 0.1307654231786728, 0.1315508633852005, 0.13226629793643951, 0.1329595297574997, 0.13348855078220367, 0.13417914509773254, 0.134675532579422, 0.13543546199798584, 0.1358477920293808, 0.1365986168384552, 0.1372324675321579, 0.13772766292095184, 0.13840624690055847, 0.13896149396896362, 0.13935445249080658, 0.14010834693908691, 0.14044588804244995, 0.14118942618370056, 0.14147624373435974, 0.14221590757369995, 0.1427062302827835, 0.14336523413658142, 0.14363645017147064, 0.14437535405158997, 0.1448153853416443, 0.14541764557361603, 0.14571541547775269, 0.14644914865493774, 0.146674245595932, 0.14727181196212769, 0.14760524034500122, 0.14821264147758484, 0.14860419929027557, 0.1491820216178894, 0.1495600789785385, 0.15002773702144623, 0.1504303216934204, 0.1509145200252533, 0.15128053724765778, 0.1517947018146515, 0.1521824151277542, 0.1527230143547058, 0.15295377373695374, 0.15358930826187134, 0.1542513072490692, 0.15482844412326813, 0.15488401055335999, 0.15566913783550262, 0.1559145301580429, 0.15641121566295624, 0.1568451225757599, 0.1572497934103012, 0.15758788585662842, 0.1580338180065155, 0.15845705568790436, 0.15876834094524384, 0.15922491252422333, 0.1595212072134018, 0.1598551869392395, 0.16019506752490997, 0.16059067845344543, 0.1608666032552719, 0.16128794848918915, 0.16166725754737854, 0.16210295259952545, 0.16246990859508514, 0.16274413466453552, 0.16313113272190094, 0.16341644525527954, 0.1638147234916687, 0.16401846706867218, 0.16437262296676636, 0.16470186412334442, 0.16496288776397705, 0.1653221696615219, 0.16561049222946167, 0.1659483164548874, 0.16621585190296173, 0.16666921973228455, 0.16696122288703918, 0.16727277636528015, 0.16755411028862, 0.1678408682346344, 0.16813376545906067, 0.16856783628463745, 0.1688002198934555, 0.1691703349351883, 0.1694321632385254, 0.16971366107463837, 0.16998912394046783, 0.1703641414642334, 0.17059648036956787, 0.17097491025924683, 0.17124655842781067, 0.1715162694454193, 0.1717880368232727, 0.17212864756584167, 0.17240917682647705, 0.17266851663589478, 0.17295728623867035, 0.17332254350185394, 0.1734629124403, 0.1738869696855545, 0.17406730353832245, 0.17447899281978607, 0.17466644942760468, 0.17497320473194122, 0.17522799968719482, 0.1755937933921814, 0.17584149539470673, 0.17610755562782288, 0.17626099288463593, 0.1766631007194519, 0.17690156400203705, 0.1772126704454422, 0.17746470868587494, 0.17773739993572235, 0.17800575494766235, 0.17825929820537567, 0.17849016189575195, 0.17886075377464294, 0.17907492816448212, 0.17937569320201874, 0.17958109080791473, 0.17993012070655823, 0.1801680028438568, 0.1804116666316986, 0.1806376427412033, 0.18097063899040222, 0.18116913735866547, 0.18151751160621643, 0.1817135512828827, 0.18203702569007874, 0.18224038183689117, 0.1825629621744156, 0.18264736235141754, 0.18298158049583435, 0.18323922157287598, 0.18356482684612274, 0.18378473818302155, 0.1841140240430832, 0.18432515859603882, 0.18464677035808563, 0.18476079404354095, 0.18509425222873688, 0.18536190688610077, 0.18564704060554504, 0.18591128289699554, 0.18619810044765472, 0.1864476203918457, 0.18668128550052643, 0.18693791329860687, 0.18727971613407135, 0.18748238682746887, 0.18779030442237854, 0.18802599608898163, 0.18837077915668488, 0.18854880332946777, 0.18890975415706635, 0.18910838663578033, 0.1894623339176178, 0.1896677315235138, 0.18994265794754028, 0.19027337431907654, 0.1904943883419037, 0.19075942039489746, 0.1910264790058136, 0.19129450619220734, 0.19147859513759613, 0.19181863963603973, 0.1921093910932541, 0.19235940277576447, 0.19263480603694916, 0.19286701083183289, 0.19316677749156952, 0.19342131912708282, 0.19376489520072937, 0.19394747912883759, 0.19420456886291504, 0.194472074508667, 0.1948220133781433, 0.19500242173671722, 0.19532163441181183, 0.19553379714488983, 0.19581691920757294, 0.19608891010284424, 0.1963394582271576, 0.1966194212436676, 0.19689704477787018, 0.19710485637187958, 0.19734428822994232, 0.19760656356811523, 0.1978735327720642, 0.19813477993011475, 0.19843478500843048, 0.19865043461322784, 0.19886605441570282, 0.1991860568523407, 0.19945278763771057, 0.19968079030513763, 0.19987927377223969, 0.2001650184392929, 0.2004116028547287, 0.20074063539505005, 0.20101696252822876, 0.20133069157600403, 0.20152905583381653, 0.20185749232769012, 0.20206734538078308, 0.2024957537651062, 0.20272590219974518, 0.203060582280159, 0.2033074051141739, 0.20358821749687195, 0.20386601984500885, 0.204151451587677, 0.20447075366973877, 0.2047109752893448, 0.2050098031759262, 0.2052813172340393, 0.20561961829662323, 0.20585185289382935, 0.20612585544586182, 0.20638830959796906, 0.2066890001296997, 0.20688195526599884, 0.20718346536159515, 0.20745500922203064, 0.20774902403354645, 0.20802606642246246, 0.20830141007900238, 0.2086312621831894, 0.2088478058576584, 0.2091633379459381, 0.2094295769929886, 0.2097456157207489, 0.2099848836660385, 0.2102482169866562, 0.21051165461540222, 0.21081887185573578, 0.2110794484615326, 0.2113897055387497, 0.21155861020088196, 0.211958646774292, 0.2121812254190445, 0.21249371767044067], \"yaxis\": \"y\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Cost function by epoch of training\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"cost\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6c493878-d4d1-4adc-bd0b-59553b0b1d0f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': False}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.loss, name='Training cost',\n",
    "               hovertemplate =\n",
    "                'loss = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.val_loss, name='Validation cost',\n",
    "               hovertemplate = 'val_loss = %{y:.4f}',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Cost function by epoch of training',\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='cost', secondary_y=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Val ROC-AUC",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "xaxis": "x",
         "y": [
          0.6767765108125108,
          0.7171845961528407,
          0.7653445918433631,
          0.7857349956509134,
          0.7992520204636807,
          0.8113153887956753,
          0.8176825626181343,
          0.8258582910703506,
          0.825962463183278,
          0.8371401705095483,
          0.8414147919647257,
          0.8473573555017927,
          0.851457696615951,
          0.8561446495143124,
          0.8585540752289014,
          0.8592508005012935,
          0.8608846786983476,
          0.8661455684470196,
          0.8669567642161267,
          0.8681739539614713,
          0.8712761440316112,
          0.8737239906395614,
          0.874734420525788,
          0.876592882707746,
          0.8775874689266074,
          0.878191112653228,
          0.8783162776254145,
          0.879550103221493,
          0.8793821603474199,
          0.8798899498864802,
          0.8801343384555911,
          0.8798859889696388,
          0.8809320671074374,
          0.8802357379267294,
          0.8817903977869566,
          0.8814545120388106,
          0.882027656705753,
          0.8813024128321031,
          0.8820597401321679,
          0.8811305090411887,
          0.8813016206487347,
          0.8793342332536398,
          0.8807795718090459,
          0.8799735252318326,
          0.880282080653773,
          0.8798681648438528,
          0.879331856703535,
          0.8788331772732098,
          0.8791322264947312,
          0.8774924069224153,
          0.8776853035725886,
          0.8770190773598745,
          0.8769489691317829,
          0.8767148789464595,
          0.875280234866525,
          0.8754030232886066,
          0.8757060334269693,
          0.8743957621358531,
          0.8725701755636781,
          0.8730264731838008,
          0.8734435577271942,
          0.8724854119432733,
          0.8720192120310473,
          0.8713882379782212,
          0.8700744018619478,
          0.8684096285135311,
          0.8691463590460211,
          0.8685031061509869,
          0.8664038202250751,
          0.866500466596004,
          0.8666680133783927,
          0.8644380171967165,
          0.8645711040025857,
          0.8660572400014577,
          0.8641773888685561,
          0.8646942885163514,
          0.8635646350332005,
          0.8618820375589978,
          0.860413725685912,
          0.8609702345021206,
          0.8582482924487496,
          0.8603634220420271,
          0.8582051184551791,
          0.8587901458726455,
          0.857667622039809,
          0.8552043278561775,
          0.8562424841602936,
          0.8558151012331128,
          0.854017637170511,
          0.8547908081379414,
          0.8525445721972156,
          0.85372532150762,
          0.8505466857424423,
          0.8513879844795433,
          0.8517575380208408,
          0.8480913133924936,
          0.848744468579631,
          0.8516272238567606,
          0.8376234023641922,
          0.8528246090178987,
          0.8736930954881988,
          0.8357027537878245,
          0.7217487606291204,
          0.7006394504148663,
          0.785362273376143,
          0.7802511062840738,
          0.796288858574672,
          0.8134538877983164,
          0.8162514833633571,
          0.8197481807508947,
          0.8226875771388555,
          0.826732069325551,
          0.8288139272173609,
          0.8321771417073452,
          0.8345113100019488,
          0.836868451614232,
          0.8375251716265267,
          0.8389229791798367,
          0.8400245101534143,
          0.8414175646065145,
          0.8425594969318738,
          0.8425721718657663,
          0.8437402462422782,
          0.8436721184726071,
          0.8443403251437418,
          0.8440369189136947,
          0.8445439162693866,
          0.8447962266721802,
          0.8444171669304636,
          0.8444108294635175,
          0.8442733856491229,
          0.8446215502394772,
          0.8444928204421335,
          0.8410598938157413,
          0.8437327205002796,
          0.8437850046025853,
          0.843003119618104,
          0.8391051813545385,
          0.8422881741282418,
          0.8420342793587117,
          0.8418342530582239,
          0.8411113857346788,
          0.8407426243767497,
          0.8365503899918721,
          0.8407675781528501,
          0.8408594714235692,
          0.8404974436242706,
          0.840194829577592,
          0.8402296856457958,
          0.8403433639591423,
          0.8397729919339889,
          0.8397119938146322,
          0.8392279697766201,
          0.839950441008481,
          0.8390992399792765,
          0.8395111753307762,
          0.8391986589919942,
          0.8398308213198725,
          0.8398755796801797,
          0.8396359442112784,
          0.8396121787102303,
          0.8397195195566307,
          0.8392117300175705,
          0.8397797254926191,
          0.8392964936379753,
          0.8397595248167283,
          0.8396006920513905,
          0.8401659148846502,
          0.8394390866442637,
          0.8395111753307762,
          0.8393464011901763,
          0.8396201005439132,
          0.8392089573757816,
          0.8396141591686509,
          0.8392850069791356,
          0.8396034646931795,
          0.8392382681604076,
          0.8400142117696267,
          0.839295305362923,
          0.8397480381578886,
          0.8404966514409025,
          0.8401948295775921,
          0.8397345710406278,
          0.8405101185581629,
          0.8407537149439053,
          0.8415787739219572,
          0.84179939699002,
          0.8422596555269842,
          0.8424790903199945,
          0.84291360289749,
          0.8426094044840748,
          0.8436388467711398,
          0.8435711150931529,
          0.8443918170626792,
          0.844105046683366,
          0.8446033300220069,
          0.8448528677830116,
          0.8448548482414321,
          0.8447304754526139,
          0.845332534812498,
          0.8452509399255664,
          0.8451095351943304,
          0.8447752338129211,
          0.8449867467722489,
          0.8448310827403842,
          0.845462452884894,
          0.845373332255964,
          0.845287776452191,
          0.8450390308745547,
          0.8446274916147389,
          0.845467998168472,
          0.8453111458615548,
          0.8455753390148724,
          0.8451586505631632,
          0.844869107542061,
          0.8453559042218621,
          0.8447225536189313,
          0.844630660348212,
          0.8437699531185883,
          0.8425448415395609,
          0.8333123404740743,
          0.8371552219935451,
          0.8043996279906902,
          0.7799667124548655,
          0.8395523688659262,
          0.8216811081694702,
          0.8312823705928859,
          0.8339603464693178,
          0.8332889710647103,
          0.8344732852002719,
          0.8364026477936903,
          0.8370462967804084,
          0.837546956669154,
          0.8381315879949365,
          0.8383672625469962,
          0.8387471144720811,
          0.8394279960771079,
          0.8395713812667646,
          0.8399195458571185,
          0.8399607393922686,
          0.840150467308969,
          0.8402863267566271,
          0.8405517081849969,
          0.8410357322230091,
          0.8415680794464856,
          0.8419483274632547,
          0.8424497795353687,
          0.8425721718657662,
          0.8432993961978368,
          0.8433203890570957,
          0.8433580177670886,
          0.843581017385256,
          0.843937499900977,
          0.8443015081586965,
          0.8443779538537345,
          0.8444607370157184,
          0.8445597599367521,
          0.8450822048681252,
          0.8452141033989421,
          0.8454244280832173,
          0.8453757088060688,
          0.8457325874134738,
          0.8458256689592454,
          0.8458981537374419,
          0.8464233713106041,
          0.846376236400192,
          0.8466428061036144,
          0.8468903634061984,
          0.8466186445108821,
          0.8472508068387606,
          0.8469735426598666,
          0.8475043055166065,
          0.8471573292013048,
          0.8477744400451862,
          0.8477597846528733,
          0.8480802228253379,
          0.8477459214439285,
          0.8481384483029055,
          0.8483467925287602,
          0.8486018755733427,
          0.8480540807741851,
          0.8488910225027607,
          0.8486692111596454,
          0.8489425144216982,
          0.8489033013449689,
          0.8492974125706825,
          0.8489884610570577,
          0.8494308954682359,
          0.8494823873871732,
          0.8495057567965372,
          0.8498812517130965,
          0.8499901769262335,
          0.8500052284102305,
          0.850345471166902,
          0.8502567466296559,
          0.850587879277592,
          0.8502444677874477,
          0.8504698439557201,
          0.8496740957622945,
          0.8500745444549541,
          0.8512137041385244,
          0.8505272772499195,
          0.8510592283817119,
          0.8511487451023263,
          0.8513824391959656,
          0.8515321618525684,
          0.851610191914343,
          0.8517199093108481,
          0.8519377597371218,
          0.8519536034044872,
          0.8521849209480217,
          0.8521635319970784,
          0.852318799937259,
          0.8523085015534715,
          0.8525010021119609,
          0.8525326894466916,
          0.8526673606192973,
          0.852168285097288,
          0.852012224973739,
          0.8519124098693373,
          0.8516577229164389,
          0.8516569307330708,
          0.8516296004068653,
          0.8516882219761173,
          0.8515638491872991,
          0.8515895951467678,
          0.8515175064602554,
          0.8515040393429948,
          0.8516133606478158,
          0.8515357266777256,
          0.8516062309975015,
          0.8514580927076352,
          0.8516387105156005,
          0.8515008706095216,
          0.8516498010827561,
          0.8516553463663341,
          0.8517242663193735,
          0.8516133606478159,
          0.8518613140420839,
          0.8516676252085422,
          0.8517888292638873,
          0.8516723783087518,
          0.8517385256200024,
          0.8516795079590662,
          0.8517020851850621,
          0.8515800889463486,
          0.851672774400436,
          0.8515555312619323,
          0.8516090036392905,
          0.8514687871831068,
          0.8515745436627707,
          0.8515198830103601,
          0.8515301813941477,
          0.8514363076650079,
          0.8515571156286689,
          0.8514137304390121,
          0.8515816733130852,
          0.8514573005242669,
          0.8516656447501216,
          0.8515171103685713,
          0.8516256394900241,
          0.8515674140124563,
          0.8517222858609528,
          0.8516882219761172,
          0.851752388828947,
          0.8516771314089615,
          0.8517626872127345,
          0.8516343535070751,
          0.8517777386967316,
          0.8516957477181158,
          0.8517626872127346,
          0.8517309998780038,
          0.8517797191551524,
          0.8517001047266413,
          0.8518664632339777,
          0.8517983354643066,
          0.8519108255026007,
          0.8518165556817767,
          0.8519512268543825,
          0.8518759694343968,
          0.8520062835984772,
          0.8518862678181844,
          0.8520779761933054,
          0.8519330066369121,
          0.8521496687881336,
          0.8520039070483725,
          0.8522078942657013,
          0.8521112478947727,
          0.8522296793083288,
          0.8521231306452967,
          0.8522863204191601,
          0.8522142317326475,
          0.8523920768988238,
          0.8523627661141981,
          0.8524697108689143,
          0.8523996026408225,
          0.8525200145127994,
          0.8524328743422896,
          0.8525113004957483,
          0.8525128848624848,
          0.8525675455148953,
          0.852654685685405,
          0.8526467638517222,
          0.8526962753122391,
          0.8527358844806524,
          0.8526733019945593,
          0.8528594650861024,
          0.8527905451330631,
          0.8528709517449422,
          0.8528143106341112,
          0.8529901753418666,
          0.8527477672311764,
          0.8530147330262831,
          0.8529339303227197,
          0.8530876138961638,
          0.85305275782796,
          0.8530123564761782,
          0.8531430667319427,
          0.8531097950304753,
          0.8531597025826763,
          0.8531810915336194,
          0.8532191163352963,
          0.8531216777809992,
          0.8532611020538147,
          0.8533292298234857,
          0.8533070486891742,
          0.8534044872434711,
          0.8533890396677901,
          0.853451226062199,
          0.853383098292528,
          0.8535668848339663,
          0.8535462880663913,
          0.8535280678489212,
          0.8535403466911293,
          0.8536948224479416,
          0.8536167923861672,
          0.8537629502176127,
          0.8537680994095065,
          0.8538033515693946,
          0.8538861347313786,
          0.8538651418721194,
          0.8538599926802257,
          0.8540358573879813,
          0.8539855537440961,
          0.854034669112929,
          0.8540342730212449,
          0.8540798235649202,
          0.8540596228890294,
          0.854185580044584,
          0.8541954823366874,
          0.8541400295009085,
          0.8542461820722566,
          0.8543543151020253,
          0.8543558994687618,
          0.8543606525689714,
          0.854500869025155,
          0.8544275920635901,
          0.8545420625603051,
          0.8545943466626106,
          0.8547230764599544,
          0.8545666202447212,
          0.8547234725516385,
          0.8546941617670125,
          0.8548716108415048,
          0.854843092240247,
          0.8548981489843418,
          0.8549013177178147,
          0.8549155770184436,
          0.854963504112224,
          0.8549916266217974,
          0.8550510403744176,
          0.85504074199063,
          0.8551009479266185,
          0.8551516476621878,
          0.8552570080501674,
          0.85520551613123,
          0.8553184022612081,
          0.8554253470159243,
          0.8553572192462534,
          0.855385737847511,
          0.8555085262695926,
          0.8554942669689638,
          0.8555940820733657,
          0.8556740925935609,
          0.8556883518941897,
          0.8557984653823788,
          0.8557937122821694,
          0.8558697618855232,
          0.8559315521882482,
          0.8560301790175975,
          0.8559672004398202,
          0.8560242376423355,
          0.8560678077275903,
          0.8560828592115874,
          0.856152571347995,
          0.8562428802519777,
          0.8561070208043197,
          0.8562896190707056,
          0.8562947682625992,
          0.8563090275632281
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Avg precision = %{y:.4f}<br>epoch = %{x}<br>",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Val avg precision",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500
         ],
         "xaxis": "x",
         "y": [
          0.05340468671384806,
          0.10401419973338867,
          0.13563413688505227,
          0.14104468031278425,
          0.15382355608961235,
          0.16307885644094067,
          0.16762967320764557,
          0.17921485875804813,
          0.18586756841505012,
          0.19835730856023945,
          0.21226879726778766,
          0.2244592413245426,
          0.23666776971723197,
          0.24792981669051684,
          0.2542497456244058,
          0.2580437940457585,
          0.26602991498406153,
          0.2768796473456159,
          0.2793336579875792,
          0.2851776145791968,
          0.292144814758461,
          0.29683538184475217,
          0.30546095446009414,
          0.3105731044380617,
          0.3125604358957341,
          0.31443820535521905,
          0.3176981516065062,
          0.3192932041014412,
          0.32180913208826034,
          0.326609355386303,
          0.32839951808813445,
          0.3292462286271016,
          0.33147572667533376,
          0.3318812520519076,
          0.328532827415493,
          0.33439573930009137,
          0.33220009922869065,
          0.3328216801120181,
          0.3356145181972293,
          0.33402168167834023,
          0.3345608571858982,
          0.33524265293753686,
          0.33579225320408823,
          0.33601268315194843,
          0.3354836130969042,
          0.3361838910961422,
          0.33566743420338296,
          0.3359001345736193,
          0.3354856535059442,
          0.3353664701871836,
          0.3384681072730719,
          0.3405115847068479,
          0.34054690775866187,
          0.34075029054920025,
          0.3398043464030325,
          0.3407536933071192,
          0.33875860460858104,
          0.3404790541252663,
          0.33904482426826305,
          0.3396982705212689,
          0.3387190815993787,
          0.34058594946010795,
          0.3403931823379573,
          0.3406940813083099,
          0.33918218452234516,
          0.3407240014749697,
          0.33885759044450664,
          0.3358202309497452,
          0.33420617996452506,
          0.33299820814277215,
          0.3325456687858142,
          0.3331744395236074,
          0.3314757710681743,
          0.33118155818272255,
          0.33100575957492706,
          0.33216557272441183,
          0.33064635310041446,
          0.3327482042362402,
          0.33036140250015117,
          0.33300791522909057,
          0.331750737882746,
          0.33211719307924725,
          0.329333246975594,
          0.33081143935561114,
          0.32950126548057257,
          0.32872349939145185,
          0.3289162244927627,
          0.32789166507761874,
          0.32638325766455084,
          0.32632978504906235,
          0.32445955808699123,
          0.32295330023136176,
          0.3223676378992841,
          0.32731398026978786,
          0.32493568532593425,
          0.3271813959113548,
          0.3262570370281022,
          0.3285603105560572,
          0.3284612943890324,
          0.3240346215414763,
          0.2338072505243283,
          0.14539017915778812,
          0.17110061297386103,
          0.14587100547750126,
          0.19088060674759183,
          0.21278784628876024,
          0.23863097865053046,
          0.2508740789174544,
          0.25551926036238576,
          0.26246941776120697,
          0.2708295054180395,
          0.2765665387095343,
          0.28215120936217236,
          0.28575066778142033,
          0.28946963446323365,
          0.2894280053605777,
          0.2956822465067857,
          0.29768017373241273,
          0.2979481238917812,
          0.2982453822702377,
          0.2911229702620904,
          0.29298168077788816,
          0.2917209566483042,
          0.2882258192488952,
          0.2897389487377955,
          0.2897855233394996,
          0.29215749224909743,
          0.292056693406425,
          0.2917032487057498,
          0.2911664223504843,
          0.29150752205751385,
          0.2911826011764091,
          0.2918458307660031,
          0.28878994199014313,
          0.2903602596035671,
          0.29016436450935834,
          0.2885726934393131,
          0.2883475703474341,
          0.2891017837892116,
          0.29243652206655424,
          0.29233014725170936,
          0.2923632479592192,
          0.2928520317956159,
          0.29270801085533366,
          0.2949467956860501,
          0.2952064598679508,
          0.2920525486184312,
          0.29210071005862365,
          0.2923748363158205,
          0.29304531218642405,
          0.291801037746936,
          0.29294235133346724,
          0.2914628157385947,
          0.2949097261308798,
          0.2931993956342319,
          0.2945464148373876,
          0.2933439185051431,
          0.2948859548363172,
          0.29367339992660246,
          0.29407552835724027,
          0.2940309714336477,
          0.2936949660000933,
          0.29383139586970386,
          0.2936339015684409,
          0.2933947149467852,
          0.28992452181460665,
          0.2907408368094658,
          0.2870935221947654,
          0.2857317520549645,
          0.2854542203226001,
          0.28540801996042364,
          0.2862614328197429,
          0.28592181517215015,
          0.2868945911831161,
          0.28623170838279943,
          0.28714611993672307,
          0.28641434172183594,
          0.28707064618138983,
          0.28634320615154946,
          0.2863490761951468,
          0.2861754789606282,
          0.2859679156329365,
          0.284537402634144,
          0.28598306652438726,
          0.28436863927346734,
          0.28541068191350866,
          0.2852273829486585,
          0.28769352627672845,
          0.2880654190398009,
          0.28723787723749805,
          0.2880532283368303,
          0.288026877529587,
          0.28917050903129493,
          0.2910057219349501,
          0.29047700114801334,
          0.29114349703154263,
          0.29150334591803023,
          0.29124011130815214,
          0.2918940677684892,
          0.29420900234463226,
          0.2937883279212105,
          0.29422927890073797,
          0.2936569657320779,
          0.29489354291331116,
          0.2947128373366198,
          0.29517064227065176,
          0.29554760587653733,
          0.29509872438937856,
          0.29820641732172787,
          0.29505687741709935,
          0.2992595310518157,
          0.3005860250698965,
          0.298722070116337,
          0.30010278202206375,
          0.29628275958345585,
          0.3005199119455884,
          0.30003828939182775,
          0.300036030927262,
          0.30302655652015104,
          0.3032276565035429,
          0.2951465253381003,
          0.2622558195096211,
          0.13554707217647985,
          0.22922626406768057,
          0.23213631225524908,
          0.282693642872748,
          0.28607435940467774,
          0.2918705259914267,
          0.29199426192943845,
          0.2936895307370452,
          0.29677798162487845,
          0.2990875380833756,
          0.29974358065705003,
          0.2999374452306955,
          0.2990169442197419,
          0.29918270971226374,
          0.2993388052592209,
          0.29489070752226365,
          0.29545251237183956,
          0.29540366470188534,
          0.2962603696255986,
          0.29638931020379616,
          0.2976148019945003,
          0.29862988713065536,
          0.30047022712656873,
          0.30113242150067665,
          0.3005463701788468,
          0.299981198333983,
          0.3003629173704986,
          0.2997050750731064,
          0.30014729057600786,
          0.29991392591310617,
          0.3000792618649214,
          0.3010356590222483,
          0.30054043829119387,
          0.3009255221680367,
          0.3003706047832226,
          0.30272398736453965,
          0.30293678409195923,
          0.30444224667716047,
          0.3040745720854009,
          0.30437718109126,
          0.304273909788373,
          0.30390655952055445,
          0.3046357823524235,
          0.30606670006673475,
          0.30638727179423275,
          0.3065798628053514,
          0.30681546449036345,
          0.30633546656527283,
          0.30714409254251374,
          0.30786898957136516,
          0.3090743721645145,
          0.3091296052625692,
          0.3091390387823247,
          0.30957962922238624,
          0.30896252676975633,
          0.3096434442071,
          0.3099338292727446,
          0.3056226806821485,
          0.30510295264523124,
          0.3058838633053385,
          0.3068370772828199,
          0.30739796145665177,
          0.3068150778765339,
          0.30710832923174414,
          0.30655776036955606,
          0.30691906449130124,
          0.3072167300461461,
          0.3069038049502449,
          0.3077676124242224,
          0.30811264928205945,
          0.30775254600395646,
          0.30818929560255987,
          0.3081904679059186,
          0.3088408948868523,
          0.30856266727628295,
          0.3087393971325342,
          0.30959825093767196,
          0.30902191957221187,
          0.3083482924664278,
          0.3088640617857369,
          0.30896819374362566,
          0.30911652924924976,
          0.3095833362568143,
          0.30915079243257176,
          0.3088299566864968,
          0.3094648996556773,
          0.30946728995327544,
          0.3095007216698552,
          0.3093503783033453,
          0.308999668470455,
          0.3093602044472059,
          0.30982605809404107,
          0.3095971598329439,
          0.3097562746008283,
          0.30997772211706304,
          0.31004583185176515,
          0.31058173370656345,
          0.3107217315936124,
          0.31050309849030094,
          0.31082937879180955,
          0.3108266957140996,
          0.310978290928603,
          0.3110003732258428,
          0.306721292372919,
          0.3068831093169952,
          0.3068749898572237,
          0.306803040152594,
          0.30685581243073257,
          0.3070942050200702,
          0.30668530895887397,
          0.3071766417084438,
          0.30700134778419985,
          0.30685085497154263,
          0.30746552864708193,
          0.307390499271412,
          0.30728067974361695,
          0.3075515690807975,
          0.3072074509967221,
          0.30748663116591,
          0.3074014485472031,
          0.307896581058794,
          0.30788313520320576,
          0.30756026174545326,
          0.3074951079624422,
          0.3076659105818172,
          0.307476203993856,
          0.3072100400743362,
          0.30713784929117877,
          0.30735892364602285,
          0.30732973342961434,
          0.3072275483182498,
          0.3075017245977799,
          0.3073884183365525,
          0.3075241092750326,
          0.3078758948630238,
          0.307708609387938,
          0.3098857910190025,
          0.3100833722393959,
          0.31016184366915595,
          0.3100234922872198,
          0.3107901868372364,
          0.31063753023312046,
          0.31089001548541273,
          0.31065406575049564,
          0.3108889787781851,
          0.3107096958001135,
          0.3109265242578347,
          0.31051436670756843,
          0.31072299563474354,
          0.3107186455083512,
          0.3103883255386216,
          0.3107796023993477,
          0.310774048619587,
          0.310947526928299,
          0.3110569119809576,
          0.3109345369685922,
          0.3113332875465355,
          0.31128758349225333,
          0.31128762770993623,
          0.31128234989583614,
          0.3115336237717584,
          0.3112584688087733,
          0.3114219242050509,
          0.3113065810476745,
          0.3116872679511629,
          0.3111177616639425,
          0.3111541445376967,
          0.3113051308311425,
          0.3118605668736055,
          0.31141209714405726,
          0.3117179837204368,
          0.31337723298918896,
          0.30724308717210436,
          0.30867906398213557,
          0.30896453065891005,
          0.30862044890607393,
          0.30869641233407186,
          0.3087064037842161,
          0.30858159922529377,
          0.3087822994125051,
          0.30858992270165014,
          0.3048201738346644,
          0.30462308187851744,
          0.30456529324606235,
          0.3044967921021997,
          0.30440117800491784,
          0.30428246044218665,
          0.30417262686540214,
          0.30427825993394253,
          0.30407641396831253,
          0.30426322328976074,
          0.304361788341417,
          0.30425350464166556,
          0.3042659524121176,
          0.3040857455184498,
          0.3042298592266185,
          0.3039526628497715,
          0.3040826491462512,
          0.30417379691406543,
          0.30426759332941467,
          0.3041481571650484,
          0.30417537527336236,
          0.3041204151042195,
          0.30385442669803736,
          0.3039089778564587,
          0.3039898966333771,
          0.30379650757786436,
          0.30388159075086296,
          0.30389754376906747,
          0.30385986396951603,
          0.30366946411398055,
          0.30360067502685634,
          0.3035949973896387,
          0.30375302399012116,
          0.30368648323931424,
          0.30362117203209044,
          0.30367574253429885,
          0.30386849737787697,
          0.30373162864076725,
          0.3040800796129924,
          0.30392809596503995,
          0.3038196996324244,
          0.3038636993469407,
          0.3036772745771123,
          0.303735342176515,
          0.3037946719005868,
          0.30400068215625303,
          0.3037225834944592,
          0.30404947331638627,
          0.30389681318257733,
          0.30411618488717246,
          0.30410832764200874,
          0.30388550691624744,
          0.3042424545771694,
          0.3041790648218609,
          0.30425350723072636,
          0.3043354318823023,
          0.30442550925457107,
          0.3045855784251829,
          0.30453202683428165,
          0.3043396942135637,
          0.3042632490390336,
          0.30434067219230404,
          0.3064307334350959,
          0.30634805726553466,
          0.3061651840392266,
          0.3064201795205172,
          0.3064486817044093,
          0.3062920632316357,
          0.3062281664708445,
          0.30637169098722045,
          0.30646966564778366,
          0.30660413808348647,
          0.3064980837930643,
          0.3084295015814298,
          0.30860929524727343,
          0.30855823166050245,
          0.3086070442322807,
          0.3086965055347725,
          0.30879912049640895,
          0.30889500302359263,
          0.308980731459453,
          0.30879788404402025,
          0.30890751563886387,
          0.3088075950799914,
          0.30917155195376056,
          0.3091612214825182,
          0.3092122174466905,
          0.30904128329849295,
          0.30902810138688125,
          0.3090636428356465,
          0.30931789434126644,
          0.309273088688741,
          0.3094486436764571,
          0.3053131354275249,
          0.30924249094546163,
          0.3054685133674987,
          0.3053035915419524
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Validation performance by epoch of training"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "performance"
         }
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"14765f35-657d-42ec-a84b-bbd041ef978f\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"14765f35-657d-42ec-a84b-bbd041ef978f\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '14765f35-657d-42ec-a84b-bbd041ef978f',\n",
       "                        [{\"hovertemplate\": \"ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Val ROC-AUC\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0], \"xaxis\": \"x\", \"y\": [0.6767765108125108, 0.7171845961528407, 0.7653445918433631, 0.7857349956509134, 0.7992520204636807, 0.8113153887956753, 0.8176825626181343, 0.8258582910703506, 0.825962463183278, 0.8371401705095483, 0.8414147919647257, 0.8473573555017927, 0.851457696615951, 0.8561446495143124, 0.8585540752289014, 0.8592508005012935, 0.8608846786983476, 0.8661455684470196, 0.8669567642161267, 0.8681739539614713, 0.8712761440316112, 0.8737239906395614, 0.874734420525788, 0.876592882707746, 0.8775874689266074, 0.878191112653228, 0.8783162776254145, 0.879550103221493, 0.8793821603474199, 0.8798899498864802, 0.8801343384555911, 0.8798859889696388, 0.8809320671074374, 0.8802357379267294, 0.8817903977869566, 0.8814545120388106, 0.882027656705753, 0.8813024128321031, 0.8820597401321679, 0.8811305090411887, 0.8813016206487347, 0.8793342332536398, 0.8807795718090459, 0.8799735252318326, 0.880282080653773, 0.8798681648438528, 0.879331856703535, 0.8788331772732098, 0.8791322264947312, 0.8774924069224153, 0.8776853035725886, 0.8770190773598745, 0.8769489691317829, 0.8767148789464595, 0.875280234866525, 0.8754030232886066, 0.8757060334269693, 0.8743957621358531, 0.8725701755636781, 0.8730264731838008, 0.8734435577271942, 0.8724854119432733, 0.8720192120310473, 0.8713882379782212, 0.8700744018619478, 0.8684096285135311, 0.8691463590460211, 0.8685031061509869, 0.8664038202250751, 0.866500466596004, 0.8666680133783927, 0.8644380171967165, 0.8645711040025857, 0.8660572400014577, 0.8641773888685561, 0.8646942885163514, 0.8635646350332005, 0.8618820375589978, 0.860413725685912, 0.8609702345021206, 0.8582482924487496, 0.8603634220420271, 0.8582051184551791, 0.8587901458726455, 0.857667622039809, 0.8552043278561775, 0.8562424841602936, 0.8558151012331128, 0.854017637170511, 0.8547908081379414, 0.8525445721972156, 0.85372532150762, 0.8505466857424423, 0.8513879844795433, 0.8517575380208408, 0.8480913133924936, 0.848744468579631, 0.8516272238567606, 0.8376234023641922, 0.8528246090178987, 0.8736930954881988, 0.8357027537878245, 0.7217487606291204, 0.7006394504148663, 0.785362273376143, 0.7802511062840738, 0.796288858574672, 0.8134538877983164, 0.8162514833633571, 0.8197481807508947, 0.8226875771388555, 0.826732069325551, 0.8288139272173609, 0.8321771417073452, 0.8345113100019488, 0.836868451614232, 0.8375251716265267, 0.8389229791798367, 0.8400245101534143, 0.8414175646065145, 0.8425594969318738, 0.8425721718657663, 0.8437402462422782, 0.8436721184726071, 0.8443403251437418, 0.8440369189136947, 0.8445439162693866, 0.8447962266721802, 0.8444171669304636, 0.8444108294635175, 0.8442733856491229, 0.8446215502394772, 0.8444928204421335, 0.8410598938157413, 0.8437327205002796, 0.8437850046025853, 0.843003119618104, 0.8391051813545385, 0.8422881741282418, 0.8420342793587117, 0.8418342530582239, 0.8411113857346788, 0.8407426243767497, 0.8365503899918721, 0.8407675781528501, 0.8408594714235692, 0.8404974436242706, 0.840194829577592, 0.8402296856457958, 0.8403433639591423, 0.8397729919339889, 0.8397119938146322, 0.8392279697766201, 0.839950441008481, 0.8390992399792765, 0.8395111753307762, 0.8391986589919942, 0.8398308213198725, 0.8398755796801797, 0.8396359442112784, 0.8396121787102303, 0.8397195195566307, 0.8392117300175705, 0.8397797254926191, 0.8392964936379753, 0.8397595248167283, 0.8396006920513905, 0.8401659148846502, 0.8394390866442637, 0.8395111753307762, 0.8393464011901763, 0.8396201005439132, 0.8392089573757816, 0.8396141591686509, 0.8392850069791356, 0.8396034646931795, 0.8392382681604076, 0.8400142117696267, 0.839295305362923, 0.8397480381578886, 0.8404966514409025, 0.8401948295775921, 0.8397345710406278, 0.8405101185581629, 0.8407537149439053, 0.8415787739219572, 0.84179939699002, 0.8422596555269842, 0.8424790903199945, 0.84291360289749, 0.8426094044840748, 0.8436388467711398, 0.8435711150931529, 0.8443918170626792, 0.844105046683366, 0.8446033300220069, 0.8448528677830116, 0.8448548482414321, 0.8447304754526139, 0.845332534812498, 0.8452509399255664, 0.8451095351943304, 0.8447752338129211, 0.8449867467722489, 0.8448310827403842, 0.845462452884894, 0.845373332255964, 0.845287776452191, 0.8450390308745547, 0.8446274916147389, 0.845467998168472, 0.8453111458615548, 0.8455753390148724, 0.8451586505631632, 0.844869107542061, 0.8453559042218621, 0.8447225536189313, 0.844630660348212, 0.8437699531185883, 0.8425448415395609, 0.8333123404740743, 0.8371552219935451, 0.8043996279906902, 0.7799667124548655, 0.8395523688659262, 0.8216811081694702, 0.8312823705928859, 0.8339603464693178, 0.8332889710647103, 0.8344732852002719, 0.8364026477936903, 0.8370462967804084, 0.837546956669154, 0.8381315879949365, 0.8383672625469962, 0.8387471144720811, 0.8394279960771079, 0.8395713812667646, 0.8399195458571185, 0.8399607393922686, 0.840150467308969, 0.8402863267566271, 0.8405517081849969, 0.8410357322230091, 0.8415680794464856, 0.8419483274632547, 0.8424497795353687, 0.8425721718657662, 0.8432993961978368, 0.8433203890570957, 0.8433580177670886, 0.843581017385256, 0.843937499900977, 0.8443015081586965, 0.8443779538537345, 0.8444607370157184, 0.8445597599367521, 0.8450822048681252, 0.8452141033989421, 0.8454244280832173, 0.8453757088060688, 0.8457325874134738, 0.8458256689592454, 0.8458981537374419, 0.8464233713106041, 0.846376236400192, 0.8466428061036144, 0.8468903634061984, 0.8466186445108821, 0.8472508068387606, 0.8469735426598666, 0.8475043055166065, 0.8471573292013048, 0.8477744400451862, 0.8477597846528733, 0.8480802228253379, 0.8477459214439285, 0.8481384483029055, 0.8483467925287602, 0.8486018755733427, 0.8480540807741851, 0.8488910225027607, 0.8486692111596454, 0.8489425144216982, 0.8489033013449689, 0.8492974125706825, 0.8489884610570577, 0.8494308954682359, 0.8494823873871732, 0.8495057567965372, 0.8498812517130965, 0.8499901769262335, 0.8500052284102305, 0.850345471166902, 0.8502567466296559, 0.850587879277592, 0.8502444677874477, 0.8504698439557201, 0.8496740957622945, 0.8500745444549541, 0.8512137041385244, 0.8505272772499195, 0.8510592283817119, 0.8511487451023263, 0.8513824391959656, 0.8515321618525684, 0.851610191914343, 0.8517199093108481, 0.8519377597371218, 0.8519536034044872, 0.8521849209480217, 0.8521635319970784, 0.852318799937259, 0.8523085015534715, 0.8525010021119609, 0.8525326894466916, 0.8526673606192973, 0.852168285097288, 0.852012224973739, 0.8519124098693373, 0.8516577229164389, 0.8516569307330708, 0.8516296004068653, 0.8516882219761173, 0.8515638491872991, 0.8515895951467678, 0.8515175064602554, 0.8515040393429948, 0.8516133606478158, 0.8515357266777256, 0.8516062309975015, 0.8514580927076352, 0.8516387105156005, 0.8515008706095216, 0.8516498010827561, 0.8516553463663341, 0.8517242663193735, 0.8516133606478159, 0.8518613140420839, 0.8516676252085422, 0.8517888292638873, 0.8516723783087518, 0.8517385256200024, 0.8516795079590662, 0.8517020851850621, 0.8515800889463486, 0.851672774400436, 0.8515555312619323, 0.8516090036392905, 0.8514687871831068, 0.8515745436627707, 0.8515198830103601, 0.8515301813941477, 0.8514363076650079, 0.8515571156286689, 0.8514137304390121, 0.8515816733130852, 0.8514573005242669, 0.8516656447501216, 0.8515171103685713, 0.8516256394900241, 0.8515674140124563, 0.8517222858609528, 0.8516882219761172, 0.851752388828947, 0.8516771314089615, 0.8517626872127345, 0.8516343535070751, 0.8517777386967316, 0.8516957477181158, 0.8517626872127346, 0.8517309998780038, 0.8517797191551524, 0.8517001047266413, 0.8518664632339777, 0.8517983354643066, 0.8519108255026007, 0.8518165556817767, 0.8519512268543825, 0.8518759694343968, 0.8520062835984772, 0.8518862678181844, 0.8520779761933054, 0.8519330066369121, 0.8521496687881336, 0.8520039070483725, 0.8522078942657013, 0.8521112478947727, 0.8522296793083288, 0.8521231306452967, 0.8522863204191601, 0.8522142317326475, 0.8523920768988238, 0.8523627661141981, 0.8524697108689143, 0.8523996026408225, 0.8525200145127994, 0.8524328743422896, 0.8525113004957483, 0.8525128848624848, 0.8525675455148953, 0.852654685685405, 0.8526467638517222, 0.8526962753122391, 0.8527358844806524, 0.8526733019945593, 0.8528594650861024, 0.8527905451330631, 0.8528709517449422, 0.8528143106341112, 0.8529901753418666, 0.8527477672311764, 0.8530147330262831, 0.8529339303227197, 0.8530876138961638, 0.85305275782796, 0.8530123564761782, 0.8531430667319427, 0.8531097950304753, 0.8531597025826763, 0.8531810915336194, 0.8532191163352963, 0.8531216777809992, 0.8532611020538147, 0.8533292298234857, 0.8533070486891742, 0.8534044872434711, 0.8533890396677901, 0.853451226062199, 0.853383098292528, 0.8535668848339663, 0.8535462880663913, 0.8535280678489212, 0.8535403466911293, 0.8536948224479416, 0.8536167923861672, 0.8537629502176127, 0.8537680994095065, 0.8538033515693946, 0.8538861347313786, 0.8538651418721194, 0.8538599926802257, 0.8540358573879813, 0.8539855537440961, 0.854034669112929, 0.8540342730212449, 0.8540798235649202, 0.8540596228890294, 0.854185580044584, 0.8541954823366874, 0.8541400295009085, 0.8542461820722566, 0.8543543151020253, 0.8543558994687618, 0.8543606525689714, 0.854500869025155, 0.8544275920635901, 0.8545420625603051, 0.8545943466626106, 0.8547230764599544, 0.8545666202447212, 0.8547234725516385, 0.8546941617670125, 0.8548716108415048, 0.854843092240247, 0.8548981489843418, 0.8549013177178147, 0.8549155770184436, 0.854963504112224, 0.8549916266217974, 0.8550510403744176, 0.85504074199063, 0.8551009479266185, 0.8551516476621878, 0.8552570080501674, 0.85520551613123, 0.8553184022612081, 0.8554253470159243, 0.8553572192462534, 0.855385737847511, 0.8555085262695926, 0.8554942669689638, 0.8555940820733657, 0.8556740925935609, 0.8556883518941897, 0.8557984653823788, 0.8557937122821694, 0.8558697618855232, 0.8559315521882482, 0.8560301790175975, 0.8559672004398202, 0.8560242376423355, 0.8560678077275903, 0.8560828592115874, 0.856152571347995, 0.8562428802519777, 0.8561070208043197, 0.8562896190707056, 0.8562947682625992, 0.8563090275632281], \"yaxis\": \"y\"}, {\"hovertemplate\": \"Avg precision = %{y:.4f}<br>epoch = %{x}<br>\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Val avg precision\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 481.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0], \"xaxis\": \"x\", \"y\": [0.05340468671384806, 0.10401419973338867, 0.13563413688505227, 0.14104468031278425, 0.15382355608961235, 0.16307885644094067, 0.16762967320764557, 0.17921485875804813, 0.18586756841505012, 0.19835730856023945, 0.21226879726778766, 0.2244592413245426, 0.23666776971723197, 0.24792981669051684, 0.2542497456244058, 0.2580437940457585, 0.26602991498406153, 0.2768796473456159, 0.2793336579875792, 0.2851776145791968, 0.292144814758461, 0.29683538184475217, 0.30546095446009414, 0.3105731044380617, 0.3125604358957341, 0.31443820535521905, 0.3176981516065062, 0.3192932041014412, 0.32180913208826034, 0.326609355386303, 0.32839951808813445, 0.3292462286271016, 0.33147572667533376, 0.3318812520519076, 0.328532827415493, 0.33439573930009137, 0.33220009922869065, 0.3328216801120181, 0.3356145181972293, 0.33402168167834023, 0.3345608571858982, 0.33524265293753686, 0.33579225320408823, 0.33601268315194843, 0.3354836130969042, 0.3361838910961422, 0.33566743420338296, 0.3359001345736193, 0.3354856535059442, 0.3353664701871836, 0.3384681072730719, 0.3405115847068479, 0.34054690775866187, 0.34075029054920025, 0.3398043464030325, 0.3407536933071192, 0.33875860460858104, 0.3404790541252663, 0.33904482426826305, 0.3396982705212689, 0.3387190815993787, 0.34058594946010795, 0.3403931823379573, 0.3406940813083099, 0.33918218452234516, 0.3407240014749697, 0.33885759044450664, 0.3358202309497452, 0.33420617996452506, 0.33299820814277215, 0.3325456687858142, 0.3331744395236074, 0.3314757710681743, 0.33118155818272255, 0.33100575957492706, 0.33216557272441183, 0.33064635310041446, 0.3327482042362402, 0.33036140250015117, 0.33300791522909057, 0.331750737882746, 0.33211719307924725, 0.329333246975594, 0.33081143935561114, 0.32950126548057257, 0.32872349939145185, 0.3289162244927627, 0.32789166507761874, 0.32638325766455084, 0.32632978504906235, 0.32445955808699123, 0.32295330023136176, 0.3223676378992841, 0.32731398026978786, 0.32493568532593425, 0.3271813959113548, 0.3262570370281022, 0.3285603105560572, 0.3284612943890324, 0.3240346215414763, 0.2338072505243283, 0.14539017915778812, 0.17110061297386103, 0.14587100547750126, 0.19088060674759183, 0.21278784628876024, 0.23863097865053046, 0.2508740789174544, 0.25551926036238576, 0.26246941776120697, 0.2708295054180395, 0.2765665387095343, 0.28215120936217236, 0.28575066778142033, 0.28946963446323365, 0.2894280053605777, 0.2956822465067857, 0.29768017373241273, 0.2979481238917812, 0.2982453822702377, 0.2911229702620904, 0.29298168077788816, 0.2917209566483042, 0.2882258192488952, 0.2897389487377955, 0.2897855233394996, 0.29215749224909743, 0.292056693406425, 0.2917032487057498, 0.2911664223504843, 0.29150752205751385, 0.2911826011764091, 0.2918458307660031, 0.28878994199014313, 0.2903602596035671, 0.29016436450935834, 0.2885726934393131, 0.2883475703474341, 0.2891017837892116, 0.29243652206655424, 0.29233014725170936, 0.2923632479592192, 0.2928520317956159, 0.29270801085533366, 0.2949467956860501, 0.2952064598679508, 0.2920525486184312, 0.29210071005862365, 0.2923748363158205, 0.29304531218642405, 0.291801037746936, 0.29294235133346724, 0.2914628157385947, 0.2949097261308798, 0.2931993956342319, 0.2945464148373876, 0.2933439185051431, 0.2948859548363172, 0.29367339992660246, 0.29407552835724027, 0.2940309714336477, 0.2936949660000933, 0.29383139586970386, 0.2936339015684409, 0.2933947149467852, 0.28992452181460665, 0.2907408368094658, 0.2870935221947654, 0.2857317520549645, 0.2854542203226001, 0.28540801996042364, 0.2862614328197429, 0.28592181517215015, 0.2868945911831161, 0.28623170838279943, 0.28714611993672307, 0.28641434172183594, 0.28707064618138983, 0.28634320615154946, 0.2863490761951468, 0.2861754789606282, 0.2859679156329365, 0.284537402634144, 0.28598306652438726, 0.28436863927346734, 0.28541068191350866, 0.2852273829486585, 0.28769352627672845, 0.2880654190398009, 0.28723787723749805, 0.2880532283368303, 0.288026877529587, 0.28917050903129493, 0.2910057219349501, 0.29047700114801334, 0.29114349703154263, 0.29150334591803023, 0.29124011130815214, 0.2918940677684892, 0.29420900234463226, 0.2937883279212105, 0.29422927890073797, 0.2936569657320779, 0.29489354291331116, 0.2947128373366198, 0.29517064227065176, 0.29554760587653733, 0.29509872438937856, 0.29820641732172787, 0.29505687741709935, 0.2992595310518157, 0.3005860250698965, 0.298722070116337, 0.30010278202206375, 0.29628275958345585, 0.3005199119455884, 0.30003828939182775, 0.300036030927262, 0.30302655652015104, 0.3032276565035429, 0.2951465253381003, 0.2622558195096211, 0.13554707217647985, 0.22922626406768057, 0.23213631225524908, 0.282693642872748, 0.28607435940467774, 0.2918705259914267, 0.29199426192943845, 0.2936895307370452, 0.29677798162487845, 0.2990875380833756, 0.29974358065705003, 0.2999374452306955, 0.2990169442197419, 0.29918270971226374, 0.2993388052592209, 0.29489070752226365, 0.29545251237183956, 0.29540366470188534, 0.2962603696255986, 0.29638931020379616, 0.2976148019945003, 0.29862988713065536, 0.30047022712656873, 0.30113242150067665, 0.3005463701788468, 0.299981198333983, 0.3003629173704986, 0.2997050750731064, 0.30014729057600786, 0.29991392591310617, 0.3000792618649214, 0.3010356590222483, 0.30054043829119387, 0.3009255221680367, 0.3003706047832226, 0.30272398736453965, 0.30293678409195923, 0.30444224667716047, 0.3040745720854009, 0.30437718109126, 0.304273909788373, 0.30390655952055445, 0.3046357823524235, 0.30606670006673475, 0.30638727179423275, 0.3065798628053514, 0.30681546449036345, 0.30633546656527283, 0.30714409254251374, 0.30786898957136516, 0.3090743721645145, 0.3091296052625692, 0.3091390387823247, 0.30957962922238624, 0.30896252676975633, 0.3096434442071, 0.3099338292727446, 0.3056226806821485, 0.30510295264523124, 0.3058838633053385, 0.3068370772828199, 0.30739796145665177, 0.3068150778765339, 0.30710832923174414, 0.30655776036955606, 0.30691906449130124, 0.3072167300461461, 0.3069038049502449, 0.3077676124242224, 0.30811264928205945, 0.30775254600395646, 0.30818929560255987, 0.3081904679059186, 0.3088408948868523, 0.30856266727628295, 0.3087393971325342, 0.30959825093767196, 0.30902191957221187, 0.3083482924664278, 0.3088640617857369, 0.30896819374362566, 0.30911652924924976, 0.3095833362568143, 0.30915079243257176, 0.3088299566864968, 0.3094648996556773, 0.30946728995327544, 0.3095007216698552, 0.3093503783033453, 0.308999668470455, 0.3093602044472059, 0.30982605809404107, 0.3095971598329439, 0.3097562746008283, 0.30997772211706304, 0.31004583185176515, 0.31058173370656345, 0.3107217315936124, 0.31050309849030094, 0.31082937879180955, 0.3108266957140996, 0.310978290928603, 0.3110003732258428, 0.306721292372919, 0.3068831093169952, 0.3068749898572237, 0.306803040152594, 0.30685581243073257, 0.3070942050200702, 0.30668530895887397, 0.3071766417084438, 0.30700134778419985, 0.30685085497154263, 0.30746552864708193, 0.307390499271412, 0.30728067974361695, 0.3075515690807975, 0.3072074509967221, 0.30748663116591, 0.3074014485472031, 0.307896581058794, 0.30788313520320576, 0.30756026174545326, 0.3074951079624422, 0.3076659105818172, 0.307476203993856, 0.3072100400743362, 0.30713784929117877, 0.30735892364602285, 0.30732973342961434, 0.3072275483182498, 0.3075017245977799, 0.3073884183365525, 0.3075241092750326, 0.3078758948630238, 0.307708609387938, 0.3098857910190025, 0.3100833722393959, 0.31016184366915595, 0.3100234922872198, 0.3107901868372364, 0.31063753023312046, 0.31089001548541273, 0.31065406575049564, 0.3108889787781851, 0.3107096958001135, 0.3109265242578347, 0.31051436670756843, 0.31072299563474354, 0.3107186455083512, 0.3103883255386216, 0.3107796023993477, 0.310774048619587, 0.310947526928299, 0.3110569119809576, 0.3109345369685922, 0.3113332875465355, 0.31128758349225333, 0.31128762770993623, 0.31128234989583614, 0.3115336237717584, 0.3112584688087733, 0.3114219242050509, 0.3113065810476745, 0.3116872679511629, 0.3111177616639425, 0.3111541445376967, 0.3113051308311425, 0.3118605668736055, 0.31141209714405726, 0.3117179837204368, 0.31337723298918896, 0.30724308717210436, 0.30867906398213557, 0.30896453065891005, 0.30862044890607393, 0.30869641233407186, 0.3087064037842161, 0.30858159922529377, 0.3087822994125051, 0.30858992270165014, 0.3048201738346644, 0.30462308187851744, 0.30456529324606235, 0.3044967921021997, 0.30440117800491784, 0.30428246044218665, 0.30417262686540214, 0.30427825993394253, 0.30407641396831253, 0.30426322328976074, 0.304361788341417, 0.30425350464166556, 0.3042659524121176, 0.3040857455184498, 0.3042298592266185, 0.3039526628497715, 0.3040826491462512, 0.30417379691406543, 0.30426759332941467, 0.3041481571650484, 0.30417537527336236, 0.3041204151042195, 0.30385442669803736, 0.3039089778564587, 0.3039898966333771, 0.30379650757786436, 0.30388159075086296, 0.30389754376906747, 0.30385986396951603, 0.30366946411398055, 0.30360067502685634, 0.3035949973896387, 0.30375302399012116, 0.30368648323931424, 0.30362117203209044, 0.30367574253429885, 0.30386849737787697, 0.30373162864076725, 0.3040800796129924, 0.30392809596503995, 0.3038196996324244, 0.3038636993469407, 0.3036772745771123, 0.303735342176515, 0.3037946719005868, 0.30400068215625303, 0.3037225834944592, 0.30404947331638627, 0.30389681318257733, 0.30411618488717246, 0.30410832764200874, 0.30388550691624744, 0.3042424545771694, 0.3041790648218609, 0.30425350723072636, 0.3043354318823023, 0.30442550925457107, 0.3045855784251829, 0.30453202683428165, 0.3043396942135637, 0.3042632490390336, 0.30434067219230404, 0.3064307334350959, 0.30634805726553466, 0.3061651840392266, 0.3064201795205172, 0.3064486817044093, 0.3062920632316357, 0.3062281664708445, 0.30637169098722045, 0.30646966564778366, 0.30660413808348647, 0.3064980837930643, 0.3084295015814298, 0.30860929524727343, 0.30855823166050245, 0.3086070442322807, 0.3086965055347725, 0.30879912049640895, 0.30889500302359263, 0.308980731459453, 0.30879788404402025, 0.30890751563886387, 0.3088075950799914, 0.30917155195376056, 0.3091612214825182, 0.3092122174466905, 0.30904128329849295, 0.30902810138688125, 0.3090636428356465, 0.30931789434126644, 0.309273088688741, 0.3094486436764571, 0.3053131354275249, 0.30924249094546163, 0.3054685133674987, 0.3053035915419524], \"yaxis\": \"y2\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Validation performance by epoch of training\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.94], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"performance\"}}, \"yaxis2\": {\"anchor\": \"x\", \"overlaying\": \"y\", \"side\": \"right\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('14765f35-657d-42ec-a84b-bbd041ef978f');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epoch_performances.epoch,\n",
    "               y=epoch_performances.roc_auc, name='Val ROC-AUC',\n",
    "               hovertemplate =\n",
    "                'ROC-AUC = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epoch_performances.epoch,\n",
    "               y=epoch_performances.avg_prec_score, name='Val avg precision',\n",
    "               hovertemplate = 'Avg precision = %{y:.4f}<br>'+\n",
    "                               'epoch = %{x}<br>',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Validation performance by epoch of training',\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='performance', secondary_y=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, tests will explore alternative **activation functions for hidden neurons** and options for **cost function**. Until now, only rectified linear units (ReLU) were considered for hidden layers together with cross-entropy cost function. First, different cost functions will be tried on. These are the alternatives covered here:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Binary cross-entropy: } C(y, a^L(x)) = -\\frac{1}{N}\\sum_x[y\\log(a^L(x)) + (1 - y)\\log(1 - a^L(x))]\n",
    "\\end{equation}\n",
    "Where $y \\in \\{0, 1\\}$.\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Hinge loss: } C(y, a^L(x)) = -\\frac{1}{N}\\sum_x\\max{(0, 1 - ya^L(x))}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $y \\in \\{-1, 1\\}$.\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Squared Hinge loss: } C(y, a^L(x)) = -\\frac{1}{N}\\sum_x\\max{(0, 1 - ya^L(x))^2}\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $y \\in \\{-1, 1\\}$.\n",
    "<br>\n",
    "<br>\n",
    "Making use of the best cost function found among those alternatives, tests turn to defining the most appropriate activation function. While *sigmoid activation* will still be applied for the output neuron, the following alternatives configure a grid of alternative activation functions for hidden neurons:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Sigmoid activation: } \\sigma(z_j^l) = \\frac{1}{1 + \\exp{(z_j^l)}}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Tanh activation: } \\tanh(z_j^l) = \\frac{\\exp{(z_j^l)} - \\exp{(-z_j^l)}}{\\exp{(z_j^l)} + \\exp{(-z_j^l)}}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Rectified linear unit (ReLU) activation: } relu(z_j^l) = \\max{(0, z_j^l)}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Exponential linear unit (ELU) activation: } elu(z_j^l) =\n",
    "    \\left \\{\n",
    "    \\begin{array}{ll}\n",
    "    \\alpha(\\exp{(z_j^l)}-1), & \\mbox{ if } z_j^l \\leq 0 \\\\\n",
    "    z_j^l, & \\mbox{ if } z_j^l > 0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Scaled exponential linear unit (SELU) activation: } selu(z_j^l) = \n",
    "    \\left \\{\n",
    "    \\begin{array}{ll}\n",
    "    \\lambda \\alpha(\\exp{(z_j^l)}-1), & \\mbox{ if } z_j^l \\leq 0 \\\\\n",
    "    \\lambda z_j^l, & \\mbox{ if } z_j^l > 0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "<br>\n",
    "Where $\\lambda = 1.05070098$ and $\\alpha = 1.67326324$.\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Leaky rectified linear unit (ReLU) activation: } leaky_relu(z_j^l) = \n",
    "    \\left \\{\n",
    "    \\begin{array}{ll}\n",
    "    0.01z_j^l, & \\mbox{ if } z_j^l \\leq 0 \\\\\n",
    "    z_j^l, & \\mbox{ if } z_j^l > 0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Parametric rectified linear unit (PReLU) activation: } prelu(z_j^l) = \n",
    "    \\left \\{\n",
    "    \\begin{array}{ll}\n",
    "    \\alpha z_j^l, & \\mbox{ if } z_j^l \\leq 0 \\\\\n",
    "    z_j^l, & \\mbox{ if } z_j^l > 0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\mbox{Swish activation: } swish(z_j^l) = \\frac{z_j^l}{1 + \\exp{(z_j^l)}}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above:\n",
    "* Random samples of training and validation data.\n",
    "* Fitting hyper-parameters: *after tests from last section, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$.*\n",
    "* *After tests for number of neurons and number of hidden layers, the architecture will be given by two hidden layers with the following number of neurons:*\n",
    "    * $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "    * $J_2 = J_1/2$.\n",
    "<br>\n",
    "<br>\n",
    "* Adam optimizer for model estimation (non-fixed and parameter-specific learning rates).\n",
    "* No regularization, no dropout and no early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cost_function'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_functions = ['binary_crossentropy', 'hinge', 'squared_hinge']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 50.88 minutes.\n",
      "Start time: 2021-01-15, 21:55:12\n",
      "End time: 2021-01-15, 22:46:06\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(cost_functions),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over cost functions:\n",
    "for c in range(len(cost_functions)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "    \n",
    "    if cost_functions[c] not in ['hinge', 'squared_hinge']:\n",
    "        y_train = sample_train_scaled['y'].values\n",
    "        y_val = samplescaled['y'].values\n",
    "\n",
    "    else:\n",
    "        # Converting labels 0 into -1 in order to apply Hinge cost functions:\n",
    "        y_train = []\n",
    "        y_val = []\n",
    "\n",
    "        # Loop over observations\n",
    "        for i in sample_train_scaled['y'].values:\n",
    "            if i == 0:\n",
    "                y_train.append(-1.0)\n",
    "            else:\n",
    "                y_train.append(1.0)\n",
    "\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        # Loop over observations\n",
    "        for i in samplescaled['y'].values:\n",
    "            if i == 0:\n",
    "                y_val.append(-1.0)\n",
    "            else:\n",
    "                y_val.append(1.0)\n",
    "\n",
    "        y_val = np.array(y_val)\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_functions[c],\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_functions[c],\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative cost functions.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(c+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>batch_sizes</th>\n",
       "      <th>cost_function</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1610758512</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>0.825063</td>\n",
       "      <td>0.012350</td>\n",
       "      <td>0.216830</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>66.807243</td>\n",
       "      <td>13.005352</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1610759513</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>hinge</td>\n",
       "      <td>0.695188</td>\n",
       "      <td>0.037362</td>\n",
       "      <td>0.117656</td>\n",
       "      <td>0.031940</td>\n",
       "      <td>18.606750</td>\n",
       "      <td>3.683641</td>\n",
       "      <td>17.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1610760546</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>0.685966</td>\n",
       "      <td>0.032641</td>\n",
       "      <td>0.106505</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>21.015342</td>\n",
       "      <td>3.390197</td>\n",
       "      <td>16.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "0    1610758512  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1    1610759513  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2    1610760546  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "   num_layers num_neurons  batch_sizes        cost_function  avg_roc_auc  \\\n",
       "0           2    [45, 22]          512  binary_crossentropy     0.825063   \n",
       "1           2    [45, 22]          512                hinge     0.695188   \n",
       "2           2    [45, 22]          512        squared_hinge     0.685966   \n",
       "\n",
       "   std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "0     0.012350  0.216830  0.016672      66.807243   13.005352         16.67  \n",
       "1     0.037362  0.117656  0.031940      18.606750    3.683641         17.22  \n",
       "2     0.032641  0.106505  0.031416      21.015342    3.390197         16.98  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "costs = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative cost functions.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    costs.append(e['architecture']['cost_function'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std__roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std__avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std__roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std__avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by cost function:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'batch_sizes': batch_sizes,\n",
    "    'cost_function': costs,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_ues('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='activation_functions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regul_param = 0\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: {'neurons': 45, 'activation': 'sigmoid', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'sigmoid', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'elu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'elu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'selu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'selu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'leaky_relu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'leaky_relu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'prelu', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'prelu', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'swish', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'swish', 'dropout_param': 0}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_functions = ['sigmoid', 'tanh', 'relu', 'elu', 'selu', 'leaky_relu', 'prelu', 'swish']\n",
    "\n",
    "model_architectures = [\n",
    "    {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "         'activation': a,\n",
    "         'dropout_param': 0},\n",
    "     2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "         'activation': a,\n",
    "         'dropout_param': 0}} for a in activation_functions]\n",
    "\n",
    "model_architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 20.7 minutes.\n",
      "Start time: 2021-01-17, 17:41:12\n",
      "End time: 2021-01-17, 18:01:55\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(activation_functions),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over activation functions:\n",
    "for a in range(len(activation_functions)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architectures[a], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architectures[a]),\n",
    "            'num_hidden_neurons': [model_architectures[a][l]['neurons'] for l in model_architectures[a].keys()],\n",
    "            'hidden_activations': [model_architectures[a][l]['activation'] for l in model_architectures[a].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architectures[a][l]['dropout_param'] for l in model_architectures[a].keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative activation functions.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(a+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>batch_sizes</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1610905503</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.840113</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.215579</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>68.636417</td>\n",
       "      <td>20.340183</td>\n",
       "      <td>16.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1610908768</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>selu</td>\n",
       "      <td>0.834494</td>\n",
       "      <td>0.012304</td>\n",
       "      <td>0.240145</td>\n",
       "      <td>0.019824</td>\n",
       "      <td>67.821606</td>\n",
       "      <td>12.113811</td>\n",
       "      <td>27.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1610907581</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.833973</td>\n",
       "      <td>0.011489</td>\n",
       "      <td>0.238648</td>\n",
       "      <td>0.018832</td>\n",
       "      <td>72.587216</td>\n",
       "      <td>12.672494</td>\n",
       "      <td>19.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1610910448</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>leaky_relu</td>\n",
       "      <td>0.826563</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.224233</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>82.499836</td>\n",
       "      <td>13.600794</td>\n",
       "      <td>30.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1610912269</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>prelu</td>\n",
       "      <td>0.824457</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.220836</td>\n",
       "      <td>0.016831</td>\n",
       "      <td>80.180429</td>\n",
       "      <td>13.120543</td>\n",
       "      <td>31.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1610916072</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>swish</td>\n",
       "      <td>0.823466</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.216896</td>\n",
       "      <td>0.016818</td>\n",
       "      <td>74.028194</td>\n",
       "      <td>12.896742</td>\n",
       "      <td>20.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1610906515</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.822166</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.218378</td>\n",
       "      <td>0.015513</td>\n",
       "      <td>76.740598</td>\n",
       "      <td>14.077458</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1610904413</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>512</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.011603</td>\n",
       "      <td>0.185369</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>69.221882</td>\n",
       "      <td>12.385405</td>\n",
       "      <td>18.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "1    1610905503  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4    1610908768  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3    1610907581  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5    1610910448  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "6    1610912269  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "7    1610916072  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2    1610906515  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "0    1610904413  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "   num_layers num_neurons  batch_sizes activation_function  avg_roc_auc  \\\n",
       "1           2    [45, 22]          512                tanh     0.840113   \n",
       "4           2    [45, 22]          512                selu     0.834494   \n",
       "3           2    [45, 22]          512                 elu     0.833973   \n",
       "5           2    [45, 22]          512          leaky_relu     0.826563   \n",
       "6           2    [45, 22]          512               prelu     0.824457   \n",
       "7           2    [45, 22]          512               swish     0.823466   \n",
       "2           2    [45, 22]          512                relu     0.822166   \n",
       "0           2    [45, 22]          512             sigmoid     0.803191   \n",
       "\n",
       "   std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "1     0.012240  0.215579  0.010599      68.636417   20.340183         16.85  \n",
       "4     0.012304  0.240145  0.019824      67.821606   12.113811         27.98  \n",
       "3     0.011489  0.238648  0.018832      72.587216   12.672494         19.78  \n",
       "5     0.010019  0.224233  0.016487      82.499836   13.600794         30.35  \n",
       "6     0.010283  0.220836  0.016831      80.180429   13.120543         31.45  \n",
       "7     0.011124  0.216896  0.016818      74.028194   12.896742         20.70  \n",
       "2     0.010714  0.218378  0.015513      76.740598   14.077458         17.77  \n",
       "0     0.011603  0.185369  0.014967      69.221882   12.385405         18.15  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "activations = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over activation functions:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative activation functions.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by activation function:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'batch_sizes': batch_sizes,\n",
    "    'activation_function': activations,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regularization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will explore **L2 regularization** to reduce overfitting and improve generalization. First, different values for the regularization parameter $\\lambda$ will be tried on, revealing appropriate ranges for a complete grid (or random) search that should be implemented in a second round of tests.\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above:\n",
    "* Random samples of training and validation data.\n",
    "* *Following results of tests from an earlier section, cross-entropy cost function will be used. Regarding activation functions, sigmoid will be applied for the neuron in the output layer, while tanh activation function will be used for neurons in hidden layers, since this alternative has shown the best results during tests.*\n",
    "* Fitting hyper-parameters: *after previous tests, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$. However, for the first round of tests, in which only one estimation will take place, $T = 100$ will be used*.\n",
    "* *After tests for number of neurons and number of hidden layers, the architecture will be given by two hidden layers with the following number of neurons:*\n",
    "    * $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "    * $J_2 = J_1/2$.\n",
    "<br>\n",
    "<br>\n",
    "* Adam optimizer for model estimation (non-fixed and parameter-specific learning rates).\n",
    "* No dropout and no early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: for the first round of tests, only one estimation per value of regularization parameter will be implemented. For the second round of tests, a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_overfitting_l2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing overfitting through L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 100\n",
    "es_param = None\n",
    "batch_size = 512\n",
    "regularization = 'l2'\n",
    "input_dropout = 0\n",
    "\n",
    "# Choose a value for the regularization parameter [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]:\n",
    "regul_param = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 3.43 minutes.\n",
      "Start time: 2021-01-23, 12:26:14\n",
      "End time: 2021-01-23, 12:29:40\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "epoch_costs = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "val_roc_auc = []\n",
    "val_avg_prec_score = []\n",
    "val_brier_score = []\n",
    "epoch_performance = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for t in range(n_estimations):\n",
    "    # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "    model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                     output_activation = output_activation, cost_function = cost_function,\n",
    "                     num_epochs = num_epochs, batch_size = batch_size,\n",
    "                     default_adam = default_adam,\n",
    "                     regularization = regularization, regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "    # Training the model:\n",
    "    model.run(train_inputs = X_train, train_output = y_train,\n",
    "              val_inputs = X_val, val_output = y_val,\n",
    "              verbose = 0)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "\n",
    "    # Cost function by training epoch:\n",
    "    model_costs = model.model_costs\n",
    "    epoch_costs.append({'epoch': list(model_costs['epoch']),\n",
    "                        'loss': list(model_costs['loss']),\n",
    "                        'val_loss': list(model_costs['val_loss'])})\n",
    "\n",
    "    min_cost.append(model_costs.loss.min())\n",
    "    epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "    min_cost.append(model_costs.val_loss.min())\n",
    "    epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Running time and performance metrics on validation data by epoch of training:\n",
    "    epoch_performance.append(model.epoch_performance)\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regularization': regularization,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'validation',\n",
    "        'epoch_costs': epoch_costs,\n",
    "        'avg_epoch_costs': {\n",
    "            'epoch': [sum(l)/len(l) for l in zip(*[d['epoch'] for d in epoch_costs])],\n",
    "            'loss': [sum(l)/len(l) for l in zip(*[d['loss'] for d in epoch_costs])],\n",
    "            'val_loss': [sum(l)/len(l) for l in zip(*[d['val_loss'] for d in epoch_costs])]\n",
    "        },\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(val_brier_score),\n",
    "        'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(val_brier_score),\n",
    "        'avg_epoch_performance': {\n",
    "            'roc_auc': [sum(l)/len(l) for l in zip(*[d['epochroc_auc'] for d in epoch_performance])],\n",
    "            'avg_prec_score': [sum(l)/len(l) for l in zip(*[d['epochavg_prec_score'] for d in\n",
    "                                                            epoch_performance])],\n",
    "            'brier_score': [sum(l)/len(l) for l in zip(*[d['epochbrier_score'] for d in\n",
    "                                                         epoch_performance])],\n",
    "            'running_time': [sum(l)/len(l) for l in zip(*[d['running_time'] for d in epoch_performance])]\n",
    "        }\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": '{0}. Assessing overfitting by trying different values for the L2 regularization parameter.'.format(model_architecture_def)\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [model_assessment[e] for e in model_assessment.keys() if\n",
    "            ('Assessing overfitting by trying different values for the L2 regularization parameter.' in\n",
    "            model_assessment[e]['comment']) &\n",
    "            (model_assessment[e]['hyper_parameters']['regul_param'] == regul_param)][0]\n",
    "\n",
    "# Cost function by training epoch:\n",
    "model_costs = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'loss': outcomes['performance_metrics']['avg_epoch_costs']['loss'],\n",
    "    'val_loss': outcomes['performance_metrics']['avg_epoch_costs']['val_loss']\n",
    "})\n",
    "\n",
    "epoch_performances = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'roc_auc': outcomes['performance_metrics']['avg_epoch_performance']['roc_auc'],\n",
    "    'avg_prec_score': outcomes['performance_metrics']['avg_epoch_performance']['avg_prec_score']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "loss = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Training cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.13518796861171722,
          0.0761260911822319,
          0.07699869573116302,
          0.07108493149280548,
          0.06876248121261597,
          0.062022238969802856,
          0.0563831590116024,
          0.05257658660411835,
          0.047081951051950455,
          0.04283904284238815,
          0.04012301191687584,
          0.03694954141974449,
          0.03542492538690567,
          0.033507514744997025,
          0.032138437032699585,
          0.03085760399699211,
          0.029859919100999832,
          0.02852354757487774,
          0.027292653918266296,
          0.026064474135637283,
          0.025267256423830986,
          0.02410949021577835,
          0.02328822761774063,
          0.022338932380080223,
          0.02163088507950306,
          0.02101939171552658,
          0.020249104127287865,
          0.01920023001730442,
          0.018392203375697136,
          0.017724035307765007,
          0.01717452146112919,
          0.01641932874917984,
          0.015787823125720024,
          0.015099105425179005,
          0.014711132273077965,
          0.014063442125916481,
          0.014094794169068336,
          0.013327703811228275,
          0.01278573740273714,
          0.012223483994603157,
          0.011700676754117012,
          0.011324776336550713,
          0.01088903658092022,
          0.010224598459899426,
          0.009714337065815926,
          0.009112768806517124,
          0.008603157475590706,
          0.008134429343044758,
          0.0077828154899179935,
          0.007442190311849117,
          0.007215443532913923,
          0.006949057336896658,
          0.006778904236853123,
          0.006568741984665394,
          0.006419914308935404,
          0.006222723983228207,
          0.006101381499320269,
          0.005945091135799885,
          0.005821025464683771,
          0.005716831889003515,
          0.005595305934548378,
          0.005450888071209192,
          0.005338973831385374,
          0.005260220263153315,
          0.005107293836772442,
          0.004934290423989296,
          0.004866939503699541,
          0.00472587114199996,
          0.004640042316168547,
          0.004452157765626907,
          0.004252145532518625,
          0.0040800077840685844,
          0.003928247839212418,
          0.003817175980657339,
          0.0037420594599097967,
          0.003670609788969159,
          0.0036081415601074696,
          0.0035407559480518103,
          0.0034706308506429195,
          0.003414509352296591,
          0.00334017351269722,
          0.003288442734628916,
          0.0032400768250226974,
          0.0032000229693949223,
          0.0031351293437182903,
          0.0036613671109080315,
          0.0032036006450653076,
          0.00543168606236577,
          0.06937801837921143,
          0.1417844295501709,
          0.043231185525655746,
          0.042261168360710144,
          0.03206431865692139,
          0.02340475097298622,
          0.020543524995446205,
          0.01790492981672287,
          0.016008561477065086,
          0.014442870393395424,
          0.01314721629023552,
          0.012006442993879318
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "val_loss = %{y:.4f}",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.07157256454229355,
          0.06799811124801636,
          0.06682661920785904,
          0.06440000981092453,
          0.061027295887470245,
          0.05884170904755592,
          0.05675433948636055,
          0.055435534566640854,
          0.05375012010335922,
          0.05286407098174095,
          0.05196049436926842,
          0.05105307698249817,
          0.05057121068239212,
          0.05008452758193016,
          0.04956952482461929,
          0.04912377893924713,
          0.04876001924276352,
          0.04841569811105728,
          0.04819482937455177,
          0.04794880747795105,
          0.0478716716170311,
          0.04766097292304039,
          0.04744577035307884,
          0.047335151582956314,
          0.04726354405283928,
          0.04709210619330406,
          0.04709784686565399,
          0.04707682505249977,
          0.046990592032670975,
          0.04696984961628914,
          0.0468781553208828,
          0.04690762981772423,
          0.04692486301064491,
          0.04694274440407753,
          0.04713509604334831,
          0.04727734997868538,
          0.04759033024311066,
          0.047472335398197174,
          0.04757801070809364,
          0.04763496294617653,
          0.047939933836460114,
          0.04791521653532982,
          0.04818829521536827,
          0.04837886616587639,
          0.0487661175429821,
          0.04899965226650238,
          0.049250390380620956,
          0.049465592950582504,
          0.04970945417881012,
          0.04995725676417351,
          0.05023236945271492,
          0.050462495535612106,
          0.05071831867098808,
          0.05095957964658737,
          0.051244527101516724,
          0.05143167823553085,
          0.05158381909132004,
          0.051714226603507996,
          0.05175919458270073,
          0.05198017135262489,
          0.052048634737730026,
          0.052167702466249466,
          0.052350159734487534,
          0.05240941792726517,
          0.05253148823976517,
          0.05270317196846008,
          0.05285836383700371,
          0.05300328880548477,
          0.05326498672366142,
          0.05354461073875427,
          0.053823504596948624,
          0.054032232612371445,
          0.05432944372296333,
          0.05444302037358284,
          0.05486117675900459,
          0.05501308664679527,
          0.05530987307429314,
          0.05554001033306122,
          0.05582200363278389,
          0.056021060794591904,
          0.05628153681755066,
          0.05644722282886505,
          0.05662383884191513,
          0.05679941177368164,
          0.05752319470047951,
          0.05680255591869354,
          0.05630991980433464,
          0.08180999755859375,
          0.07969055324792862,
          0.05843164399266243,
          0.05661479011178017,
          0.052652668207883835,
          0.05196552723646164,
          0.05180870369076729,
          0.050824642181396484,
          0.05098267272114754,
          0.05065727233886719,
          0.05082786828279495,
          0.0505254901945591,
          0.05059167370200157
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost function by epoch of training - Regularization parameter = 0"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cost"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"b21e09d0-209d-436a-a16a-927c68a9bb6a\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"b21e09d0-209d-436a-a16a-927c68a9bb6a\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'b21e09d0-209d-436a-a16a-927c68a9bb6a',\n",
       "                        [{\"hovertemplate\": \"loss = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Training cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.13518796861171722, 0.0761260911822319, 0.07699869573116302, 0.07108493149280548, 0.06876248121261597, 0.062022238969802856, 0.0563831590116024, 0.05257658660411835, 0.047081951051950455, 0.04283904284238815, 0.04012301191687584, 0.03694954141974449, 0.03542492538690567, 0.033507514744997025, 0.032138437032699585, 0.03085760399699211, 0.029859919100999832, 0.02852354757487774, 0.027292653918266296, 0.026064474135637283, 0.025267256423830986, 0.02410949021577835, 0.02328822761774063, 0.022338932380080223, 0.02163088507950306, 0.02101939171552658, 0.020249104127287865, 0.01920023001730442, 0.018392203375697136, 0.017724035307765007, 0.01717452146112919, 0.01641932874917984, 0.015787823125720024, 0.015099105425179005, 0.014711132273077965, 0.014063442125916481, 0.014094794169068336, 0.013327703811228275, 0.01278573740273714, 0.012223483994603157, 0.011700676754117012, 0.011324776336550713, 0.01088903658092022, 0.010224598459899426, 0.009714337065815926, 0.009112768806517124, 0.008603157475590706, 0.008134429343044758, 0.0077828154899179935, 0.007442190311849117, 0.007215443532913923, 0.006949057336896658, 0.006778904236853123, 0.006568741984665394, 0.006419914308935404, 0.006222723983228207, 0.006101381499320269, 0.005945091135799885, 0.005821025464683771, 0.005716831889003515, 0.005595305934548378, 0.005450888071209192, 0.005338973831385374, 0.005260220263153315, 0.005107293836772442, 0.004934290423989296, 0.004866939503699541, 0.00472587114199996, 0.004640042316168547, 0.004452157765626907, 0.004252145532518625, 0.0040800077840685844, 0.003928247839212418, 0.003817175980657339, 0.0037420594599097967, 0.003670609788969159, 0.0036081415601074696, 0.0035407559480518103, 0.0034706308506429195, 0.003414509352296591, 0.00334017351269722, 0.003288442734628916, 0.0032400768250226974, 0.0032000229693949223, 0.0031351293437182903, 0.0036613671109080315, 0.0032036006450653076, 0.00543168606236577, 0.06937801837921143, 0.1417844295501709, 0.043231185525655746, 0.042261168360710144, 0.03206431865692139, 0.02340475097298622, 0.020543524995446205, 0.01790492981672287, 0.016008561477065086, 0.014442870393395424, 0.01314721629023552, 0.012006442993879318], \"yaxis\": \"y\"}, {\"hovertemplate\": \"val_loss = %{y:.4f}\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Validation cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.07157256454229355, 0.06799811124801636, 0.06682661920785904, 0.06440000981092453, 0.061027295887470245, 0.05884170904755592, 0.05675433948636055, 0.055435534566640854, 0.05375012010335922, 0.05286407098174095, 0.05196049436926842, 0.05105307698249817, 0.05057121068239212, 0.05008452758193016, 0.04956952482461929, 0.04912377893924713, 0.04876001924276352, 0.04841569811105728, 0.04819482937455177, 0.04794880747795105, 0.0478716716170311, 0.04766097292304039, 0.04744577035307884, 0.047335151582956314, 0.04726354405283928, 0.04709210619330406, 0.04709784686565399, 0.04707682505249977, 0.046990592032670975, 0.04696984961628914, 0.0468781553208828, 0.04690762981772423, 0.04692486301064491, 0.04694274440407753, 0.04713509604334831, 0.04727734997868538, 0.04759033024311066, 0.047472335398197174, 0.04757801070809364, 0.04763496294617653, 0.047939933836460114, 0.04791521653532982, 0.04818829521536827, 0.04837886616587639, 0.0487661175429821, 0.04899965226650238, 0.049250390380620956, 0.049465592950582504, 0.04970945417881012, 0.04995725676417351, 0.05023236945271492, 0.050462495535612106, 0.05071831867098808, 0.05095957964658737, 0.051244527101516724, 0.05143167823553085, 0.05158381909132004, 0.051714226603507996, 0.05175919458270073, 0.05198017135262489, 0.052048634737730026, 0.052167702466249466, 0.052350159734487534, 0.05240941792726517, 0.05253148823976517, 0.05270317196846008, 0.05285836383700371, 0.05300328880548477, 0.05326498672366142, 0.05354461073875427, 0.053823504596948624, 0.054032232612371445, 0.05432944372296333, 0.05444302037358284, 0.05486117675900459, 0.05501308664679527, 0.05530987307429314, 0.05554001033306122, 0.05582200363278389, 0.056021060794591904, 0.05628153681755066, 0.05644722282886505, 0.05662383884191513, 0.05679941177368164, 0.05752319470047951, 0.05680255591869354, 0.05630991980433464, 0.08180999755859375, 0.07969055324792862, 0.05843164399266243, 0.05661479011178017, 0.052652668207883835, 0.05196552723646164, 0.05180870369076729, 0.050824642181396484, 0.05098267272114754, 0.05065727233886719, 0.05082786828279495, 0.0505254901945591, 0.05059167370200157], \"yaxis\": \"y\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Cost function by epoch of training - Regularization parameter = 0\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"cost\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('b21e09d0-209d-436a-a16a-927c68a9bb6a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': False}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.loss, name='Training cost',\n",
    "               hovertemplate =\n",
    "                'loss = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.val_loss, name='Validation cost',\n",
    "               hovertemplate = 'val_loss = %{y:.4f}',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Cost function by epoch of training - Regularization parameter = {0}'.format(regul_param),\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='cost', secondary_y=False)\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"Plots/epoch_costs_\" + regularization + \"_regul_param_\" + str(regul_param) + \".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Val ROC-AUC",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.7289493113549981,
          0.7560602027672548,
          0.7587500613942111,
          0.7659228857021992,
          0.7809347605308896,
          0.7934164016813299,
          0.8051395272566532,
          0.8094343493877214,
          0.8196919357317476,
          0.8238881310334666,
          0.8289141384134469,
          0.8421840020153145,
          0.8384829213187635,
          0.853167624416359,
          0.8562080241837738,
          0.8631111100548666,
          0.8644229657127195,
          0.8717815570205667,
          0.8690200057987822,
          0.8804123948178533,
          0.8764368225841972,
          0.8837989787172016,
          0.8834084323166452,
          0.8884122585623138,
          0.8885516828351292,
          0.8925799352627752,
          0.892326040493245,
          0.8951652256851197,
          0.89406250643649,
          0.8974653300948876,
          0.8962592309166987,
          0.8989938479039621,
          0.8986797471984435,
          0.9014369414117023,
          0.9010729331539831,
          0.9023689451444705,
          0.9023788474365739,
          0.9039477665974298,
          0.9044179274264973,
          0.9050148375944876,
          0.9055978845535333,
          0.9065603873459798,
          0.9067243693032113,
          0.9070852088274577,
          0.9066914936934283,
          0.9058402926642235,
          0.9066106909898648,
          0.9062074696554161,
          0.907112539153663,
          0.9056933426494097,
          0.9064669097085241,
          0.9058739604573749,
          0.9068451772668723,
          0.9061393418857449,
          0.9067572449129945,
          0.905805832687704,
          0.9067639784716248,
          0.905797514762337,
          0.9064597800582096,
          0.904853628279045,
          0.9056081829373208,
          0.9044092134094464,
          0.9046084475265659,
          0.9032312367408308,
          0.904175123224123,
          0.9031044874019079,
          0.9036871382692695,
          0.902346764010159,
          0.9043719807911377,
          0.9031421161119007,
          0.9035833622480263,
          0.9033381814955471,
          0.9035433569879286,
          0.902102375441048,
          0.9020750451148427,
          0.9016955892814421,
          0.9017708467014277,
          0.8999096118776805,
          0.8963839997972011,
          0.8894512070497982,
          0.8474100356957825,
          0.8479174291431586,
          0.8529624489239773,
          0.8620060142561319,
          0.8654781539592533,
          0.8737235945478772,
          0.8771026527052269,
          0.8816335454800394,
          0.8842849832136344,
          0.8863117843613497,
          0.8880427050210167,
          0.8888737053743304,
          0.8898488831006691,
          0.8909432844239322,
          0.8918325102548137,
          0.8922923727000937,
          0.8930857443434146,
          0.8934960953281778,
          0.8936695834858286,
          0.8937424643557093
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Avg precision = %{y:.4f}<br>epoch = %{x}<br>",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Val avg precision",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.047445404593799326,
          0.10578297830320096,
          0.1227865853231416,
          0.13539466690843432,
          0.15177343998984613,
          0.17113943786517022,
          0.19032981895116965,
          0.20494356246740197,
          0.22007012507444196,
          0.2288209886665521,
          0.23281414359983613,
          0.2423513625320961,
          0.24480111895737544,
          0.25212636637563,
          0.2550704628631021,
          0.26130479817826635,
          0.2621862978017243,
          0.26817232854587014,
          0.2726474919781264,
          0.28293242950524833,
          0.2908046870436948,
          0.2970121912166438,
          0.299623927622696,
          0.28980737560462455,
          0.29638849280955926,
          0.2983960025131081,
          0.30503739041634736,
          0.30962845848719206,
          0.3136742528594194,
          0.3220205814654374,
          0.3189953486228933,
          0.32782334339460617,
          0.3196720727662107,
          0.33489445382223787,
          0.3366550993950302,
          0.3343177680143394,
          0.3375872238089486,
          0.3409991414520824,
          0.34093947272906894,
          0.33568555838168235,
          0.3380788058189076,
          0.3397330800013426,
          0.34109692848790957,
          0.3404816440160885,
          0.34332070689839617,
          0.33957214027623706,
          0.3421164918140995,
          0.3407996997751867,
          0.3425316457352403,
          0.3422422158266781,
          0.343849163009404,
          0.34332538002411606,
          0.3455856321413061,
          0.3490963155364923,
          0.34924718825607004,
          0.34821272752370425,
          0.34879070787911554,
          0.3474007818753879,
          0.3479063345127267,
          0.34472327422313076,
          0.3465091953853601,
          0.35043675245102013,
          0.3495788229422728,
          0.34792966670813474,
          0.3488598456270923,
          0.34452757972412845,
          0.3499289334543258,
          0.3469132556817964,
          0.34942221685096836,
          0.3465227351413474,
          0.3502668573383866,
          0.3507894701623001,
          0.3516868026703502,
          0.3476038196954495,
          0.3410333068336716,
          0.34783981756398535,
          0.3449671033723233,
          0.3441761791065901,
          0.34911947262716847,
          0.34057709511627143,
          0.22086468049239075,
          0.24837988080325804,
          0.2529288555982026,
          0.26893050529795426,
          0.280386037133801,
          0.2916810629211735,
          0.29611384145930936,
          0.2995591337945318,
          0.3063848440382175,
          0.3074478478707027,
          0.3117989282347551,
          0.3151654907058885,
          0.3162694816352335,
          0.32148090100977816,
          0.3212361928426357,
          0.3254430090033084,
          0.3251686311641227,
          0.32691562006019126,
          0.32464892226035896,
          0.3262951245648543
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Validation performance by epoch of training - Regularization parameter = 0"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "performance"
         }
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"242be454-b91c-49c6-ba48-d92a023c5e93\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"242be454-b91c-49c6-ba48-d92a023c5e93\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '242be454-b91c-49c6-ba48-d92a023c5e93',\n",
       "                        [{\"hovertemplate\": \"ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Val ROC-AUC\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.7289493113549981, 0.7560602027672548, 0.7587500613942111, 0.7659228857021992, 0.7809347605308896, 0.7934164016813299, 0.8051395272566532, 0.8094343493877214, 0.8196919357317476, 0.8238881310334666, 0.8289141384134469, 0.8421840020153145, 0.8384829213187635, 0.853167624416359, 0.8562080241837738, 0.8631111100548666, 0.8644229657127195, 0.8717815570205667, 0.8690200057987822, 0.8804123948178533, 0.8764368225841972, 0.8837989787172016, 0.8834084323166452, 0.8884122585623138, 0.8885516828351292, 0.8925799352627752, 0.892326040493245, 0.8951652256851197, 0.89406250643649, 0.8974653300948876, 0.8962592309166987, 0.8989938479039621, 0.8986797471984435, 0.9014369414117023, 0.9010729331539831, 0.9023689451444705, 0.9023788474365739, 0.9039477665974298, 0.9044179274264973, 0.9050148375944876, 0.9055978845535333, 0.9065603873459798, 0.9067243693032113, 0.9070852088274577, 0.9066914936934283, 0.9058402926642235, 0.9066106909898648, 0.9062074696554161, 0.907112539153663, 0.9056933426494097, 0.9064669097085241, 0.9058739604573749, 0.9068451772668723, 0.9061393418857449, 0.9067572449129945, 0.905805832687704, 0.9067639784716248, 0.905797514762337, 0.9064597800582096, 0.904853628279045, 0.9056081829373208, 0.9044092134094464, 0.9046084475265659, 0.9032312367408308, 0.904175123224123, 0.9031044874019079, 0.9036871382692695, 0.902346764010159, 0.9043719807911377, 0.9031421161119007, 0.9035833622480263, 0.9033381814955471, 0.9035433569879286, 0.902102375441048, 0.9020750451148427, 0.9016955892814421, 0.9017708467014277, 0.8999096118776805, 0.8963839997972011, 0.8894512070497982, 0.8474100356957825, 0.8479174291431586, 0.8529624489239773, 0.8620060142561319, 0.8654781539592533, 0.8737235945478772, 0.8771026527052269, 0.8816335454800394, 0.8842849832136344, 0.8863117843613497, 0.8880427050210167, 0.8888737053743304, 0.8898488831006691, 0.8909432844239322, 0.8918325102548137, 0.8922923727000937, 0.8930857443434146, 0.8934960953281778, 0.8936695834858286, 0.8937424643557093], \"yaxis\": \"y\"}, {\"hovertemplate\": \"Avg precision = %{y:.4f}<br>epoch = %{x}<br>\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Val avg precision\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.047445404593799326, 0.10578297830320096, 0.1227865853231416, 0.13539466690843432, 0.15177343998984613, 0.17113943786517022, 0.19032981895116965, 0.20494356246740197, 0.22007012507444196, 0.2288209886665521, 0.23281414359983613, 0.2423513625320961, 0.24480111895737544, 0.25212636637563, 0.2550704628631021, 0.26130479817826635, 0.2621862978017243, 0.26817232854587014, 0.2726474919781264, 0.28293242950524833, 0.2908046870436948, 0.2970121912166438, 0.299623927622696, 0.28980737560462455, 0.29638849280955926, 0.2983960025131081, 0.30503739041634736, 0.30962845848719206, 0.3136742528594194, 0.3220205814654374, 0.3189953486228933, 0.32782334339460617, 0.3196720727662107, 0.33489445382223787, 0.3366550993950302, 0.3343177680143394, 0.3375872238089486, 0.3409991414520824, 0.34093947272906894, 0.33568555838168235, 0.3380788058189076, 0.3397330800013426, 0.34109692848790957, 0.3404816440160885, 0.34332070689839617, 0.33957214027623706, 0.3421164918140995, 0.3407996997751867, 0.3425316457352403, 0.3422422158266781, 0.343849163009404, 0.34332538002411606, 0.3455856321413061, 0.3490963155364923, 0.34924718825607004, 0.34821272752370425, 0.34879070787911554, 0.3474007818753879, 0.3479063345127267, 0.34472327422313076, 0.3465091953853601, 0.35043675245102013, 0.3495788229422728, 0.34792966670813474, 0.3488598456270923, 0.34452757972412845, 0.3499289334543258, 0.3469132556817964, 0.34942221685096836, 0.3465227351413474, 0.3502668573383866, 0.3507894701623001, 0.3516868026703502, 0.3476038196954495, 0.3410333068336716, 0.34783981756398535, 0.3449671033723233, 0.3441761791065901, 0.34911947262716847, 0.34057709511627143, 0.22086468049239075, 0.24837988080325804, 0.2529288555982026, 0.26893050529795426, 0.280386037133801, 0.2916810629211735, 0.29611384145930936, 0.2995591337945318, 0.3063848440382175, 0.3074478478707027, 0.3117989282347551, 0.3151654907058885, 0.3162694816352335, 0.32148090100977816, 0.3212361928426357, 0.3254430090033084, 0.3251686311641227, 0.32691562006019126, 0.32464892226035896, 0.3262951245648543], \"yaxis\": \"y2\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Validation performance by epoch of training - Regularization parameter = 0\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.94], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"performance\"}}, \"yaxis2\": {\"anchor\": \"x\", \"overlaying\": \"y\", \"side\": \"right\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('242be454-b91c-49c6-ba48-d92a023c5e93');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epoch_performances.epoch,\n",
    "               y=epoch_performances.roc_auc, name='Val ROC-AUC',\n",
    "               hovertemplate =\n",
    "                'ROC-AUC = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epoch_performances.epoch,\n",
    "               y=epoch_performances.avg_prec_score, name='Val avg precision',\n",
    "               hovertemplate = 'Avg precision = %{y:.4f}<br>'+\n",
    "                               'epoch = %{x}<br>',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Validation performance by epoch of training - Regularization parameter = {0}'.format(regul_param),\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='performance', secondary_y=False)\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"Plots/epoch_roc_auc_\" + regularization + \"_regul_param_\" + str(regul_param) + \".html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_overfitting_l1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing overfitting through L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 100\n",
    "es_param = None\n",
    "batch_size = 512\n",
    "regularization = 'l1'\n",
    "input_dropout = 0\n",
    "\n",
    "# Choose a value for the regularization parameter [0, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]:\n",
    "regul_param = 10\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 1.58 minutes.\n",
      "Start time: 2021-01-23, 13:58:01\n",
      "End time: 2021-01-23, 13:59:37\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "epoch_costs = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "val_roc_auc = []\n",
    "val_avg_prec_score = []\n",
    "val_brier_score = []\n",
    "epoch_performance = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for t in range(n_estimations):\n",
    "    # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "    model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                     output_activation = output_activation, cost_function = cost_function,\n",
    "                     num_epochs = num_epochs, batch_size = batch_size,\n",
    "                     default_adam = default_adam,\n",
    "                     regularization = regularization, regul_param = regul_param, input_dropout = input_dropout)\n",
    "\n",
    "    # Training the model:\n",
    "    model.run(train_inputs = X_train, train_output = y_train,\n",
    "              val_inputs = X_val, val_output = y_val,\n",
    "              verbose = 0)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "\n",
    "    # Cost function by training epoch:\n",
    "    model_costs = model.model_costs\n",
    "    epoch_costs.append({'epoch': list(model_costs['epoch']),\n",
    "                        'loss': list(model_costs['loss']),\n",
    "                        'val_loss': list(model_costs['val_loss'])})\n",
    "\n",
    "    min_cost.append(model_costs.loss.min())\n",
    "    epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "    min_cost.append(model_costs.val_loss.min())\n",
    "    epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Running time and performance metrics on validation data by epoch of training:\n",
    "    epoch_performance.append(model.epoch_performance)\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regularization': regularization,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'validation',\n",
    "        'epoch_costs': epoch_costs,\n",
    "        'avg_epoch_costs': {\n",
    "            'epoch': [sum(l)/len(l) for l in zip(*[d['epoch'] for d in epoch_costs])],\n",
    "            'loss': [sum(l)/len(l) for l in zip(*[d['loss'] for d in epoch_costs])],\n",
    "            'val_loss': [sum(l)/len(l) for l in zip(*[d['val_loss'] for d in epoch_costs])]\n",
    "        },\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(val_brier_score),\n",
    "        'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(val_brier_score),\n",
    "        'avg_epoch_performance': {\n",
    "            'roc_auc': [sum(l)/len(l) for l in zip(*[d['epochroc_auc'] for d in epoch_performance])],\n",
    "            'avg_prec_score': [sum(l)/len(l) for l in zip(*[d['epochavg_prec_score'] for d in\n",
    "                                                            epoch_performance])],\n",
    "            'brier_score': [sum(l)/len(l) for l in zip(*[d['epochbrier_score'] for d in\n",
    "                                                         epoch_performance])],\n",
    "            'running_time': [sum(l)/len(l) for l in zip(*[d['running_time'] for d in epoch_performance])]\n",
    "        }\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": '{0}. Assessing overfitting by trying different values for the L1 regularization parameter.'.format(model_architecture_def)\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = [model_assessment[e] for e in model_assessment.keys() if\n",
    "            ('Assessing overfitting by trying different values for the L1 regularization parameter.' in\n",
    "            model_assessment[e]['comment']) &\n",
    "            (model_assessment[e]['hyper_parameters']['regul_param'] == regul_param)][0]\n",
    "\n",
    "# Cost function by training epoch:\n",
    "model_costs = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'loss': outcomes['performance_metrics']['avg_epoch_costs']['loss'],\n",
    "    'val_loss': outcomes['performance_metrics']['avg_epoch_costs']['val_loss']\n",
    "})\n",
    "\n",
    "epoch_performances = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'roc_auc': outcomes['performance_metrics']['avg_epoch_performance']['roc_auc'],\n",
    "    'avg_prec_score': outcomes['performance_metrics']['avg_epoch_performance']['avg_prec_score']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "loss = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Training cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          14036.9248046875,
          2072.7744140625,
          902.2222290039062,
          620.5711669921875,
          432.0158996582031,
          288.3351135253906,
          188.90841674804688,
          131.25807189941406,
          114.50021362304688,
          113.26949310302734,
          113.2735824584961,
          113.22893524169922,
          113.1010971069336,
          113.17393493652344,
          113.13575744628906,
          113.20653533935547,
          113.05378723144531,
          113.15211486816406,
          113.19007873535156,
          113.08606719970703,
          113.04978942871094,
          113.17012786865234,
          113.05143737792969,
          113.18911743164062,
          113.09754943847656,
          113.1885986328125,
          112.98436737060547,
          113.05955505371094,
          113.1124038696289,
          113.24684143066406,
          113.0354995727539,
          113.08514404296875,
          113.1281509399414,
          113.03937530517578,
          113.0919189453125,
          113.17594909667969,
          113.02123260498047,
          113.09888458251953,
          113.07225799560547,
          113.19324493408203,
          113.07665252685547,
          112.99435424804688,
          113.11722564697266,
          113.09602355957031,
          113.06861114501953,
          113.17265319824219,
          113.03861236572266,
          113.06227111816406,
          112.98920440673828,
          113.15071105957031,
          113.14424133300781,
          113.00729370117188,
          113.06096649169922,
          113.11502838134766,
          113.02194213867188,
          113.08212280273438,
          113.0377426147461,
          113.0938949584961,
          113.01514434814453,
          113.10707092285156,
          113.10665893554688,
          113.02833557128906,
          112.95208740234375,
          113.14881134033203,
          113.01335906982422,
          113.12847900390625,
          113.0019760131836,
          113.1109619140625,
          113.05599212646484,
          112.97725677490234,
          113.11141204833984,
          113.06399536132812,
          112.9825668334961,
          113.12937927246094,
          113.0826416015625,
          113.02313995361328,
          112.932861328125,
          113.10198211669922,
          113.10482788085938,
          113.03009796142578,
          113.06916046142578,
          113.02684783935547,
          112.98533630371094,
          113.01803588867188,
          113.0929946899414,
          113.1322021484375,
          112.89200592041016,
          113.09779357910156,
          113.03132629394531,
          113.09571075439453,
          112.9921646118164,
          113.0557632446289,
          113.00390625,
          113.03482055664062,
          113.0530776977539,
          113.1522445678711,
          112.86576843261719,
          113.02735900878906,
          113.02814483642578,
          113.08512878417969
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "val_loss = %{y:.4f}",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          4356.98388671875,
          1137.554443359375,
          728.0530395507812,
          514.4038696289062,
          348.8650207519531,
          228.76260375976562,
          151.1797332763672,
          116.9565658569336,
          113.7586669921875,
          112.95124816894531,
          112.85231018066406,
          112.7204360961914,
          112.35807800292969,
          113.66559600830078,
          113.59693908691406,
          112.53947448730469,
          112.45694732666016,
          113.41432189941406,
          113.35261535644531,
          112.61933898925781,
          112.71723937988281,
          113.321044921875,
          113.01631927490234,
          113.19831085205078,
          113.37601470947266,
          112.93258666992188,
          112.26200103759766,
          113.48070526123047,
          113.55038452148438,
          112.89932250976562,
          112.057373046875,
          113.21878814697266,
          113.01187133789062,
          113.12318420410156,
          112.91195678710938,
          113.21309661865234,
          112.87677001953125,
          112.54972076416016,
          113.85984802246094,
          112.87349700927734,
          112.13623809814453,
          113.26110076904297,
          113.54399871826172,
          113.33922576904297,
          112.45547485351562,
          112.83058166503906,
          112.56424713134766,
          112.87557220458984,
          113.56293487548828,
          113.66227722167969,
          112.0306167602539,
          112.4845962524414,
          113.49836730957031,
          113.42758178710938,
          112.27606201171875,
          112.77742767333984,
          113.00482177734375,
          113.31539916992188,
          113.27337646484375,
          113.37701416015625,
          112.49362182617188,
          112.19698333740234,
          113.41470336914062,
          113.82929229736328,
          112.6568832397461,
          112.2512435913086,
          113.03260803222656,
          112.9017333984375,
          112.81594848632812,
          113.3273696899414,
          112.89875793457031,
          112.81088256835938,
          112.55040740966797,
          113.90743255615234,
          112.96517181396484,
          112.23947143554688,
          112.93104553222656,
          113.56421661376953,
          112.87152862548828,
          112.60639953613281,
          112.9727783203125,
          112.7750244140625,
          112.77098083496094,
          113.65853881835938,
          113.11441040039062,
          112.59909057617188,
          112.30429077148438,
          113.530029296875,
          113.28624725341797,
          112.23768615722656,
          112.68630981445312,
          113.37409210205078,
          112.9268798828125,
          113.06941986083984,
          113.01296997070312,
          112.51898193359375,
          112.51502227783203,
          113.30598449707031,
          113.55636596679688,
          112.83004760742188
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost function by epoch of training - L1 Regularization parameter = 10"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cost"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"4c27cf4d-2f2a-4282-b297-6272122a1e01\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"4c27cf4d-2f2a-4282-b297-6272122a1e01\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '4c27cf4d-2f2a-4282-b297-6272122a1e01',\n",
       "                        [{\"hovertemplate\": \"loss = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Training cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [14036.9248046875, 2072.7744140625, 902.2222290039062, 620.5711669921875, 432.0158996582031, 288.3351135253906, 188.90841674804688, 131.25807189941406, 114.50021362304688, 113.26949310302734, 113.2735824584961, 113.22893524169922, 113.1010971069336, 113.17393493652344, 113.13575744628906, 113.20653533935547, 113.05378723144531, 113.15211486816406, 113.19007873535156, 113.08606719970703, 113.04978942871094, 113.17012786865234, 113.05143737792969, 113.18911743164062, 113.09754943847656, 113.1885986328125, 112.98436737060547, 113.05955505371094, 113.1124038696289, 113.24684143066406, 113.0354995727539, 113.08514404296875, 113.1281509399414, 113.03937530517578, 113.0919189453125, 113.17594909667969, 113.02123260498047, 113.09888458251953, 113.07225799560547, 113.19324493408203, 113.07665252685547, 112.99435424804688, 113.11722564697266, 113.09602355957031, 113.06861114501953, 113.17265319824219, 113.03861236572266, 113.06227111816406, 112.98920440673828, 113.15071105957031, 113.14424133300781, 113.00729370117188, 113.06096649169922, 113.11502838134766, 113.02194213867188, 113.08212280273438, 113.0377426147461, 113.0938949584961, 113.01514434814453, 113.10707092285156, 113.10665893554688, 113.02833557128906, 112.95208740234375, 113.14881134033203, 113.01335906982422, 113.12847900390625, 113.0019760131836, 113.1109619140625, 113.05599212646484, 112.97725677490234, 113.11141204833984, 113.06399536132812, 112.9825668334961, 113.12937927246094, 113.0826416015625, 113.02313995361328, 112.932861328125, 113.10198211669922, 113.10482788085938, 113.03009796142578, 113.06916046142578, 113.02684783935547, 112.98533630371094, 113.01803588867188, 113.0929946899414, 113.1322021484375, 112.89200592041016, 113.09779357910156, 113.03132629394531, 113.09571075439453, 112.9921646118164, 113.0557632446289, 113.00390625, 113.03482055664062, 113.0530776977539, 113.1522445678711, 112.86576843261719, 113.02735900878906, 113.02814483642578, 113.08512878417969], \"yaxis\": \"y\"}, {\"hovertemplate\": \"val_loss = %{y:.4f}\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Validation cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [4356.98388671875, 1137.554443359375, 728.0530395507812, 514.4038696289062, 348.8650207519531, 228.76260375976562, 151.1797332763672, 116.9565658569336, 113.7586669921875, 112.95124816894531, 112.85231018066406, 112.7204360961914, 112.35807800292969, 113.66559600830078, 113.59693908691406, 112.53947448730469, 112.45694732666016, 113.41432189941406, 113.35261535644531, 112.61933898925781, 112.71723937988281, 113.321044921875, 113.01631927490234, 113.19831085205078, 113.37601470947266, 112.93258666992188, 112.26200103759766, 113.48070526123047, 113.55038452148438, 112.89932250976562, 112.057373046875, 113.21878814697266, 113.01187133789062, 113.12318420410156, 112.91195678710938, 113.21309661865234, 112.87677001953125, 112.54972076416016, 113.85984802246094, 112.87349700927734, 112.13623809814453, 113.26110076904297, 113.54399871826172, 113.33922576904297, 112.45547485351562, 112.83058166503906, 112.56424713134766, 112.87557220458984, 113.56293487548828, 113.66227722167969, 112.0306167602539, 112.4845962524414, 113.49836730957031, 113.42758178710938, 112.27606201171875, 112.77742767333984, 113.00482177734375, 113.31539916992188, 113.27337646484375, 113.37701416015625, 112.49362182617188, 112.19698333740234, 113.41470336914062, 113.82929229736328, 112.6568832397461, 112.2512435913086, 113.03260803222656, 112.9017333984375, 112.81594848632812, 113.3273696899414, 112.89875793457031, 112.81088256835938, 112.55040740966797, 113.90743255615234, 112.96517181396484, 112.23947143554688, 112.93104553222656, 113.56421661376953, 112.87152862548828, 112.60639953613281, 112.9727783203125, 112.7750244140625, 112.77098083496094, 113.65853881835938, 113.11441040039062, 112.59909057617188, 112.30429077148438, 113.530029296875, 113.28624725341797, 112.23768615722656, 112.68630981445312, 113.37409210205078, 112.9268798828125, 113.06941986083984, 113.01296997070312, 112.51898193359375, 112.51502227783203, 113.30598449707031, 113.55636596679688, 112.83004760742188], \"yaxis\": \"y\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Cost function by epoch of training - L1 Regularization parameter = 10\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"cost\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4c27cf4d-2f2a-4282-b297-6272122a1e01');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': False}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.loss, name='Training cost',\n",
    "               hovertemplate =\n",
    "                'loss = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.val_loss, name='Validation cost',\n",
    "               hovertemplate = 'val_loss = %{y:.4f}',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Cost function by epoch of training - L1 Regularization parameter = {0}'.format(regul_param),\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='cost', secondary_y=False)\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"Plots/epoch_costs_\" + regularization + \"_regul_param_\" + str(regul_param) + \".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Val ROC-AUC",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.5804081962460015,
          0.516924997663059,
          0.48834064518582243,
          0.5184606451224478,
          0.5908483808564136,
          0.5405391916877784,
          0.5774466187237293,
          0.42843613496903354,
          0.46915673664814544,
          0.5560045914948024,
          0.5249545682838297,
          0.5561083675160456,
          0.5549395009561654,
          0.5766088848117852,
          0.500050303643885,
          0.47847717006750984,
          0.4852867783011469,
          0.5755984549255586,
          0.5353135540989944,
          0.5762908231894253,
          0.6522212029462884,
          0.44729722878414113,
          0.574618128007326,
          0.47988210727113423,
          0.6266566534688918,
          0.47762121593809564,
          0.4876811525317388,
          0.4675905901290783,
          0.46418697428731226,
          0.5849620623384937,
          0.5170054042749384,
          0.3610633160478922,
          0.5632506927643556,
          0.36535893036232886,
          0.5507837070062281,
          0.5525811710688296,
          0.48203050856587876,
          0.5491462639840169,
          0.4951146051678874,
          0.4058189037132803,
          0.5484903361550906,
          0.5214139047193532,
          0.49699207975068405,
          0.5786511335351816,
          0.4294881544820943,
          0.4314381138430875,
          0.4683685141967181,
          0.42955271742660817,
          0.5244693559707652,
          0.46579589870826577,
          0.5092546821997982,
          0.38418279155912777,
          0.5912420959904431,
          0.39923744428970465,
          0.5771606405277843,
          0.5875734948119911,
          0.4822368723333128,
          0.48821270757184704,
          0.42992029050948477,
          0.43235348172512184,
          0.524846039162377,
          0.3942902591548671,
          0.5118205641296202,
          0.5462987608667753,
          0.5171618604901713,
          0.35800588433805947,
          0.5013724576855254,
          0.4026192750888434,
          0.42384345189149614,
          0.5753790201325482,
          0.43503937943523663,
          0.4986532882739434,
          0.5102504566937117,
          0.46012386579146247,
          0.5329651265037619,
          0.39653491072885627,
          0.5750185766999859,
          0.4366914778497608,
          0.4620849157196114,
          0.5413103821967877,
          0.5761220881319841,
          0.39178656361945413,
          0.5688557861865401,
          0.49394732297474364,
          0.5696253923288132,
          0.49208450378426,
          0.44455508605487926,
          0.5834390898129972,
          0.4385301354475123,
          0.5105221755890279,
          0.5690847271799697,
          0.5502303669234926,
          0.5132524355677657,
          0.5080735367977096,
          0.5778149839899741,
          0.38700137998342754,
          0.4927665736643393,
          0.55155608579029,
          0.45907303455345416,
          0.5240471222354781
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Avg precision = %{y:.4f}<br>epoch = %{x}<br>",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Val avg precision",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.035529546784228934,
          0.025937901228913103,
          0.05501836284388603,
          0.019920486068967163,
          0.03219827129414127,
          0.02263093338350693,
          0.03041349465973181,
          0.013392194751176117,
          0.013140335951248795,
          0.020226426369995505,
          0.036971491196363795,
          0.025255451459505463,
          0.025185700763725304,
          0.04628680171879049,
          0.02129099462693492,
          0.013517651492858615,
          0.017193477030237152,
          0.06247861901552834,
          0.016040799088545013,
          0.046655447433943315,
          0.04736068364909411,
          0.01789203680584608,
          0.0315176384747905,
          0.018772927824269512,
          0.030981214650607214,
          0.03041706727632653,
          0.016850813803094406,
          0.04995339713901076,
          0.013857296222484999,
          0.041183929004809064,
          0.021220713778943433,
          0.01047344093786945,
          0.02416364746223331,
          0.009125926224005614,
          0.020907220345753548,
          0.027911947276077702,
          0.02443196063430759,
          0.025911965848335074,
          0.019642133633368326,
          0.0114616331492097,
          0.030105421434962053,
          0.025479839751023588,
          0.026657210826958395,
          0.030444904765769117,
          0.011500250887440309,
          0.013816453647585325,
          0.013320059074067499,
          0.011655294171136098,
          0.026418411878069065,
          0.014765312496459817,
          0.016085993336721064,
          0.01027706635302102,
          0.03077154601773388,
          0.013345363742786682,
          0.0360562566367011,
          0.03792017257106867,
          0.018536746706656372,
          0.022030232436550654,
          0.017152705458826627,
          0.014513401139790227,
          0.019024166857205392,
          0.013961059975240907,
          0.030337083187854823,
          0.016047416832005404,
          0.01894579289062123,
          0.010554775347789043,
          0.021604910478992715,
          0.013141960374463123,
          0.02296578439069151,
          0.02399919559500349,
          0.015428689468525967,
          0.026590018592343882,
          0.037160929348412496,
          0.020352989471119833,
          0.02495993903203161,
          0.009971085852360631,
          0.0277900857826205,
          0.013931601104642704,
          0.018708682985303326,
          0.0185849307007995,
          0.027190872908253987,
          0.014074406440215678,
          0.026035775945601233,
          0.020908925962434946,
          0.023637921074255528,
          0.023997022789509114,
          0.011930751939683334,
          0.042429222426026245,
          0.011870555572109918,
          0.015708839625733856,
          0.022182310932992902,
          0.0239517900528638,
          0.025710173964643326,
          0.0339187134767263,
          0.04783205691428985,
          0.011006947686325895,
          0.023878935030255954,
          0.025951135138258814,
          0.016773527961103228,
          0.028854890222424063
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Validation performance by epoch of training - L1 Regularization parameter = 10"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "performance"
         }
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"fd84613b-b3b3-434f-bb1a-3426e065bc77\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"fd84613b-b3b3-434f-bb1a-3426e065bc77\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'fd84613b-b3b3-434f-bb1a-3426e065bc77',\n",
       "                        [{\"hovertemplate\": \"ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Val ROC-AUC\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.5804081962460015, 0.516924997663059, 0.48834064518582243, 0.5184606451224478, 0.5908483808564136, 0.5405391916877784, 0.5774466187237293, 0.42843613496903354, 0.46915673664814544, 0.5560045914948024, 0.5249545682838297, 0.5561083675160456, 0.5549395009561654, 0.5766088848117852, 0.500050303643885, 0.47847717006750984, 0.4852867783011469, 0.5755984549255586, 0.5353135540989944, 0.5762908231894253, 0.6522212029462884, 0.44729722878414113, 0.574618128007326, 0.47988210727113423, 0.6266566534688918, 0.47762121593809564, 0.4876811525317388, 0.4675905901290783, 0.46418697428731226, 0.5849620623384937, 0.5170054042749384, 0.3610633160478922, 0.5632506927643556, 0.36535893036232886, 0.5507837070062281, 0.5525811710688296, 0.48203050856587876, 0.5491462639840169, 0.4951146051678874, 0.4058189037132803, 0.5484903361550906, 0.5214139047193532, 0.49699207975068405, 0.5786511335351816, 0.4294881544820943, 0.4314381138430875, 0.4683685141967181, 0.42955271742660817, 0.5244693559707652, 0.46579589870826577, 0.5092546821997982, 0.38418279155912777, 0.5912420959904431, 0.39923744428970465, 0.5771606405277843, 0.5875734948119911, 0.4822368723333128, 0.48821270757184704, 0.42992029050948477, 0.43235348172512184, 0.524846039162377, 0.3942902591548671, 0.5118205641296202, 0.5462987608667753, 0.5171618604901713, 0.35800588433805947, 0.5013724576855254, 0.4026192750888434, 0.42384345189149614, 0.5753790201325482, 0.43503937943523663, 0.4986532882739434, 0.5102504566937117, 0.46012386579146247, 0.5329651265037619, 0.39653491072885627, 0.5750185766999859, 0.4366914778497608, 0.4620849157196114, 0.5413103821967877, 0.5761220881319841, 0.39178656361945413, 0.5688557861865401, 0.49394732297474364, 0.5696253923288132, 0.49208450378426, 0.44455508605487926, 0.5834390898129972, 0.4385301354475123, 0.5105221755890279, 0.5690847271799697, 0.5502303669234926, 0.5132524355677657, 0.5080735367977096, 0.5778149839899741, 0.38700137998342754, 0.4927665736643393, 0.55155608579029, 0.45907303455345416, 0.5240471222354781], \"yaxis\": \"y\"}, {\"hovertemplate\": \"Avg precision = %{y:.4f}<br>epoch = %{x}<br>\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Val avg precision\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.035529546784228934, 0.025937901228913103, 0.05501836284388603, 0.019920486068967163, 0.03219827129414127, 0.02263093338350693, 0.03041349465973181, 0.013392194751176117, 0.013140335951248795, 0.020226426369995505, 0.036971491196363795, 0.025255451459505463, 0.025185700763725304, 0.04628680171879049, 0.02129099462693492, 0.013517651492858615, 0.017193477030237152, 0.06247861901552834, 0.016040799088545013, 0.046655447433943315, 0.04736068364909411, 0.01789203680584608, 0.0315176384747905, 0.018772927824269512, 0.030981214650607214, 0.03041706727632653, 0.016850813803094406, 0.04995339713901076, 0.013857296222484999, 0.041183929004809064, 0.021220713778943433, 0.01047344093786945, 0.02416364746223331, 0.009125926224005614, 0.020907220345753548, 0.027911947276077702, 0.02443196063430759, 0.025911965848335074, 0.019642133633368326, 0.0114616331492097, 0.030105421434962053, 0.025479839751023588, 0.026657210826958395, 0.030444904765769117, 0.011500250887440309, 0.013816453647585325, 0.013320059074067499, 0.011655294171136098, 0.026418411878069065, 0.014765312496459817, 0.016085993336721064, 0.01027706635302102, 0.03077154601773388, 0.013345363742786682, 0.0360562566367011, 0.03792017257106867, 0.018536746706656372, 0.022030232436550654, 0.017152705458826627, 0.014513401139790227, 0.019024166857205392, 0.013961059975240907, 0.030337083187854823, 0.016047416832005404, 0.01894579289062123, 0.010554775347789043, 0.021604910478992715, 0.013141960374463123, 0.02296578439069151, 0.02399919559500349, 0.015428689468525967, 0.026590018592343882, 0.037160929348412496, 0.020352989471119833, 0.02495993903203161, 0.009971085852360631, 0.0277900857826205, 0.013931601104642704, 0.018708682985303326, 0.0185849307007995, 0.027190872908253987, 0.014074406440215678, 0.026035775945601233, 0.020908925962434946, 0.023637921074255528, 0.023997022789509114, 0.011930751939683334, 0.042429222426026245, 0.011870555572109918, 0.015708839625733856, 0.022182310932992902, 0.0239517900528638, 0.025710173964643326, 0.0339187134767263, 0.04783205691428985, 0.011006947686325895, 0.023878935030255954, 0.025951135138258814, 0.016773527961103228, 0.028854890222424063], \"yaxis\": \"y2\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Validation performance by epoch of training - L1 Regularization parameter = 10\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.94], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"performance\"}}, \"yaxis2\": {\"anchor\": \"x\", \"overlaying\": \"y\", \"side\": \"right\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fd84613b-b3b3-434f-bb1a-3426e065bc77');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epoch_performances.epoch,\n",
    "               y=epoch_performances.roc_auc, name='Val ROC-AUC',\n",
    "               hovertemplate =\n",
    "                'ROC-AUC = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epoch_performances.epoch,\n",
    "               y=epoch_performances.avg_prec_score, name='Val avg precision',\n",
    "               hovertemplate = 'Avg precision = %{y:.4f}<br>'+\n",
    "                               'epoch = %{x}<br>',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Validation performance by epoch of training - L1 Regularization parameter = {0}'.format(regul_param),\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='performance', secondary_y=False)\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"Plots/epoch_roc_auc_\" + regularization + \"_regul_param_\" + str(regul_param) + \".html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grid_l2_regul_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid of L2 regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regul_params = sorted([1/(10**i) for i in range(9)])\n",
    "regul_params.append(10)\n",
    "regul_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 23.82 minutes.\n",
      "Start time: 2021-01-25, 10:32:50\n",
      "End time: 2021-01-25, 10:56:40\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(regul_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over regularization parameters:\n",
    "for r in range(len(regul_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regularization = regularization, regul_param = regul_params[r],\n",
    "                         input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_params[r],\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative values for the L2 regularization parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(r+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grid_l1_regul_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid of L1 regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l1'\n",
    "input_dropout = 0\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regul_params = sorted([1/(10**i) for i in range(9)])\n",
    "regul_params.append(10)\n",
    "regul_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 30.38 minutes.\n",
      "Start time: 2021-01-25, 10:59:52\n",
      "End time: 2021-01-25, 11:30:16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(regul_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over regularization parameters:\n",
    "for r in range(len(regul_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regularization = regularization, regul_param = regul_params[r],\n",
    "                         input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_params[r],\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative values for the L1 regularization parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(r+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>regularization</th>\n",
       "      <th>regul_params</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1611445622</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.842478</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.219281</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>78.852707</td>\n",
       "      <td>17.205115</td>\n",
       "      <td>27.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1611581570</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.841854</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.218019</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>76.004348</td>\n",
       "      <td>21.144747</td>\n",
       "      <td>23.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1611425007</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.841730</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>0.220132</td>\n",
       "      <td>0.011486</td>\n",
       "      <td>79.264487</td>\n",
       "      <td>19.165792</td>\n",
       "      <td>28.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1611449073</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.841708</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.218036</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>75.088199</td>\n",
       "      <td>21.534740</td>\n",
       "      <td>33.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1611421300</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.840573</td>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.217344</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>77.814185</td>\n",
       "      <td>17.786486</td>\n",
       "      <td>17.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1611426713</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.840472</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.226658</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>71.472031</td>\n",
       "      <td>20.434551</td>\n",
       "      <td>31.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1611423572</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.839394</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.217219</td>\n",
       "      <td>0.011849</td>\n",
       "      <td>71.548231</td>\n",
       "      <td>18.332164</td>\n",
       "      <td>23.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1611583192</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.839098</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>0.217027</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>64.962496</td>\n",
       "      <td>21.303333</td>\n",
       "      <td>30.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1611428623</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.839048</td>\n",
       "      <td>0.009865</td>\n",
       "      <td>0.245409</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>85.052495</td>\n",
       "      <td>23.086329</td>\n",
       "      <td>42.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1611422380</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.838922</td>\n",
       "      <td>0.014618</td>\n",
       "      <td>0.217930</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>57.391121</td>\n",
       "      <td>20.664231</td>\n",
       "      <td>19.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1611493158</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.838844</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>75.151156</td>\n",
       "      <td>20.917176</td>\n",
       "      <td>21.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1611447287</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.838173</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.215420</td>\n",
       "      <td>0.011444</td>\n",
       "      <td>78.772763</td>\n",
       "      <td>18.823190</td>\n",
       "      <td>29.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1611494464</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.838107</td>\n",
       "      <td>0.009079</td>\n",
       "      <td>0.248933</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>92.314056</td>\n",
       "      <td>22.923225</td>\n",
       "      <td>19.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1611440197</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.832136</td>\n",
       "      <td>0.008086</td>\n",
       "      <td>0.220396</td>\n",
       "      <td>0.012087</td>\n",
       "      <td>102.904862</td>\n",
       "      <td>18.234623</td>\n",
       "      <td>19.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1611495643</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-03</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.811340</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>0.169727</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>69.995780</td>\n",
       "      <td>18.261084</td>\n",
       "      <td>20.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1611496874</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-02</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.784143</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.158780</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>130.327230</td>\n",
       "      <td>19.373122</td>\n",
       "      <td>44.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1611441339</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.767243</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.161174</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>157.110069</td>\n",
       "      <td>75.613732</td>\n",
       "      <td>18.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1611443523</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.743999</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.072761</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>147.802546</td>\n",
       "      <td>36.107489</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1611442420</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l2</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.735642</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.106145</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>134.129711</td>\n",
       "      <td>17.161109</td>\n",
       "      <td>18.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1611510904</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.493376</td>\n",
       "      <td>0.071619</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>6.888896</td>\n",
       "      <td>2.283832</td>\n",
       "      <td>19.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1611509616</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.482237</td>\n",
       "      <td>0.069800</td>\n",
       "      <td>0.020501</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>6.908832</td>\n",
       "      <td>1.839415</td>\n",
       "      <td>21.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1611499550</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>l1</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.428858</td>\n",
       "      <td>0.058033</td>\n",
       "      <td>0.014850</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>7.389900</td>\n",
       "      <td>2.162186</td>\n",
       "      <td>37.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                                       architecture  \\\n",
       "10    1611445622  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "20    1611581570  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3     1611425007  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "12    1611449073  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "0     1611421300  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4     1611426713  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2     1611423572  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "21    1611583192  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5     1611428623  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1     1611422380  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "13    1611493158  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "11    1611447287  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "14    1611494464  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "6     1611440197  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "15    1611495643  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "16    1611496874  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "7     1611441339  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "9     1611443523  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "8     1611442420  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "19    1611510904  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "18    1611509616  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "17    1611499550  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "    num_layers num_neurons regularization  regul_params activation_function  \\\n",
       "10           2    [45, 22]             l1  1.000000e-08                tanh   \n",
       "20           2    [45, 22]             l2  0.000000e+00                tanh   \n",
       "3            2    [45, 22]             l2  1.000000e-05                tanh   \n",
       "12           2    [45, 22]             l1  1.000000e-06                tanh   \n",
       "0            2    [45, 22]             l2  1.000000e-08                tanh   \n",
       "4            2    [45, 22]             l2  1.000000e-04                tanh   \n",
       "2            2    [45, 22]             l2  1.000000e-06                tanh   \n",
       "21           2    [45, 22]             l1  0.000000e+00                tanh   \n",
       "5            2    [45, 22]             l2  1.000000e-03                tanh   \n",
       "1            2    [45, 22]             l2  1.000000e-07                tanh   \n",
       "13           2    [45, 22]             l1  1.000000e-05                tanh   \n",
       "11           2    [45, 22]             l1  1.000000e-07                tanh   \n",
       "14           2    [45, 22]             l1  1.000000e-04                tanh   \n",
       "6            2    [45, 22]             l2  1.000000e-02                tanh   \n",
       "15           2    [45, 22]             l1  1.000000e-03                tanh   \n",
       "16           2    [45, 22]             l1  1.000000e-02                tanh   \n",
       "7            2    [45, 22]             l2  1.000000e-01                tanh   \n",
       "9            2    [45, 22]             l2  1.000000e+01                tanh   \n",
       "8            2    [45, 22]             l2  1.000000e+00                tanh   \n",
       "19           2    [45, 22]             l1  1.000000e+01                tanh   \n",
       "18           2    [45, 22]             l1  1.000000e+00                tanh   \n",
       "17           2    [45, 22]             l1  1.000000e-01                tanh   \n",
       "\n",
       "    avg_roc_auc  std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  \\\n",
       "10     0.842478     0.010684  0.219281  0.012745      78.852707   17.205115   \n",
       "20     0.841854     0.011076  0.218019  0.010311      76.004348   21.144747   \n",
       "3      0.841730     0.010619  0.220132  0.011486      79.264487   19.165792   \n",
       "12     0.841708     0.011210  0.218036  0.010125      75.088199   21.534740   \n",
       "0      0.840573     0.010802  0.217344  0.012220      77.814185   17.786486   \n",
       "4      0.840472     0.011759  0.226658  0.011092      71.472031   20.434551   \n",
       "2      0.839394     0.011732  0.217219  0.011849      71.548231   18.332164   \n",
       "21     0.839098     0.012917  0.217027  0.010187      64.962496   21.303333   \n",
       "5      0.839048     0.009865  0.245409  0.010630      85.052495   23.086329   \n",
       "1      0.838922     0.014618  0.217930  0.010546      57.391121   20.664231   \n",
       "13     0.838844     0.011162  0.235215  0.011245      75.151156   20.917176   \n",
       "11     0.838173     0.010640  0.215420  0.011444      78.772763   18.823190   \n",
       "14     0.838107     0.009079  0.248933  0.010859      92.314056   22.923225   \n",
       "6      0.832136     0.008086  0.220396  0.012087     102.904862   18.234623   \n",
       "15     0.811340     0.011591  0.169727  0.009294      69.995780   18.261084   \n",
       "16     0.784143     0.006017  0.158780  0.008196     130.327230   19.373122   \n",
       "7      0.767243     0.004883  0.161174  0.002132     157.110069   75.613732   \n",
       "9      0.743999     0.005034  0.072761  0.002015     147.802546   36.107489   \n",
       "8      0.735642     0.005485  0.106145  0.006185     134.129711   17.161109   \n",
       "19     0.493376     0.071619  0.020784  0.009100       6.888896    2.283832   \n",
       "18     0.482237     0.069800  0.020501  0.011146       6.908832    1.839415   \n",
       "17     0.428858     0.058033  0.014850  0.006868       7.389900    2.162186   \n",
       "\n",
       "    running_time  \n",
       "10         27.73  \n",
       "20         23.82  \n",
       "3          28.42  \n",
       "12         33.60  \n",
       "0          17.98  \n",
       "4          31.82  \n",
       "2          23.92  \n",
       "21         30.38  \n",
       "5          42.00  \n",
       "1          19.85  \n",
       "13         21.75  \n",
       "11         29.75  \n",
       "14         19.65  \n",
       "6          19.02  \n",
       "15         20.50  \n",
       "16         44.58  \n",
       "7          18.00  \n",
       "9          22.38  \n",
       "8          18.38  \n",
       "19         19.12  \n",
       "18         21.45  \n",
       "17         37.87  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "regul_option = []\n",
    "regul_params = []\n",
    "activations = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over regularization parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative values for the L1 regularization parameter.' in model_assessment[e]['comment']) |\n",
    "          ('Testing alternative values for the L2 regularization parameter.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    regul_option.append(e['hyper_parameters']['regularization'])\n",
    "    regul_params.append(e['hyper_parameters']['regul_param'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by regularization parameter:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'regularization': regul_option,\n",
    "    'regul_params': regul_params,\n",
    "    'activation_function': activations,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dropout'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will explore an additional approach to reduce overfitting and improve generalization. **Dropout layers** attenuate the influence of specific observations by turning to zero a fraction $\\rho$ of their neurons at each mini-batch update. As a consequence of their activations being set equal to zero, all associated parameters are not updated in a given mini-batch update.\n",
    "<br>\n",
    "<br>\n",
    "Dropout applies for both input and hidden layers, and the same grid of values $\\rho \\in [0, 0.1, 0.2, 0.3, 0.4, 0.5]$ will be tested separately for each kind of dropout. First, tests will be conducted regarding the input layer, and in a second moment the best value of dropout fraction for hidden layers will be assessed.\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above:\n",
    "* Random samples of training and validation data.\n",
    "* *Following results of tests from an earlier section, cross-entropy cost function will be used. Regarding activation functions, sigmoid will be applied for the neuron in the output layer, while tanh activation function will be used for neurons in hidden layers, since this alternative has shown the best results during tests.*\n",
    "* Fitting hyper-parameters: *after previous tests, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$.*\n",
    "* *After tests for number of neurons and number of hidden layers, the architecture will be given by two hidden layers with the following number of neurons:*\n",
    "    * $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "    * $J_2 = J_1/2$.\n",
    "<br>\n",
    "<br>\n",
    "* Adam optimizer for model estimation (non-fixed and parameter-specific learning rates).\n",
    "* *The section concerning regularization has shown that L2 regularization with $\\lambda = 1e-5$ is the best alternative to improve generalization by using standard regularization techniques.*\n",
    "* No early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='input_dropout'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid of values for input dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.1, 0.2, 0.3, 0.4, 0.5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_params = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "dropout_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 23.78 minutes.\n",
      "Start time: 2021-01-27, 08:56:01\n",
      "End time: 2021-01-27, 09:19:48\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(dropout_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for d in range(len(dropout_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = dropout_params[d])\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': dropout_params[d],\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative values for input dropout parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(d+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>input_dropout</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1611710233</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839178</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.217772</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>65.235886</td>\n",
       "      <td>20.143439</td>\n",
       "      <td>29.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1611712007</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.837265</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.216944</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>76.381586</td>\n",
       "      <td>20.942726</td>\n",
       "      <td>22.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1611713335</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.832779</td>\n",
       "      <td>0.012708</td>\n",
       "      <td>0.214787</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>65.532764</td>\n",
       "      <td>21.622277</td>\n",
       "      <td>22.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1611714657</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.828563</td>\n",
       "      <td>0.010786</td>\n",
       "      <td>0.208723</td>\n",
       "      <td>0.009775</td>\n",
       "      <td>76.815692</td>\n",
       "      <td>21.352891</td>\n",
       "      <td>24.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1611716146</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.822564</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.201364</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>68.142388</td>\n",
       "      <td>21.746335</td>\n",
       "      <td>33.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1611748561</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.814562</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>0.190004</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>55.195296</td>\n",
       "      <td>24.532837</td>\n",
       "      <td>23.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "0    1611710233  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1    1611712007  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2    1611713335  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3    1611714657  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4    1611716146  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5    1611748561  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "   num_layers num_neurons activation_function  input_dropout  avg_roc_auc  \\\n",
       "0           2    [45, 22]                tanh            0.0     0.839178   \n",
       "1           2    [45, 22]                tanh            0.1     0.837265   \n",
       "2           2    [45, 22]                tanh            0.2     0.832779   \n",
       "3           2    [45, 22]                tanh            0.3     0.828563   \n",
       "4           2    [45, 22]                tanh            0.4     0.822564   \n",
       "5           2    [45, 22]                tanh            0.5     0.814562   \n",
       "\n",
       "   std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "0     0.012864  0.217772  0.010811      65.235886   20.143439         29.57  \n",
       "1     0.010962  0.216944  0.010359      76.381586   20.942726         22.12  \n",
       "2     0.012708  0.214787  0.009934      65.532764   21.622277         22.03  \n",
       "3     0.010786  0.208723  0.009775      76.815692   21.352891         24.80  \n",
       "4     0.012071  0.201364  0.009260      68.142388   21.746335         33.42  \n",
       "5     0.014758  0.190004  0.007745      55.195296   24.532837         23.77  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "dropout_params = []\n",
    "activations = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative values for input dropout parameter.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    dropout_params.append(e['hyper_parameters']['input_dropout'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by dropout parameter:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'input_dropout': dropout_params,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hidden_dropout'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid of values for dropout of hidden neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0}},\n",
       " {1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0.1},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0.1}},\n",
       " {1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0.2},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0.2}},\n",
       " {1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0.3},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0.3}},\n",
       " {1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0.4},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0.4}},\n",
       " {1: {'neurons': 45, 'activation': 'tanh', 'dropout_param': 0.5},\n",
       "  2: {'neurons': 22, 'activation': 'tanh', 'dropout_param': 0.5}}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_params = dropout_params = [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "model_architectures = [{1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                            'activation': 'tanh',\n",
    "                            'dropout_param': d},\n",
    "                        2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                            'activation': 'tanh',\n",
    "                            'dropout_param': d}} for d in dropout_params]\n",
    "\n",
    "model_architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 114.18 minutes.\n",
      "Start time: 2021-01-27, 17:50:18\n",
      "End time: 2021-01-27, 19:44:30\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(model_architectures),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for d in range(len(model_architectures)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architectures[d], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architectures[d]),\n",
    "            'num_hidden_neurons': [model_architectures[d][l]['neurons'] for l in model_architectures[d].keys()],\n",
    "            'hidden_activations': [model_architectures[d][l]['activation'] for l in model_architectures[d].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architectures[d][l]['dropout_param'] for l in model_architectures[d].keys()],\n",
    "            'default_adam': default_adam\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative values for hidden dropout parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(d+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>hidden_dropout</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1611758452</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.836742</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.216486</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>82.919320</td>\n",
       "      <td>18.499740</td>\n",
       "      <td>20.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1611780618</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[0.1, 0.1]</td>\n",
       "      <td>0.835017</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>0.211302</td>\n",
       "      <td>0.010447</td>\n",
       "      <td>72.944082</td>\n",
       "      <td>20.226319</td>\n",
       "      <td>22.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1611781951</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[0.2, 0.2]</td>\n",
       "      <td>0.830879</td>\n",
       "      <td>0.011435</td>\n",
       "      <td>0.204076</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>72.663473</td>\n",
       "      <td>18.974657</td>\n",
       "      <td>19.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1611783130</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[0.3, 0.3]</td>\n",
       "      <td>0.828517</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.195914</td>\n",
       "      <td>0.010254</td>\n",
       "      <td>65.273031</td>\n",
       "      <td>19.105422</td>\n",
       "      <td>18.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1611784262</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[0.4, 0.4]</td>\n",
       "      <td>0.824138</td>\n",
       "      <td>0.010985</td>\n",
       "      <td>0.183365</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>75.025663</td>\n",
       "      <td>15.477594</td>\n",
       "      <td>22.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1611785641</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[0.5, 0.5]</td>\n",
       "      <td>0.817505</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>0.167977</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>59.749227</td>\n",
       "      <td>14.402298</td>\n",
       "      <td>30.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "0    1611758452  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1    1611780618  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2    1611781951  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3    1611783130  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4    1611784262  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5    1611785641  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "   num_layers num_neurons activation_function hidden_dropout  avg_roc_auc  \\\n",
       "0           2    [45, 22]                tanh         [0, 0]     0.836742   \n",
       "1           2    [45, 22]                tanh     [0.1, 0.1]     0.835017   \n",
       "2           2    [45, 22]                tanh     [0.2, 0.2]     0.830879   \n",
       "3           2    [45, 22]                tanh     [0.3, 0.3]     0.828517   \n",
       "4           2    [45, 22]                tanh     [0.4, 0.4]     0.824138   \n",
       "5           2    [45, 22]                tanh     [0.5, 0.5]     0.817505   \n",
       "\n",
       "   std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "0     0.010091  0.216486  0.011702      82.919320   18.499740         20.03  \n",
       "1     0.011447  0.211302  0.010447      72.944082   20.226319         22.20  \n",
       "2     0.011435  0.204076  0.010755      72.663473   18.974657         19.65  \n",
       "3     0.012693  0.195914  0.010254      65.273031   19.105422         18.85  \n",
       "4     0.010985  0.183365  0.011847      75.025663   15.477594         22.97  \n",
       "5     0.013682  0.167977  0.011663      59.749227   14.402298         30.47  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "dropout_params = []\n",
    "activations = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative values for hidden dropout parameter.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    dropout_params.append(e['hyper_parameters']['hidden_dropout'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by dropout parameter:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'hidden_dropout': dropout_params,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='learning_rate'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, learning rate has been approached by the use of Adam optimizer, which dynamically calculates learning rates parameter-specific. Besides, all hyper-parameters of Adam has been using their Keras default values. This implies values of $\\eta = 0.001$, $\\beta_1 = 0.9$ and $\\beta_2 = 0.999$. While $\\eta$ is the initial learning rate, $\\beta_1$ and $\\beta_2$ control the decay of learning rates. The decay causes faster learning during initial updates, sequentially slowing down as iterations take place. Therefore, the higher decay parameters are, the more dynamic the learning process will be. Note that no decay (and no momentum) results in standard stochastic gradient descent (SGD).\n",
    "<br>\n",
    "<br>\n",
    "Consequently, two tests shoud be implemented in order to fine tune the learning process: first, alternative values for Adam hyper-parameters will be used; then, tests will focus on different settings for SGD optimizer. The comparison between Adam and SGD optimizers will result from these two tests.\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above:\n",
    "* Random samples of training and validation data.\n",
    "* *Following results of tests from an earlier section, cross-entropy cost function will be used. Regarding activation functions, sigmoid will be applied for the neuron in the output layer, while tanh activation function will be used for neurons in hidden layers, since this alternative has shown the best results during tests.*\n",
    "* Fitting hyper-parameters: *after previous tests, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$.*\n",
    "* *After tests for number of neurons and number of hidden layers, the architecture will be given by two hidden layers with the following number of neurons:*\n",
    "    * $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "    * $J_2 = J_1/2$.\n",
    "<br>\n",
    "<br>\n",
    "* *The section concerning regularization has shown that L2 regularization with $\\lambda = 1e-5$ is the best alternative to improve generalization by using standard regularization techniques.*\n",
    "* *Previous tests have pointed to the adequacy of using dropout layers with parameters $\\rho_{input} = 0.1$ and $\\rho_{hidden} = 0.1$ for input and hidden layers, respectively.*\n",
    "* No early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data. Defining the best SGD setting will also make use of cost function evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adam_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Adam hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'learning_rate': [0.001, 0.01, 0.0001],\n",
    "    'beta_1': [0.9, 0.75, 0.99],\n",
    "    'beta_2': [0.999, 0.9, 0.9999],\n",
    "    'epsilon': [1e-07]\n",
    "}\n",
    "\n",
    "# List with all permutations of possible values for hyper-parameters:\n",
    "opt_params = permutation(opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 135.88 minutes.\n",
      "Start time: 2021-01-31, 13:31:52\n",
      "End time: 2021-01-31, 15:47:45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(opt_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over optimizer parameters:\n",
    "for o in range(len(opt_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params[o],\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params[o]\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'stdroc_auc': np.nanstd(val_roc_auc),\n",
    "            'stdavg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'stdbrier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative values for Adam hyper-parameters.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(o+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1612103127</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.841918</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.220372</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>91.278950</td>\n",
       "      <td>21.397904</td>\n",
       "      <td>33.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1612035335</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.840332</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.216347</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>95.575174</td>\n",
       "      <td>21.157383</td>\n",
       "      <td>18.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1612101357</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.834922</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.212843</td>\n",
       "      <td>0.012475</td>\n",
       "      <td>75.834169</td>\n",
       "      <td>17.062192</td>\n",
       "      <td>29.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1612034069</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.833715</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.211345</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>67.468275</td>\n",
       "      <td>19.248567</td>\n",
       "      <td>21.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1612061623</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.831532</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.213040</td>\n",
       "      <td>0.009796</td>\n",
       "      <td>99.957116</td>\n",
       "      <td>21.747802</td>\n",
       "      <td>20.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1612060550</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.822889</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.205331</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>62.402770</td>\n",
       "      <td>19.501402</td>\n",
       "      <td>17.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1612042453</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.797746</td>\n",
       "      <td>0.013293</td>\n",
       "      <td>0.139704</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>60.011605</td>\n",
       "      <td>10.918304</td>\n",
       "      <td>35.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1612058405</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.797398</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.138820</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>73.264003</td>\n",
       "      <td>10.759020</td>\n",
       "      <td>18.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1612114011</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.796865</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.137727</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>66.114846</td>\n",
       "      <td>10.786355</td>\n",
       "      <td>20.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1612115212</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>71.083088</td>\n",
       "      <td>10.747258</td>\n",
       "      <td>29.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1612097891</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.786739</td>\n",
       "      <td>0.014489</td>\n",
       "      <td>0.134954</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>54.299236</td>\n",
       "      <td>10.487556</td>\n",
       "      <td>17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1612098949</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.786698</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.125711</td>\n",
       "      <td>0.011611</td>\n",
       "      <td>56.910389</td>\n",
       "      <td>10.827307</td>\n",
       "      <td>19.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1612038919</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.776932</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.182270</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>53.808385</td>\n",
       "      <td>12.564284</td>\n",
       "      <td>27.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1612111854</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.775888</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>0.180521</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>57.987397</td>\n",
       "      <td>12.704524</td>\n",
       "      <td>17.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1612066539</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.769768</td>\n",
       "      <td>0.018074</td>\n",
       "      <td>0.168056</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>42.589098</td>\n",
       "      <td>11.863354</td>\n",
       "      <td>33.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1612105146</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.762299</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>0.113842</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>44.423984</td>\n",
       "      <td>9.199696</td>\n",
       "      <td>34.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1612036435</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.761005</td>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.113814</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>40.290885</td>\n",
       "      <td>8.658467</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1612059492</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.750360</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.095877</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>37.054488</td>\n",
       "      <td>13.969063</td>\n",
       "      <td>17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1612064558</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.748654</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0.157435</td>\n",
       "      <td>0.015884</td>\n",
       "      <td>24.835173</td>\n",
       "      <td>9.911849</td>\n",
       "      <td>33.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1612037620</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.737984</td>\n",
       "      <td>0.022815</td>\n",
       "      <td>0.156216</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>32.346514</td>\n",
       "      <td>10.365058</td>\n",
       "      <td>21.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1612062861</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.736936</td>\n",
       "      <td>0.034001</td>\n",
       "      <td>0.086858</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>21.673846</td>\n",
       "      <td>4.481056</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1612110712</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.736554</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.155628</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>36.940770</td>\n",
       "      <td>10.945691</td>\n",
       "      <td>19.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1612100096</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.729030</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.061596</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>34.144311</td>\n",
       "      <td>6.771818</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1612040541</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.672271</td>\n",
       "      <td>0.029384</td>\n",
       "      <td>0.104714</td>\n",
       "      <td>0.015174</td>\n",
       "      <td>22.878967</td>\n",
       "      <td>6.900792</td>\n",
       "      <td>31.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1612112915</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.669966</td>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.104234</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>21.839666</td>\n",
       "      <td>7.107012</td>\n",
       "      <td>18.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1612096731</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.667381</td>\n",
       "      <td>0.035789</td>\n",
       "      <td>0.077491</td>\n",
       "      <td>0.022254</td>\n",
       "      <td>18.647877</td>\n",
       "      <td>3.482112</td>\n",
       "      <td>19.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                                       architecture  \\\n",
       "19    1612103127  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1     1612035335  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "18    1612101357  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "0     1612034069  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "10    1612061623  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "9     1612060550  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "6     1612042453  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "7     1612058405  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "24    1612114011  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "25    1612115212  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "15    1612097891  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "16    1612098949  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4     1612038919  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "22    1612111854  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "13    1612066539  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "20    1612105146  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2     1612036435  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "8     1612059492  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "12    1612064558  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3     1612037620  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "11    1612062861  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "21    1612110712  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "17    1612100096  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5     1612040541  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "23    1612112915  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "14    1612096731  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "    num_layers num_neurons activation_function optimizer  learning_rate  \\\n",
       "19           2    [45, 22]                tanh      adam         0.0010   \n",
       "1            2    [45, 22]                tanh      adam         0.0010   \n",
       "18           2    [45, 22]                tanh      adam         0.0010   \n",
       "0            2    [45, 22]                tanh      adam         0.0010   \n",
       "10           2    [45, 22]                tanh      adam         0.0010   \n",
       "9            2    [45, 22]                tanh      adam         0.0010   \n",
       "6            2    [45, 22]                tanh      adam         0.0001   \n",
       "7            2    [45, 22]                tanh      adam         0.0001   \n",
       "24           2    [45, 22]                tanh      adam         0.0001   \n",
       "25           2    [45, 22]                tanh      adam         0.0001   \n",
       "15           2    [45, 22]                tanh      adam         0.0001   \n",
       "16           2    [45, 22]                tanh      adam         0.0001   \n",
       "4            2    [45, 22]                tanh      adam         0.0100   \n",
       "22           2    [45, 22]                tanh      adam         0.0100   \n",
       "13           2    [45, 22]                tanh      adam         0.0100   \n",
       "20           2    [45, 22]                tanh      adam         0.0010   \n",
       "2            2    [45, 22]                tanh      adam         0.0010   \n",
       "8            2    [45, 22]                tanh      adam         0.0001   \n",
       "12           2    [45, 22]                tanh      adam         0.0100   \n",
       "3            2    [45, 22]                tanh      adam         0.0100   \n",
       "11           2    [45, 22]                tanh      adam         0.0010   \n",
       "21           2    [45, 22]                tanh      adam         0.0100   \n",
       "17           2    [45, 22]                tanh      adam         0.0001   \n",
       "5            2    [45, 22]                tanh      adam         0.0100   \n",
       "23           2    [45, 22]                tanh      adam         0.0100   \n",
       "14           2    [45, 22]                tanh      adam         0.0100   \n",
       "\n",
       "    beta_1  beta_2  avg_roc_auc  std_roc_auc  avg_prec  std_prec  \\\n",
       "19    0.75  0.9999     0.841918     0.009224  0.220372  0.010299   \n",
       "1     0.75  0.9990     0.840332     0.008792  0.216347  0.010226   \n",
       "18    0.90  0.9999     0.834922     0.011010  0.212843  0.012475   \n",
       "0     0.90  0.9990     0.833715     0.012357  0.211345  0.010980   \n",
       "10    0.75  0.9000     0.831532     0.008319  0.213040  0.009796   \n",
       "9     0.90  0.9000     0.822889     0.013187  0.205331  0.010529   \n",
       "6     0.90  0.9990     0.797746     0.013293  0.139704  0.012795   \n",
       "7     0.75  0.9990     0.797398     0.010884  0.138820  0.012903   \n",
       "24    0.90  0.9999     0.796865     0.012053  0.137727  0.012769   \n",
       "25    0.75  0.9999     0.796087     0.011199  0.140300  0.013054   \n",
       "15    0.90  0.9000     0.786739     0.014489  0.134954  0.012868   \n",
       "16    0.75  0.9000     0.786698     0.013823  0.125711  0.011611   \n",
       "4     0.75  0.9990     0.776932     0.014439  0.182270  0.014507   \n",
       "22    0.75  0.9999     0.775888     0.013380  0.180521  0.014209   \n",
       "13    0.75  0.9000     0.769768     0.018074  0.168056  0.014166   \n",
       "20    0.99  0.9999     0.762299     0.017160  0.113842  0.012375   \n",
       "2     0.99  0.9990     0.761005     0.018888  0.113814  0.013145   \n",
       "8     0.99  0.9990     0.750360     0.020250  0.095877  0.006864   \n",
       "12    0.90  0.9000     0.748654     0.030145  0.157435  0.015884   \n",
       "3     0.90  0.9990     0.737984     0.022815  0.156216  0.015071   \n",
       "11    0.99  0.9000     0.736936     0.034001  0.086858  0.019383   \n",
       "21    0.90  0.9999     0.736554     0.019939  0.155628  0.014218   \n",
       "17    0.99  0.9000     0.729030     0.021351  0.061596  0.009096   \n",
       "5     0.99  0.9990     0.672271     0.029384  0.104714  0.015174   \n",
       "23    0.99  0.9999     0.669966     0.030677  0.104234  0.014666   \n",
       "14    0.99  0.9000     0.667381     0.035789  0.077491  0.022254   \n",
       "\n",
       "    ratio_roc_auc  ratio_prec  running_time  \n",
       "19      91.278950   21.397904         33.63  \n",
       "1       95.575174   21.157383         18.32  \n",
       "18      75.834169   17.062192         29.48  \n",
       "0       67.468275   19.248567         21.08  \n",
       "10      99.957116   21.747802         20.62  \n",
       "9       62.402770   19.501402         17.87  \n",
       "6       60.011605   10.918304         35.15  \n",
       "7       73.264003   10.759020         18.10  \n",
       "24      66.114846   10.786355         20.02  \n",
       "25      71.083088   10.747258         29.05  \n",
       "15      54.299236   10.487556         17.62  \n",
       "16      56.910389   10.827307         19.12  \n",
       "4       53.808385   12.564284         27.02  \n",
       "22      57.987397   12.704524         17.67  \n",
       "13      42.589098   11.863354         33.78  \n",
       "20      44.423984    9.199696         34.60  \n",
       "2       40.290885    8.658467         19.75  \n",
       "8       37.054488   13.969063         17.62  \n",
       "12      24.835173    9.911849         33.00  \n",
       "3       32.346514   10.365058         21.63  \n",
       "11      21.673846    4.481056         28.28  \n",
       "21      36.940770   10.945691         19.03  \n",
       "17      34.144311    6.771818         21.02  \n",
       "5       22.878967    6.900792         31.87  \n",
       "23      21.839666    7.107012         18.25  \n",
       "14      18.647877    3.482112         19.32  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "optimizers = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "activations = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over optimizer parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative values for Adam hyper-parameters.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by Adam parameters:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sgd_opt1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD optimizer (no momentum and no decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis tries to identify an appropriate value for the learning rate $\\eta_0$ such that learning occurs rapidly enough without too much oscillation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'relu',\n",
    "                          'dropout_param': 0}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "opt_params = {'learning_rate': 0.005, 'momentum': 0.0, 'decay': 0.0}\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'sgd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 2.03 minutes.\n",
      "Start time: 2021-02-01, 12:33:04\n",
      "End time: 2021-02-01, 12:35:07\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "epoch_costs = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "val_roc_auc = []\n",
    "val_avg_prec_score = []\n",
    "val_brier_score = []\n",
    "epoch_performance = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for t in range(n_estimations):\n",
    "    # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "    model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                     output_activation = output_activation, cost_function = cost_function,\n",
    "                     num_epochs = num_epochs, batch_size = batch_size,\n",
    "                     default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                     regularization = regularization, regul_param = regul_param,\n",
    "                     input_dropout = input_dropout)\n",
    "\n",
    "    # Training the model:\n",
    "    model.run(train_inputs = X_train, train_output = y_train,\n",
    "              val_inputs = X_val, val_output = y_val,\n",
    "              verbose = 0)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "    val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "\n",
    "    # Cost function by training epoch:\n",
    "    model_costs = model.model_costs\n",
    "    epoch_costs.append({'epoch': list(model_costs['epoch']),\n",
    "                        'loss': list(model_costs['loss']),\n",
    "                        'val_loss': list(model_costs['val_loss'])})\n",
    "\n",
    "    min_cost.append(model_costs.loss.min())\n",
    "    epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "    min_cost.append(model_costs.val_loss.min())\n",
    "    epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Running time and performance metrics on validation data by epoch of training:\n",
    "    epoch_performance.append(model.epoch_performance)\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regularization': regularization,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam,\n",
    "        'optimizer': optimizer,\n",
    "        'opt_params': opt_params\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'validation',\n",
    "        'avg_epoch_costs': {\n",
    "            'epoch': [sum(l)/len(l) for l in zip(*[d['epoch'] for d in epoch_costs])],\n",
    "            'loss': [sum(l)/len(l) for l in zip(*[d['loss'] for d in epoch_costs])],\n",
    "            'val_loss': [sum(l)/len(l) for l in zip(*[d['val_loss'] for d in epoch_costs])]\n",
    "        },\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(val_brier_score),\n",
    "        'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(val_brier_score),\n",
    "        'avg_epoch_performance': {\n",
    "            'roc_auc': [sum(l)/len(l) for l in zip(*[d['epoch_val_roc_auc'] for d in epoch_performance])],\n",
    "            'avg_prec_score': [sum(l)/len(l) for l in zip(*[d['epoch_avg_prec_score'] for d in\n",
    "                                                            epoch_performance])],\n",
    "            'brier_score': [sum(l)/len(l) for l in zip(*[d['epoch_brier_score'] for d in\n",
    "                                                         epoch_performance])],\n",
    "            'running_time': [sum(l)/len(l) for l in zip(*[d['running_time'] for d in epoch_performance])]\n",
    "        }\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": '{0}. Defining learning rate with no momentum and no decay.'.format(model_architecture_def)\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1612134743': 0.01,\n",
       " '1612135513': 0.1,\n",
       " '1612135652': 1,\n",
       " '1612136651': 0.001,\n",
       " '1612139237': 0.0001,\n",
       " '1612193584': 0.005}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs = dict(zip([e for e in model_assessment.keys() if ('Defining learning rate with no momentum and no decay.' in\n",
    "                                        model_assessment[e]['comment'])],\n",
    "               [model_assessment[e]['hyper_parameters']['opt_params']['learning_rate'] for e in\n",
    "                model_assessment.keys() if ('Defining learning rate with no momentum and no decay.' in\n",
    "                                            model_assessment[e]['comment'])]))\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an estimation_id:\n",
    "es_id = '1612193584'\n",
    "\n",
    "outcomes = model_assessment[es_id]\n",
    "\n",
    "# Cost function by training epoch:\n",
    "model_costs = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'loss': outcomes['performance_metrics']['avg_epoch_costs']['loss'],\n",
    "    'val_loss': outcomes['performance_metrics']['avg_epoch_costs']['val_loss']\n",
    "})\n",
    "\n",
    "epoch_performances = pd.DataFrame(data = {\n",
    "    'epoch': outcomes['performance_metrics']['avg_epoch_costs']['epoch'],\n",
    "    'roc_auc': outcomes['performance_metrics']['avg_epoch_performance']['roc_auc'],\n",
    "    'avg_prec_score': outcomes['performance_metrics']['avg_epoch_performance']['avg_prec_score']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "loss = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Training cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.21544434130191803,
          0.11494031548500061,
          0.09316950291395187,
          0.08436158299446106,
          0.07903182506561279,
          0.07566986978054047,
          0.07306259870529175,
          0.07158487290143967,
          0.06911801546812057,
          0.06778917461633682,
          0.06614521145820618,
          0.06545772403478622,
          0.06289764493703842,
          0.062331005930900574,
          0.060226261615753174,
          0.05982780456542969,
          0.058983903378248215,
          0.05863972753286362,
          0.057212475687265396,
          0.05648605898022652,
          0.055113039910793304,
          0.0552731454372406,
          0.054102636873722076,
          0.05222509801387787,
          0.051710501313209534,
          0.0514780730009079,
          0.051678139716386795,
          0.050426043570041656,
          0.049776747822761536,
          0.04868955537676811,
          0.048416901379823685,
          0.04785603657364845,
          0.04731106385588646,
          0.046793047338724136,
          0.04605834186077118,
          0.04620804637670517,
          0.04495980963110924,
          0.04534054920077324,
          0.04570402950048447,
          0.0446050763130188,
          0.04435967653989792,
          0.04458080977201462,
          0.043266698718070984,
          0.042840585112571716,
          0.04268711060285568,
          0.04269280657172203,
          0.04217924922704697,
          0.04078918322920799,
          0.041516244411468506,
          0.04028041288256645,
          0.04077766835689545,
          0.0393860749900341,
          0.039182014763355255,
          0.039714641869068146,
          0.03932029381394386,
          0.03940815106034279,
          0.03873838111758232,
          0.03728480637073517,
          0.038572758436203,
          0.03866797685623169,
          0.03863409161567688,
          0.037573449313640594,
          0.03823806717991829,
          0.03680418059229851,
          0.037115078419446945,
          0.036247894167900085,
          0.03646974638104439,
          0.03714634105563164,
          0.03630991280078888,
          0.03638332337141037,
          0.03623891621828079,
          0.03551236540079117,
          0.03560785949230194,
          0.03567203879356384,
          0.034819621592760086,
          0.03510456159710884,
          0.03513297438621521,
          0.035164620727300644,
          0.034722454845905304,
          0.03417382761836052,
          0.03482354059815407,
          0.033959485590457916,
          0.03462330251932144,
          0.03367196395993233,
          0.03292626515030861,
          0.03414567559957504,
          0.033425040543079376,
          0.03348059579730034,
          0.03256005048751831,
          0.0334155298769474,
          0.03244074061512947,
          0.032430779188871384,
          0.032622139900922775,
          0.03188552334904671,
          0.032266661524772644,
          0.03249775990843773,
          0.03119007684290409,
          0.03131776675581932,
          0.031189516186714172,
          0.03172227367758751
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "val_loss = %{y:.4f}",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Validation cost",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100
         ],
         "xaxis": "x",
         "y": [
          0.15737740695476532,
          0.11383627355098724,
          0.09998035430908203,
          0.0927724689245224,
          0.0878588929772377,
          0.08569712191820145,
          0.08460182696580887,
          0.08327056467533112,
          0.08110040426254272,
          0.08024713397026062,
          0.07938428968191147,
          0.07788629829883575,
          0.07653699070215225,
          0.07468143105506897,
          0.07376613467931747,
          0.07437806576490402,
          0.07328753173351288,
          0.07177476584911346,
          0.07172740250825882,
          0.07030187547206879,
          0.06974244117736816,
          0.06937385350465775,
          0.0669836476445198,
          0.06608261913061142,
          0.0666704848408699,
          0.06705541908740997,
          0.06548821926116943,
          0.06422077119350433,
          0.06241316720843315,
          0.06309913098812103,
          0.06276287138462067,
          0.061702340841293335,
          0.060702819377183914,
          0.060834117233753204,
          0.060486841946840286,
          0.05899127572774887,
          0.06088477373123169,
          0.060155775398015976,
          0.05847788229584694,
          0.06012604385614395,
          0.06071275845170021,
          0.058306582272052765,
          0.05741887167096138,
          0.0563105009496212,
          0.058312103152275085,
          0.057637326419353485,
          0.05577933415770531,
          0.057765573263168335,
          0.05590672791004181,
          0.055466294288635254,
          0.05525149777531624,
          0.055699799209833145,
          0.05486704781651497,
          0.05457765981554985,
          0.054667163640260696,
          0.053618915379047394,
          0.05256688967347145,
          0.05341774970293045,
          0.053339362144470215,
          0.05418968200683594,
          0.05349096655845642,
          0.05283783748745918,
          0.052821606397628784,
          0.05282892659306526,
          0.05213959515094757,
          0.051715463399887085,
          0.05204197019338608,
          0.05140024051070213,
          0.05191623792052269,
          0.052404385060071945,
          0.0520528219640255,
          0.051220785826444626,
          0.0520746186375618,
          0.0512252002954483,
          0.05144624039530754,
          0.05192674323916435,
          0.05197269842028618,
          0.05149892345070839,
          0.05107775703072548,
          0.05195994675159454,
          0.0508713535964489,
          0.05041894689202309,
          0.050809819251298904,
          0.05066417157649994,
          0.05051061138510704,
          0.05106287822127342,
          0.051242679357528687,
          0.04955486208200455,
          0.050308603793382645,
          0.04938313737511635,
          0.05030756816267967,
          0.05102381482720375,
          0.04965537413954735,
          0.05033542215824127,
          0.04924674704670906,
          0.050080183893442154,
          0.0484037809073925,
          0.04899926111102104,
          0.04895193129777908,
          0.04951121285557747
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Cost function by epoch of training - Learning rate = 0.005"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "cost"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"df6e11c2-e18e-41f0-ac62-9ef47662dd7c\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"df6e11c2-e18e-41f0-ac62-9ef47662dd7c\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'df6e11c2-e18e-41f0-ac62-9ef47662dd7c',\n",
       "                        [{\"hovertemplate\": \"loss = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Training cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.21544434130191803, 0.11494031548500061, 0.09316950291395187, 0.08436158299446106, 0.07903182506561279, 0.07566986978054047, 0.07306259870529175, 0.07158487290143967, 0.06911801546812057, 0.06778917461633682, 0.06614521145820618, 0.06545772403478622, 0.06289764493703842, 0.062331005930900574, 0.060226261615753174, 0.05982780456542969, 0.058983903378248215, 0.05863972753286362, 0.057212475687265396, 0.05648605898022652, 0.055113039910793304, 0.0552731454372406, 0.054102636873722076, 0.05222509801387787, 0.051710501313209534, 0.0514780730009079, 0.051678139716386795, 0.050426043570041656, 0.049776747822761536, 0.04868955537676811, 0.048416901379823685, 0.04785603657364845, 0.04731106385588646, 0.046793047338724136, 0.04605834186077118, 0.04620804637670517, 0.04495980963110924, 0.04534054920077324, 0.04570402950048447, 0.0446050763130188, 0.04435967653989792, 0.04458080977201462, 0.043266698718070984, 0.042840585112571716, 0.04268711060285568, 0.04269280657172203, 0.04217924922704697, 0.04078918322920799, 0.041516244411468506, 0.04028041288256645, 0.04077766835689545, 0.0393860749900341, 0.039182014763355255, 0.039714641869068146, 0.03932029381394386, 0.03940815106034279, 0.03873838111758232, 0.03728480637073517, 0.038572758436203, 0.03866797685623169, 0.03863409161567688, 0.037573449313640594, 0.03823806717991829, 0.03680418059229851, 0.037115078419446945, 0.036247894167900085, 0.03646974638104439, 0.03714634105563164, 0.03630991280078888, 0.03638332337141037, 0.03623891621828079, 0.03551236540079117, 0.03560785949230194, 0.03567203879356384, 0.034819621592760086, 0.03510456159710884, 0.03513297438621521, 0.035164620727300644, 0.034722454845905304, 0.03417382761836052, 0.03482354059815407, 0.033959485590457916, 0.03462330251932144, 0.03367196395993233, 0.03292626515030861, 0.03414567559957504, 0.033425040543079376, 0.03348059579730034, 0.03256005048751831, 0.0334155298769474, 0.03244074061512947, 0.032430779188871384, 0.032622139900922775, 0.03188552334904671, 0.032266661524772644, 0.03249775990843773, 0.03119007684290409, 0.03131776675581932, 0.031189516186714172, 0.03172227367758751], \"yaxis\": \"y\"}, {\"hovertemplate\": \"val_loss = %{y:.4f}\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Validation cost\", \"type\": \"scatter\", \"x\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0], \"xaxis\": \"x\", \"y\": [0.15737740695476532, 0.11383627355098724, 0.09998035430908203, 0.0927724689245224, 0.0878588929772377, 0.08569712191820145, 0.08460182696580887, 0.08327056467533112, 0.08110040426254272, 0.08024713397026062, 0.07938428968191147, 0.07788629829883575, 0.07653699070215225, 0.07468143105506897, 0.07376613467931747, 0.07437806576490402, 0.07328753173351288, 0.07177476584911346, 0.07172740250825882, 0.07030187547206879, 0.06974244117736816, 0.06937385350465775, 0.0669836476445198, 0.06608261913061142, 0.0666704848408699, 0.06705541908740997, 0.06548821926116943, 0.06422077119350433, 0.06241316720843315, 0.06309913098812103, 0.06276287138462067, 0.061702340841293335, 0.060702819377183914, 0.060834117233753204, 0.060486841946840286, 0.05899127572774887, 0.06088477373123169, 0.060155775398015976, 0.05847788229584694, 0.06012604385614395, 0.06071275845170021, 0.058306582272052765, 0.05741887167096138, 0.0563105009496212, 0.058312103152275085, 0.057637326419353485, 0.05577933415770531, 0.057765573263168335, 0.05590672791004181, 0.055466294288635254, 0.05525149777531624, 0.055699799209833145, 0.05486704781651497, 0.05457765981554985, 0.054667163640260696, 0.053618915379047394, 0.05256688967347145, 0.05341774970293045, 0.053339362144470215, 0.05418968200683594, 0.05349096655845642, 0.05283783748745918, 0.052821606397628784, 0.05282892659306526, 0.05213959515094757, 0.051715463399887085, 0.05204197019338608, 0.05140024051070213, 0.05191623792052269, 0.052404385060071945, 0.0520528219640255, 0.051220785826444626, 0.0520746186375618, 0.0512252002954483, 0.05144624039530754, 0.05192674323916435, 0.05197269842028618, 0.05149892345070839, 0.05107775703072548, 0.05195994675159454, 0.0508713535964489, 0.05041894689202309, 0.050809819251298904, 0.05066417157649994, 0.05051061138510704, 0.05106287822127342, 0.051242679357528687, 0.04955486208200455, 0.050308603793382645, 0.04938313737511635, 0.05030756816267967, 0.05102381482720375, 0.04965537413954735, 0.05033542215824127, 0.04924674704670906, 0.050080183893442154, 0.0484037809073925, 0.04899926111102104, 0.04895193129777908, 0.04951121285557747], \"yaxis\": \"y\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Cost function by epoch of training - Learning rate = 0.005\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"cost\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('df6e11c2-e18e-41f0-ac62-9ef47662dd7c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': False}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.loss, name='Training cost',\n",
    "               hovertemplate =\n",
    "                'loss = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=model_costs.epoch,\n",
    "               y=model_costs.val_loss, name='Validation cost',\n",
    "               hovertemplate = 'val_loss = %{y:.4f}',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Cost function by epoch of training - Learning rate = {0}'.format(lrs[es_id]),\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='cost', secondary_y=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sgd_opt2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'sgd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'learning_rate': [0.01, 0.001, 0.005],\n",
    "    'momentum': [0, 0.1, 0.9],\n",
    "    'decay': [0, 0.1, 0.9],\n",
    "}\n",
    "\n",
    "# List with all permutations of possible values for hyper-parameters:\n",
    "opt_params = permutation(opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 19.08 minutes.\n",
      "Start time: 2021-02-03, 22:51:32\n",
      "End time: 2021-02-03, 23:10:38\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(opt_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over optimizer parameters:\n",
    "for o in range(len(opt_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params[o],\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params[o]\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative values for SGD hyper-parameters.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(o+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>momentum</th>\n",
       "      <th>decay</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1612198223</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816414</td>\n",
       "      <td>0.011014</td>\n",
       "      <td>0.192285</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>74.126492</td>\n",
       "      <td>11.449813</td>\n",
       "      <td>28.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1612233471</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814363</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>0.172694</td>\n",
       "      <td>0.018062</td>\n",
       "      <td>64.720750</td>\n",
       "      <td>9.561348</td>\n",
       "      <td>28.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1612196986</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.795981</td>\n",
       "      <td>0.014481</td>\n",
       "      <td>0.144865</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>54.966973</td>\n",
       "      <td>7.601138</td>\n",
       "      <td>20.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1612195537</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791969</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.139983</td>\n",
       "      <td>0.020774</td>\n",
       "      <td>52.535652</td>\n",
       "      <td>6.738231</td>\n",
       "      <td>24.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1612229152</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774697</td>\n",
       "      <td>0.020814</td>\n",
       "      <td>0.128650</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>37.220781</td>\n",
       "      <td>8.168975</td>\n",
       "      <td>27.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1612232174</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.771879</td>\n",
       "      <td>0.023620</td>\n",
       "      <td>0.116165</td>\n",
       "      <td>0.018876</td>\n",
       "      <td>32.678861</td>\n",
       "      <td>6.154082</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1612230820</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.768147</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.110459</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>39.956433</td>\n",
       "      <td>5.787545</td>\n",
       "      <td>22.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1612299796</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.717245</td>\n",
       "      <td>0.027667</td>\n",
       "      <td>0.073812</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>25.924611</td>\n",
       "      <td>4.041969</td>\n",
       "      <td>20.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1612201860</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712283</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.058935</td>\n",
       "      <td>0.016131</td>\n",
       "      <td>33.238699</td>\n",
       "      <td>3.653569</td>\n",
       "      <td>37.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1612199938</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.704824</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.062284</td>\n",
       "      <td>0.019388</td>\n",
       "      <td>29.424035</td>\n",
       "      <td>3.212468</td>\n",
       "      <td>32.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1612319558</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.700940</td>\n",
       "      <td>0.027172</td>\n",
       "      <td>0.064337</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>25.795977</td>\n",
       "      <td>4.131704</td>\n",
       "      <td>23.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1612298344</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.700874</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.053467</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>32.089712</td>\n",
       "      <td>3.251937</td>\n",
       "      <td>24.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1612235210</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.699386</td>\n",
       "      <td>0.026991</td>\n",
       "      <td>0.053216</td>\n",
       "      <td>0.016382</td>\n",
       "      <td>25.912253</td>\n",
       "      <td>3.248437</td>\n",
       "      <td>33.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1612304046</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.688838</td>\n",
       "      <td>0.022357</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>30.811506</td>\n",
       "      <td>4.527697</td>\n",
       "      <td>36.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1612316995</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.681927</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>0.043427</td>\n",
       "      <td>0.013390</td>\n",
       "      <td>26.266053</td>\n",
       "      <td>3.243268</td>\n",
       "      <td>23.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1612318376</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.681098</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>0.045495</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>26.629937</td>\n",
       "      <td>3.235165</td>\n",
       "      <td>19.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1612403492</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.666501</td>\n",
       "      <td>0.027792</td>\n",
       "      <td>0.035521</td>\n",
       "      <td>0.008848</td>\n",
       "      <td>23.981389</td>\n",
       "      <td>4.014475</td>\n",
       "      <td>19.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1612391337</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.662154</td>\n",
       "      <td>0.025783</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>25.681391</td>\n",
       "      <td>2.832511</td>\n",
       "      <td>24.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1612368270</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.655307</td>\n",
       "      <td>0.030305</td>\n",
       "      <td>0.032444</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>21.623573</td>\n",
       "      <td>3.189346</td>\n",
       "      <td>26.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1612366948</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.654161</td>\n",
       "      <td>0.027992</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>23.369793</td>\n",
       "      <td>2.681716</td>\n",
       "      <td>22.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1612387931</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.653564</td>\n",
       "      <td>0.036467</td>\n",
       "      <td>0.034209</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>17.922287</td>\n",
       "      <td>4.306910</td>\n",
       "      <td>17.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1612394587</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.640766</td>\n",
       "      <td>0.035049</td>\n",
       "      <td>0.029828</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>18.281945</td>\n",
       "      <td>2.766429</td>\n",
       "      <td>32.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1612392804</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.639691</td>\n",
       "      <td>0.038799</td>\n",
       "      <td>0.030972</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>16.487097</td>\n",
       "      <td>2.514758</td>\n",
       "      <td>29.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1612302386</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637210</td>\n",
       "      <td>0.041679</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.012915</td>\n",
       "      <td>15.288642</td>\n",
       "      <td>2.440145</td>\n",
       "      <td>27.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1612301039</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637173</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>17.324361</td>\n",
       "      <td>3.278302</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1612390091</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.565912</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>9.126013</td>\n",
       "      <td>2.480569</td>\n",
       "      <td>20.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1612388983</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.562366</td>\n",
       "      <td>0.062395</td>\n",
       "      <td>0.022412</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>9.012979</td>\n",
       "      <td>2.617657</td>\n",
       "      <td>18.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                                       architecture  \\\n",
       "2     1612198223  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "8     1612233471  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1     1612196986  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "0     1612195537  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "5     1612229152  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "7     1612232174  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "6     1612230820  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "11    1612299796  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4     1612201860  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3     1612199938  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "17    1612319558  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "10    1612298344  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "9     1612235210  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "14    1612304046  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "15    1612316995  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "16    1612318376  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "26    1612403492  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "23    1612391337  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "19    1612368270  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "18    1612366948  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "20    1612387931  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "25    1612394587  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "24    1612392804  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "13    1612302386  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "12    1612301039  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "22    1612390091  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "21    1612388983  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "    num_layers num_neurons activation_function optimizer  learning_rate  \\\n",
       "2            2    [45, 22]                tanh       sgd          0.010   \n",
       "8            2    [45, 22]                tanh       sgd          0.005   \n",
       "1            2    [45, 22]                tanh       sgd          0.010   \n",
       "0            2    [45, 22]                tanh       sgd          0.010   \n",
       "5            2    [45, 22]                tanh       sgd          0.001   \n",
       "7            2    [45, 22]                tanh       sgd          0.005   \n",
       "6            2    [45, 22]                tanh       sgd          0.005   \n",
       "11           2    [45, 22]                tanh       sgd          0.010   \n",
       "4            2    [45, 22]                tanh       sgd          0.001   \n",
       "3            2    [45, 22]                tanh       sgd          0.001   \n",
       "17           2    [45, 22]                tanh       sgd          0.005   \n",
       "10           2    [45, 22]                tanh       sgd          0.010   \n",
       "9            2    [45, 22]                tanh       sgd          0.010   \n",
       "14           2    [45, 22]                tanh       sgd          0.001   \n",
       "15           2    [45, 22]                tanh       sgd          0.005   \n",
       "16           2    [45, 22]                tanh       sgd          0.005   \n",
       "26           2    [45, 22]                tanh       sgd          0.005   \n",
       "23           2    [45, 22]                tanh       sgd          0.001   \n",
       "19           2    [45, 22]                tanh       sgd          0.010   \n",
       "18           2    [45, 22]                tanh       sgd          0.010   \n",
       "20           2    [45, 22]                tanh       sgd          0.010   \n",
       "25           2    [45, 22]                tanh       sgd          0.005   \n",
       "24           2    [45, 22]                tanh       sgd          0.005   \n",
       "13           2    [45, 22]                tanh       sgd          0.001   \n",
       "12           2    [45, 22]                tanh       sgd          0.001   \n",
       "22           2    [45, 22]                tanh       sgd          0.001   \n",
       "21           2    [45, 22]                tanh       sgd          0.001   \n",
       "\n",
       "    momentum  decay  avg_roc_auc  std_roc_auc  avg_prec  std_prec  \\\n",
       "2        0.9    0.0     0.816414     0.011014  0.192285  0.016794   \n",
       "8        0.9    0.0     0.814363     0.012583  0.172694  0.018062   \n",
       "1        0.1    0.0     0.795981     0.014481  0.144865  0.019058   \n",
       "0        0.0    0.0     0.791969     0.015075  0.139983  0.020774   \n",
       "5        0.9    0.0     0.774697     0.020814  0.128650  0.015749   \n",
       "7        0.1    0.0     0.771879     0.023620  0.116165  0.018876   \n",
       "6        0.0    0.0     0.768147     0.019225  0.110459  0.019086   \n",
       "11       0.9    0.1     0.717245     0.027667  0.073812  0.018261   \n",
       "4        0.1    0.0     0.712283     0.021429  0.058935  0.016131   \n",
       "3        0.0    0.0     0.704824     0.023954  0.062284  0.019388   \n",
       "17       0.9    0.1     0.700940     0.027172  0.064337  0.015572   \n",
       "10       0.1    0.1     0.700874     0.021841  0.053467  0.016442   \n",
       "9        0.0    0.1     0.699386     0.026991  0.053216  0.016382   \n",
       "14       0.9    0.1     0.688838     0.022357  0.047672  0.010529   \n",
       "15       0.0    0.1     0.681927     0.025962  0.043427  0.013390   \n",
       "16       0.1    0.1     0.681098     0.025576  0.045495  0.014063   \n",
       "26       0.9    0.9     0.666501     0.027792  0.035521  0.008848   \n",
       "23       0.9    0.9     0.662154     0.025783  0.031496  0.011120   \n",
       "19       0.1    0.9     0.655307     0.030305  0.032444  0.010173   \n",
       "18       0.0    0.9     0.654161     0.027992  0.033756  0.012587   \n",
       "20       0.9    0.9     0.653564     0.036467  0.034209  0.007943   \n",
       "25       0.1    0.9     0.640766     0.035049  0.029828  0.010782   \n",
       "24       0.0    0.9     0.639691     0.038799  0.030972  0.012316   \n",
       "13       0.1    0.1     0.637210     0.041679  0.031515  0.012915   \n",
       "12       0.0    0.1     0.637173     0.036779  0.028663  0.008743   \n",
       "22       0.1    0.9     0.565912     0.062011  0.021549  0.008687   \n",
       "21       0.0    0.9     0.562366     0.062395  0.022412  0.008562   \n",
       "\n",
       "    ratio_roc_auc  ratio_prec  running_time  \n",
       "2       74.126492   11.449813         28.55  \n",
       "8       64.720750    9.561348         28.97  \n",
       "1       54.966973    7.601138         20.60  \n",
       "0       52.535652    6.738231         24.13  \n",
       "5       37.220781    8.168975         27.78  \n",
       "7       32.678861    6.154082         21.62  \n",
       "6       39.956433    5.787545         22.55  \n",
       "11      25.924611    4.041969         20.72  \n",
       "4       33.238699    3.653569         37.37  \n",
       "3       29.424035    3.212468         32.02  \n",
       "17      25.795977    4.131704         23.22  \n",
       "10      32.089712    3.251937         24.18  \n",
       "9       25.912253    3.248437         33.27  \n",
       "14      30.811506    4.527697         36.48  \n",
       "15      26.266053    3.243268         23.02  \n",
       "16      26.629937    3.235165         19.68  \n",
       "26      23.981389    4.014475         19.08  \n",
       "23      25.681391    2.832511         24.45  \n",
       "19      21.623573    3.189346         26.88  \n",
       "18      23.369793    2.681716         22.02  \n",
       "20      17.922287    4.306910         17.52  \n",
       "25      18.281945    2.766429         32.52  \n",
       "24      16.487097    2.514758         29.70  \n",
       "13      15.288642    2.440145         27.65  \n",
       "12      17.324361    3.278302         22.45  \n",
       "22       9.126013    2.480569         20.75  \n",
       "21       9.012979    2.617657         18.47  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "optimizers = []\n",
    "learning_rates = []\n",
    "momentums = []\n",
    "decays = []\n",
    "activations = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over optimizer parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative values for SGD hyper-parameters.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    momentums.append(e['hyper_parameters']['opt_params']['momentum'])\n",
    "    decays.append(e['hyper_parameters']['opt_params']['decay'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by SGD parameters:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'momentum': momentums,\n",
    "    'decay': decays,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameters_init'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default distribution for weights initialization is given by **Glorot Uniform** specification. Under this setting, initial values for its weights $w_{jk}^l$ are extracted from a Uniform distribution $Unif(-a, a)$:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle a = \\sqrt{\\frac{6}{fan\\_in + fan\\_out}}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Where $fan\\_in$ is the number of predecessor neurons and $fan\\_out$ is the number of subsequent neurons with respect to weight $w_{jk}^l$. Considering a fully connected layer $l$, $fan\\_in = J_{l-1}$ and $fan\\_out = J_{l+1}$, since all neurons in layer $l$ are connected to all neurons in predecessor layer $l-1$ and to all neurons in subsequent layer $l+1$. An immediate alternative to Glorot Uniform is given by replacing a Uniform distribution by a Normal distribution. This creates the **Glorot Normal** setting, under which initial parameters follow from $N(0, \\sigma)$:\n",
    "<br>\n",
    "<br>\n",
    "\\begin{equation}\n",
    "    \\displaystyle \\sigma = \\sqrt{\\frac{2}{fan\\_in + fan\\_out}}\n",
    "\\end{equation}\n",
    "<br>\n",
    "<br>\n",
    "Instead of these specifications that consider the density connection of neurons, two further alternatives involve the use of constant **Uniform distribution**, $Unif(-a, a)$, and constant **Normal distribution**, $N(0, \\sigma)$. In tests below, it will be used $a = 0.05$ and $\\sigma = 0.05$. A final option regards using a **truncated Normal distribution**, with specification $N(0, \\sigma)$.\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above:\n",
    "* Random samples of training and validation data.\n",
    "* *Following results of tests from an earlier section, cross-entropy cost function will be used. Regarding activation functions, sigmoid will be applied for the neuron in the output layer, while tanh activation function will be used for neurons in hidden layers, since this alternative has shown the best results during tests.*\n",
    "* Fitting hyper-parameters: *after previous tests, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$.*\n",
    "* *After tests for number of neurons and number of hidden layers, the architecture will be given by two hidden layers with the following number of neurons:*\n",
    "    * $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "    * $J_2 = J_1/2$.\n",
    "<br>\n",
    "<br>\n",
    "* *For the learning rate setting, tests have shown that Adam is a better option when compared to SGD optimizer. The best specification of its hyper-parameters is as follows: $learning\\_rate = 0.001$, $\\beta_1 = 0.75$ and $\\beta_2 = 0.9999$. This represents a modification to default values ($learning\\_rate = 0.001$, $\\beta_1 = 0.9$, $beta_2 = 0.999$).*\n",
    "* *The section concerning regularization has shown that L2 regularization with $\\lambda = 1e-5$ is the best alternative to improve generalization by using standard regularization techniques.*\n",
    "* *Previous tests have pointed to the adequacy of using dropout layers with parameters $\\rho_{input} = 0.1$ and $\\rho_{hidden} = 0.1$ for input and hidden layers, respectively.*\n",
    "* No early stopping.\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='distributions'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid of distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.75,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = ['glorot_uniform', 'glorot_normal', 'random_uniform', 'random_normal', 'truncated_normal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 110.38 minutes.\n",
      "Start time: 2021-02-06, 15:24:16\n",
      "End time: 2021-02-06, 17:14:39\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(dists),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over weights initialization:\n",
    "for d in range(len(dists)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout,\n",
    "                         weights_init = dists[d])\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params,\n",
    "            'weights_init': dists[d]\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Testing alternative distributions for weights initialization.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(d+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1612635856</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.841320</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.218564</td>\n",
       "      <td>0.011458</td>\n",
       "      <td>96.872546</td>\n",
       "      <td>19.074985</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1612639360</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>random_normal</td>\n",
       "      <td>0.840486</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.213651</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>125.281024</td>\n",
       "      <td>20.625824</td>\n",
       "      <td>22.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1612637071</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_normal</td>\n",
       "      <td>0.840143</td>\n",
       "      <td>0.009398</td>\n",
       "      <td>0.220747</td>\n",
       "      <td>0.010508</td>\n",
       "      <td>89.394914</td>\n",
       "      <td>21.008163</td>\n",
       "      <td>19.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1612640689</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>truncated_normal</td>\n",
       "      <td>0.839116</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.215265</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>143.508209</td>\n",
       "      <td>23.105433</td>\n",
       "      <td>29.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1612638230</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>random_uniform</td>\n",
       "      <td>0.834036</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.212340</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>145.093344</td>\n",
       "      <td>23.009790</td>\n",
       "      <td>18.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "0    1612635856  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "3    1612639360  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "1    1612637071  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "4    1612640689  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "2    1612638230  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "\n",
       "   num_layers num_neurons activation_function optimizer  learning_rate  \\\n",
       "0           2    [45, 22]                tanh      adam          0.001   \n",
       "3           2    [45, 22]                tanh      adam          0.001   \n",
       "1           2    [45, 22]                tanh      adam          0.001   \n",
       "4           2    [45, 22]                tanh      adam          0.001   \n",
       "2           2    [45, 22]                tanh      adam          0.001   \n",
       "\n",
       "   beta_1  beta_2      weights_init  avg_roc_auc  std_roc_auc  avg_prec  \\\n",
       "0    0.75  0.9999    glorot_uniform     0.841320     0.008685  0.218564   \n",
       "3    0.75  0.9999     random_normal     0.840486     0.006709  0.213651   \n",
       "1    0.75  0.9999     glorot_normal     0.840143     0.009398  0.220747   \n",
       "4    0.75  0.9999  truncated_normal     0.839116     0.005847  0.215265   \n",
       "2    0.75  0.9999    random_uniform     0.834036     0.005748  0.212340   \n",
       "\n",
       "   std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "0  0.011458      96.872546   19.074985         20.25  \n",
       "3  0.010358     125.281024   20.625824         22.13  \n",
       "1  0.010508      89.394914   21.008163         19.30  \n",
       "4  0.009317     143.508209   23.105433         29.83  \n",
       "2  0.009228     145.093344   23.009790         18.83  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "optimizers = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "activations = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over weights initialization:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Testing alternative distributions for weights initialization.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by weights initialization:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'weights_init': weights_inits,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='architecture_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying all definitions and hyper-parameters relevant for constructing a fully connected feedforward neural network, it is time to review the architecture previously defined. The following alternatives will be tested:\n",
    "* Current definition: $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$ and $J_2 = J_1/2$.\n",
    "* Alternative 1: $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$.\n",
    "* Alternative 2: $J_1 = (num\\_inputs + num\\_outputs)*0.1$.\n",
    "* Alternative 3: $J_1 = \\sqrt{num\\_inputs*J_2}$ and $J_2 =\\sqrt{J_1*num\\_outputs}$.\n",
    "* Alternative 4: $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$ and $J_2 = J_1$.\n",
    "* Alternative 5: $J_1 = (num\\_inputs + J_2)*0.1$ and $J_2 = (J_1 + num\\_outputs)*0.1$.\n",
    "* Alternative 6: $J_1 = (num\\_inputs + num\\_outputs)*0.1$ and $J_2 = J_1/2$.\n",
    "* Alternative 7: $J_1 = (num\\_inputs + num\\_outputs)*0.1$ and $J_2 = J_1$.\n",
    "* Alternative 8: $J_1 = \\sqrt{num\\_inputs*J_2}$ and $J_2 =\\sqrt{J_1*J_3}$ and $J_3 = \\sqrt{J_2*num\\_outputs}$.\n",
    "* Alternative 9: $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$, $J_2 = J_1/2$, $J_3 = J_1/4$.\n",
    "* Alternative 10: $J_1 = \\sqrt{num\\_inputs*num\\_outputs}$, $J_2 = J_1$, $J_3 = J_1$.\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above:\n",
    "* Random samples of training and validation data.\n",
    "* *Following results of tests from an earlier section, cross-entropy cost function will be used. Regarding activation functions, sigmoid will be applied for the neuron in the output layer, while tanh activation function will be used for neurons in hidden layers, since this alternative has shown the best results during tests.*\n",
    "* Fitting hyper-parameters: *after previous tests, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$.*\n",
    "* *For the learning rate setting, tests have shown that Adam is a better option when compared to SGD optimizer. The best specification of its hyper-parameters is as follows: $learning\\_rate = 0.001$, $\\beta_1 = 0.75$ and $\\beta_2 = 0.9999$. This represents a modification to default values ($learning\\_rate = 0.001$, $\\beta_1 = 0.9$, $beta_2 = 0.999$).*\n",
    "* *The section concerning regularization has shown that L2 regularization with $\\lambda = 1e-5$ is the best alternative to improve generalization by using standard regularization techniques.*\n",
    "* *Previous tests have pointed to the adequacy of using dropout layers with parameters $\\rho_{input} = 0.1$ and $\\rho_{hidden} = 0.1$ for input and hidden layers, respectively.*\n",
    "* No early stopping.\n",
    "* *Testing alternative distributions for weights initialization has shown that Glorot Uniform is the best option among those tested.*\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testing_architectures'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing alternative architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.75,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of model architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First alternative with 1 hidden layer:\n",
    "model_architectures = [{1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                      'activation': 'tanh',\n",
    "                      'dropout_param': 0.1}}]\n",
    "model_architectures_def = ['One hidden layer: J1 = sqrt(num_inputs*num_outputs)']\n",
    "\n",
    "# Second alternative with 1 hidden layer:\n",
    "model_architectures.append({1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('One hidden layer: J1 = (num_inputs + num_outputs)*0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First alternative with 2 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(X_train.shape[1]**(2/3)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(X_train.shape[1]**(1/3)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Two hidden layers: J1 = sqrt(num_inputs*J2), J2 = sqrt(J1*num_outputs)')\n",
    "\n",
    "# Second alternative with 2 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2')\n",
    "\n",
    "# Third alternative with 2 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Two hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1')\n",
    "\n",
    "# Fourth alternative with 2 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(((0.1*X_train.shape[1]) + (0.01*1))/0.99),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int((int(((0.1*X_train.shape[1]) + (0.01*1))/0.99) + 1)*0.1),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Two hidden layers: J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_outputs)*0.1')\n",
    "\n",
    "# Fifth alternative with 2 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1/2)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Two hidden layers: J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2')\n",
    "\n",
    "# Sixth: alternative with 2 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Two hidden layers: J1 = (num_inputs + num_outputs)*0.1, J2 = J1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First alternative with 3 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(X_train.shape[1]**(3/4)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(X_train.shape[1]**(1/2)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      3: {'neurons': int(X_train.shape[1]**(1/4)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Three hidden layers: J1 = sqrt(num_inputs*J2), J2 = sqrt(J1*J3), J3 = sqrt(J2*num_outputs)')\n",
    "\n",
    "# Second alternative with 3 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)/2),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      3: {'neurons': int(np.sqrt(X_train.shape[1]*1)/4),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Three hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1/2, J3 = J1/4')\n",
    "\n",
    "# Third alternative with 3 hidden layers:\n",
    "model_architectures.append({1: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      2: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1},\n",
    "                      3: {'neurons': int(np.sqrt(X_train.shape[1]*1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}})\n",
    "model_architectures_def.append('Three hidden layers: J1 = sqrt(num_inputs*num_outputs), J2 = J1, J3 = J1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 40.48 minutes.\n",
      "Start time: 2021-02-12, 07:42:50\n",
      "End time: 2021-02-12, 08:23:20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(model_architectures),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over architectures:\n",
    "for a in range(len(model_architectures)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architectures[a], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout,\n",
    "                         weights_init = weights_init)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architectures[a]),\n",
    "            'num_hidden_neurons': [model_architectures[a][l]['neurons'] for l in model_architectures[a].keys()],\n",
    "            'hidden_activations': [model_architectures[a][l]['activation'] for l in model_architectures[a].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architectures[a][l]['dropout_param'] for l in model_architectures[a].keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params,\n",
    "            'weights_init': weights_init\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Reviewing model architecture.'.format(model_architectures_def[a])\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(a+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1613085785</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Reviewing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.851381</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.263687</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>189.244136</td>\n",
       "      <td>31.152457</td>\n",
       "      <td>33.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1613087793</td>\n",
       "      <td>J1 = sqrt(num_inputs*J2), J2 = sqrt(J1*num_out...</td>\n",
       "      <td>2</td>\n",
       "      <td>[163, 12]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.846525</td>\n",
       "      <td>0.008377</td>\n",
       "      <td>0.224794</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>101.058540</td>\n",
       "      <td>20.839570</td>\n",
       "      <td>35.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1613084242</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs). Reviewing m...</td>\n",
       "      <td>1</td>\n",
       "      <td>[45]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.845097</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.232920</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>155.589769</td>\n",
       "      <td>22.530213</td>\n",
       "      <td>25.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1613089935</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 22]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.842236</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.219782</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>104.235820</td>\n",
       "      <td>21.031618</td>\n",
       "      <td>34.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1613126570</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1/2, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[45, 22, 11]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.840472</td>\n",
       "      <td>0.008480</td>\n",
       "      <td>0.210435</td>\n",
       "      <td>0.011061</td>\n",
       "      <td>99.114987</td>\n",
       "      <td>19.025528</td>\n",
       "      <td>20.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1613127822</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1, J3...</td>\n",
       "      <td>3</td>\n",
       "      <td>[45, 45, 45]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.840373</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>0.217723</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>128.098596</td>\n",
       "      <td>20.004111</td>\n",
       "      <td>19.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1613091994</td>\n",
       "      <td>J1 = sqrt(num_inputs*num_outputs), J2 = J1. Re...</td>\n",
       "      <td>2</td>\n",
       "      <td>[45, 45]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.838903</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>0.221652</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>106.393521</td>\n",
       "      <td>21.049210</td>\n",
       "      <td>38.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1613102037</td>\n",
       "      <td>J1 = sqrt(num_inputs*J2), J2 = sqrt(J1*J3), J3...</td>\n",
       "      <td>3</td>\n",
       "      <td>[309, 45, 6]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.833386</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.210855</td>\n",
       "      <td>0.013110</td>\n",
       "      <td>71.998131</td>\n",
       "      <td>16.083695</td>\n",
       "      <td>43.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1613096606</td>\n",
       "      <td>J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_out...</td>\n",
       "      <td>2</td>\n",
       "      <td>[211, 21]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.828730</td>\n",
       "      <td>0.013027</td>\n",
       "      <td>0.227253</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>63.617950</td>\n",
       "      <td>20.822321</td>\n",
       "      <td>29.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1613100177</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1, J2 = J1. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[209, 209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.822881</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.241864</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>103.664205</td>\n",
       "      <td>22.983567</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1613098350</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2...</td>\n",
       "      <td>2</td>\n",
       "      <td>[209, 104]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.816256</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.233644</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>101.557108</td>\n",
       "      <td>26.076738</td>\n",
       "      <td>30.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id                                       architecture  \\\n",
       "1     1613085785  J1 = (num_inputs + num_outputs)*0.1. Reviewing...   \n",
       "2     1613087793  J1 = sqrt(num_inputs*J2), J2 = sqrt(J1*num_out...   \n",
       "0     1613084242  J1 = sqrt(num_inputs*num_outputs). Reviewing m...   \n",
       "3     1613089935  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2. ...   \n",
       "9     1613126570  J1 = sqrt(num_inputs*num_outputs), J2 = J1/2, ...   \n",
       "10    1613127822  J1 = sqrt(num_inputs*num_outputs), J2 = J1, J3...   \n",
       "4     1613091994  J1 = sqrt(num_inputs*num_outputs), J2 = J1. Re...   \n",
       "8     1613102037  J1 = sqrt(num_inputs*J2), J2 = sqrt(J1*J3), J3...   \n",
       "5     1613096606  J1 = (num_inputs + J2)*0.1, J2 = (J1 + num_out...   \n",
       "7     1613100177  J1 = (num_inputs + num_outputs)*0.1, J2 = J1. ...   \n",
       "6     1613098350  J1 = (num_inputs + num_outputs)*0.1, J2 = J1/2...   \n",
       "\n",
       "    num_layers   num_neurons activation_function optimizer  learning_rate  \\\n",
       "1            1         [209]                tanh      adam          0.001   \n",
       "2            2     [163, 12]                tanh      adam          0.001   \n",
       "0            1          [45]                tanh      adam          0.001   \n",
       "3            2      [45, 22]                tanh      adam          0.001   \n",
       "9            3  [45, 22, 11]                tanh      adam          0.001   \n",
       "10           3  [45, 45, 45]                tanh      adam          0.001   \n",
       "4            2      [45, 45]                tanh      adam          0.001   \n",
       "8            3  [309, 45, 6]                tanh      adam          0.001   \n",
       "5            2     [211, 21]                tanh      adam          0.001   \n",
       "7            2    [209, 209]                tanh      adam          0.001   \n",
       "6            2    [209, 104]                tanh      adam          0.001   \n",
       "\n",
       "    beta_1  beta_2    weights_init  avg_roc_auc  std_roc_auc  avg_prec  \\\n",
       "1     0.75  0.9999  glorot_uniform     0.851381     0.004499  0.263687   \n",
       "2     0.75  0.9999  glorot_uniform     0.846525     0.008377  0.224794   \n",
       "0     0.75  0.9999  glorot_uniform     0.845097     0.005432  0.232920   \n",
       "3     0.75  0.9999  glorot_uniform     0.842236     0.008080  0.219782   \n",
       "9     0.75  0.9999  glorot_uniform     0.840472     0.008480  0.210435   \n",
       "10    0.75  0.9999  glorot_uniform     0.840373     0.006560  0.217723   \n",
       "4     0.75  0.9999  glorot_uniform     0.838903     0.007885  0.221652   \n",
       "8     0.75  0.9999  glorot_uniform     0.833386     0.011575  0.210855   \n",
       "5     0.75  0.9999  glorot_uniform     0.828730     0.013027  0.227253   \n",
       "7     0.75  0.9999  glorot_uniform     0.822881     0.007938  0.241864   \n",
       "6     0.75  0.9999  glorot_uniform     0.816256     0.008037  0.233644   \n",
       "\n",
       "    std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "1   0.008464     189.244136   31.152457         33.45  \n",
       "2   0.010787     101.058540   20.839570         35.68  \n",
       "0   0.010338     155.589769   22.530213         25.72  \n",
       "3   0.010450     104.235820   21.031618         34.30  \n",
       "9   0.011061      99.114987   19.025528         20.85  \n",
       "10  0.010884     128.098596   20.004111         19.63  \n",
       "4   0.010530     106.393521   21.049210         38.10  \n",
       "8   0.013110      71.998131   16.083695         43.33  \n",
       "5   0.010914      63.617950   20.822321         29.05  \n",
       "7   0.010523     103.664205   22.983567         31.00  \n",
       "6   0.008960     101.557108   26.076738         30.43  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "optimizers = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "activations = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over architectures:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Reviewing model architecture.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_val_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_val_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_val_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_val_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by architecture:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'weights_init': weights_inits,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='further_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This final round of tests aims to explore even further three hyper-parameters that have shown some potential to contribute more with improving performance metrics: mini-batch size, parameter of input dropout, parameter of hidden dropout, and Adam hyper-parameters. Tests will occur subsequently as follows:\n",
    "* Mini-batch size: a grid of three best ranked values will be tested again: $S \\in [32, 512, 1024]$.\n",
    "* Input and hidden dropouts: the best ranked values of $\\rho_{input} = 0.1$ and $\\rho_{output} = 0.1$ will be opposed to no dropout, $\\rho_{input} = 0$ and $\\rho_{hidden}$.\n",
    "* Adam hyper-parameters: $\\beta_1 \\in [0.25, 0.5, 0.75]$ and $\\beta_2 \\in [0.999, 0.9999]$.\n",
    "<br>\n",
    "<br>\n",
    "All estimations will follow the best alternatives derived from tests above (except when the values for the hyper-parameter are to be tested):\n",
    "* Random samples of training and validation data.\n",
    "* *Following results of tests from an earlier section, cross-entropy cost function will be used. Regarding activation functions, sigmoid will be applied for the neuron in the output layer, while tanh activation function will be used for neurons in hidden layers, since this alternative has shown the best results during tests.*\n",
    "* Fitting hyper-parameters: *after previous tests, mini-batch size is set to $S = 512$, while number of epochs is still kept as low as possible to simplify estimations, $T = 10$.*\n",
    "* *After further tests for number of neurons and number of hidden layers, the architecture will be given by one hidden layer with the following number of neurons:* $J_1 = (num\\_inputs + num\\_outputs)*0.1$.\n",
    "* *For the learning rate setting, tests have shown that Adam is a better option when compared to SGD optimizer. The best specification of its hyper-parameters is as follows: $learning\\_rate = 0.001$, $\\beta_1 = 0.75$ and $\\beta_2 = 0.9999$. This represents a modification to default values ($learning\\_rate = 0.001$, $\\beta_1 = 0.9$, $beta_2 = 0.999$).*\n",
    "* *The section concerning regularization has shown that L2 regularization with $\\lambda = 1e-5$ is the best alternative to improve generalization by using standard regularization techniques.*\n",
    "* *Previous tests have pointed to the adequacy of using dropout layers with parameters $\\rho_{input} = 0.1$ and $\\rho_{hidden} = 0.1$ for input and hidden layers, respectively.*\n",
    "* No early stopping.\n",
    "* *Testing alternative distributions for weights initialization has shown that Glorot Uniform is the best option among those tested.*\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = sample_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = sample_train_scaled['y'].values\n",
    "\n",
    "X_val = sample_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = sample_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mini_batch_size_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'One hidden layer: J1 = (num_inputs + num_outputs)*0.1'\n",
    "\n",
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0.1\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.75,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of mini-batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 512, 1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 119.42 minutes.\n",
      "Start time: 2021-02-13, 09:36:40\n",
      "End time: 2021-02-13, 11:36:05\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(batch_sizes),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for b in range(len(batch_sizes)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_sizes[b],\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout,\n",
    "                         weights_init = weights_init)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_sizes[b],\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params,\n",
    "            'weights_init': weights_init\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Reviewing mini-batch size.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(b+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1613225322</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Reviewing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>1024</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.871868</td>\n",
       "      <td>0.006789</td>\n",
       "      <td>0.276781</td>\n",
       "      <td>0.009435</td>\n",
       "      <td>128.420236</td>\n",
       "      <td>29.337094</td>\n",
       "      <td>27.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1613223667</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Reviewing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>512</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.851573</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.262050</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>184.348425</td>\n",
       "      <td>30.768012</td>\n",
       "      <td>27.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1613219800</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Reviewing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>32</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.797981</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.213972</td>\n",
       "      <td>0.015684</td>\n",
       "      <td>145.161158</td>\n",
       "      <td>13.643076</td>\n",
       "      <td>64.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "2    1613225322  J1 = (num_inputs + num_outputs)*0.1. Reviewing...   \n",
       "1    1613223667  J1 = (num_inputs + num_outputs)*0.1. Reviewing...   \n",
       "0    1613219800  J1 = (num_inputs + num_outputs)*0.1. Reviewing...   \n",
       "\n",
       "   num_layers num_neurons  batch_size activation_function optimizer  \\\n",
       "2           1       [209]        1024                tanh      adam   \n",
       "1           1       [209]         512                tanh      adam   \n",
       "0           1       [209]          32                tanh      adam   \n",
       "\n",
       "   learning_rate  beta_1  beta_2    weights_init  avg_roc_auc  std_roc_auc  \\\n",
       "2          0.001    0.75  0.9999  glorot_uniform     0.871868     0.006789   \n",
       "1          0.001    0.75  0.9999  glorot_uniform     0.851573     0.004619   \n",
       "0          0.001    0.75  0.9999  glorot_uniform     0.797981     0.005497   \n",
       "\n",
       "   avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "2  0.276781  0.009435     128.420236   29.337094         27.38  \n",
       "1  0.262050  0.008517     184.348425   30.768012         27.57  \n",
       "0  0.213972  0.015684     145.161158   13.643076         64.45  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "activations = []\n",
    "optimizers = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over mini-batch sizes:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Reviewing mini-batch size.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by mini-batch size:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'batch_size': batch_sizes,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'weights_init': weights_inits,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='input_dropout_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'One hidden layer: J1 = (num_inputs + num_outputs)*0.1.'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.75,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values  for input dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropouts = [0, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 29.57 minutes.\n",
      "Start time: 2021-02-13, 13:07:36\n",
      "End time: 2021-02-13, 13:37:11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(dropouts),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for d in range(len(dropouts)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = dropouts[d],\n",
    "                         weights_init = weights_init)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': dropouts[d],\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params,\n",
    "            'weights_init': weights_init\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Reviewing input dropout parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(d+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>input_dropout</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1613232456</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.852460</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.262223</td>\n",
       "      <td>0.008156</td>\n",
       "      <td>169.513525</td>\n",
       "      <td>32.151235</td>\n",
       "      <td>29.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1613227483</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.262149</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>215.717138</td>\n",
       "      <td>33.791632</td>\n",
       "      <td>33.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "1    1613232456  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "0    1613227483  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "\n",
       "   num_layers num_neurons activation_function optimizer  learning_rate  \\\n",
       "1           1       [209]                tanh      adam          0.001   \n",
       "0           1       [209]                tanh      adam          0.001   \n",
       "\n",
       "   beta_1  beta_2    weights_init  input_dropout  avg_roc_auc  std_roc_auc  \\\n",
       "1    0.75  0.9999  glorot_uniform            0.1     0.852460     0.005029   \n",
       "0    0.75  0.9999  glorot_uniform            0.0     0.852042     0.003950   \n",
       "\n",
       "   avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "1  0.262223  0.008156     169.513525   32.151235         29.55  \n",
       "0  0.262149  0.007758     215.717138   33.791632         33.27  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "activations = []\n",
    "optimizers = []\n",
    "input_dropouts = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Reviewing input dropout parameter.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    input_dropouts.append(e['hyper_parameters']['input_dropout'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by dropout parameter:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'weights_init': weights_inits,\n",
    "    'input_dropout': input_dropouts,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hidden_dropout_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture_def = 'One hidden layer: J1 = (num_inputs + num_outputs)*0.1'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.75,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values  for hidden dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: {'neurons': 209, 'activation': 'tanh', 'dropout_param': 0}},\n",
       " {1: {'neurons': 209, 'activation': 'tanh', 'dropout_param': 0.1}}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_params = [0, 0.1]\n",
    "model_architectures = [{1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                            'activation': 'tanh',\n",
    "                            'dropout_param': d}} for d in dropout_params]\n",
    "\n",
    "model_architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 65.65 minutes.\n",
      "Start time: 2021-02-13, 14:10:31\n",
      "End time: 2021-02-13, 15:16:11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(model_architectures),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for d in range(len(model_architectures)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architectures[d], num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout,\n",
    "                         weights_init = weights_init)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architectures[d]),\n",
    "            'num_hidden_neurons': [model_architectures[d][l]['neurons'] for l in model_architectures[d].keys()],\n",
    "            'hidden_activations': [model_architectures[d][l]['activation'] for l in model_architectures[d].keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architectures[d][l]['dropout_param'] for l in model_architectures[d].keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params,\n",
    "            'weights_init': weights_init\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Reviewing hidden dropout parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(d+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>hidden_dropout</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1613238130</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Reviewing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>[0.1]</td>\n",
       "      <td>0.852702</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.260801</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>184.156093</td>\n",
       "      <td>31.306822</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1613236231</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Reviewing...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.852324</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.261745</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>185.759093</td>\n",
       "      <td>31.329117</td>\n",
       "      <td>31.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "1    1613238130  J1 = (num_inputs + num_outputs)*0.1. Reviewing...   \n",
       "0    1613236231  J1 = (num_inputs + num_outputs)*0.1. Reviewing...   \n",
       "\n",
       "   num_layers num_neurons activation_function optimizer  learning_rate  \\\n",
       "1           1       [209]                tanh      adam          0.001   \n",
       "0           1       [209]                tanh      adam          0.001   \n",
       "\n",
       "   beta_1  beta_2    weights_init hidden_dropout  avg_roc_auc  std_roc_auc  \\\n",
       "1    0.75  0.9999  glorot_uniform          [0.1]     0.852702     0.004630   \n",
       "0    0.75  0.9999  glorot_uniform            [0]     0.852324     0.004588   \n",
       "\n",
       "   avg_prec  std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "1  0.260801  0.008330     184.156093   31.306822         34.00  \n",
       "0  0.261745  0.008355     185.759093   31.329117         31.65  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "activations = []\n",
    "optimizers = []\n",
    "hidden_dropouts = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over dropout parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Reviewing hidden dropout parameter.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    hidden_dropouts.append(e['hyper_parameters']['hidden_dropout'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by dropout parameter:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'weights_init': weights_inits,\n",
    "    'hidden_dropout': hidden_dropouts,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adam_params_review'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'One hidden layer: J1 = (num_inputs + num_outputs)*0.1.'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-5\n",
    "input_dropout = 0\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'learning_rate': [0.001],\n",
    "    'beta_1': [0.75, 0.5, 0.25],\n",
    "    'beta_2': [0.999, 0.9999],\n",
    "    'epsilon': [1e-07]\n",
    "}\n",
    "\n",
    "# List with all permutations of possible values for hyper-parameters:\n",
    "opt_params = permutation(opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 27.83 minutes.\n",
      "Start time: 2021-02-14, 14:22:26\n",
      "End time: 2021-02-14, 14:50:17\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(opt_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over optimizer parameters:\n",
    "for o in range(len(opt_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params[o],\n",
    "                         regularization = regularization, regul_param = regul_param,\n",
    "                         input_dropout = input_dropout,\n",
    "                         weights_init = weights_init)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_param,\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params[o],\n",
    "            'weights_init': weights_init\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0}. Reviewing Adam hyper-parameters.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(o+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1613317710</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.852777</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.261098</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>194.019065</td>\n",
       "      <td>32.626574</td>\n",
       "      <td>30.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1613314316</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.852422</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.278219</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>225.459120</td>\n",
       "      <td>36.844418</td>\n",
       "      <td>28.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1613319533</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.852271</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.277869</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>232.949790</td>\n",
       "      <td>33.620443</td>\n",
       "      <td>32.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1613312591</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.852164</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.261219</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>206.608472</td>\n",
       "      <td>36.159437</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1613323346</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.846702</td>\n",
       "      <td>0.004362</td>\n",
       "      <td>0.271481</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>194.128934</td>\n",
       "      <td>34.963586</td>\n",
       "      <td>27.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1613316034</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1.. Reviewin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.845258</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.270069</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>187.987971</td>\n",
       "      <td>31.489725</td>\n",
       "      <td>27.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "3    1613317710  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "1    1613314316  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "4    1613319533  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "0    1613312591  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "5    1613323346  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "2    1613316034  J1 = (num_inputs + num_outputs)*0.1.. Reviewin...   \n",
       "\n",
       "   num_layers num_neurons activation_function optimizer  learning_rate  \\\n",
       "3           1       [209]                tanh      adam          0.001   \n",
       "1           1       [209]                tanh      adam          0.001   \n",
       "4           1       [209]                tanh      adam          0.001   \n",
       "0           1       [209]                tanh      adam          0.001   \n",
       "5           1       [209]                tanh      adam          0.001   \n",
       "2           1       [209]                tanh      adam          0.001   \n",
       "\n",
       "   beta_1  beta_2    weights_init  avg_roc_auc  std_roc_auc  avg_prec  \\\n",
       "3    0.75  0.9999  glorot_uniform     0.852777     0.004395  0.261098   \n",
       "1    0.50  0.9990  glorot_uniform     0.852422     0.003781  0.278219   \n",
       "4    0.50  0.9999  glorot_uniform     0.852271     0.003659  0.277869   \n",
       "0    0.75  0.9990  glorot_uniform     0.852164     0.004125  0.261219   \n",
       "5    0.25  0.9999  glorot_uniform     0.846702     0.004362  0.271481   \n",
       "2    0.25  0.9990  glorot_uniform     0.845258     0.004496  0.270069   \n",
       "\n",
       "   std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "3  0.008003     194.019065   32.626574         30.37  \n",
       "1  0.007551     225.459120   36.844418         28.62  \n",
       "4  0.008265     232.949790   33.620443         32.45  \n",
       "0  0.007224     206.608472   36.159437         28.73  \n",
       "5  0.007765     194.128934   34.963586         27.83  \n",
       "2  0.008576     187.987971   31.489725         27.93  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "activations = []\n",
    "optimizers = []\n",
    "input_dropouts = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over optimizer parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Reviewing Adam hyper-parameters.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by Adam parameters:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta_1': beta1s,\n",
    "    'beta_2': beta2s,\n",
    "    'weights_init': weights_inits,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regul_param_grid_search'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous tests have been using a random sample with 50% of training data, which has accelerated the assessment of best choices for definitions and hyper-parameters such as: activation and cost functions, architecture (number of hidden layers and number of their neurons), fitting hyper-parameters (mini-batch size), dropout parameters (input and hidden), regularization parameter, optimizer parameters, and random distribution for weights initialization.\n",
    "<br>\n",
    "<br>\n",
    "Now, it is time to estimate fully connected feedforward neural networks using the entire training data. Besides, the regularization parameter will be defined from a grid search based on the evaluation of performance metrics on validation data. Lastly, a final model will be estimated making use of early stopping to determine the optimal number of epochs.\n",
    "<br>\n",
    "<br>\n",
    "The setting for estimation is given by definitions and values of hyper-parameters previously picked as the best choices.\n",
    "* Activation function for hidden neurons: tanh.\n",
    "* Cost function: cross-entropy.\n",
    "* Arquitecture: one hidden layer with the number of neurons given by: $J_1 = (num\\_inputs + num\\_outputs)*0.1$.\n",
    "* Mini-batch size: $S = 512$.\n",
    "* Number of epochs: $T = 10$, in order to simplify tests.\n",
    "* No early stopping so far.\n",
    "* Dropout parameters: $\\rho_{input} = \\rho_{hidden} = 0$.\n",
    "* L2 regularization parameter: defined through grid search, $\\lambda \\in [1e^{-8}, 1e^{-7}, 1e^{-6}, 1e^{-5}, 1e^{-4}, 0]$.\n",
    "* Optimizer: Adam.\n",
    "* Optimizer hyper-parameters: $\\eta = 0.001$, $\\beta_1 = 0.5$, $\\beta_2 = 0.9999$.\n",
    "* Random distribution for weights initialization: Glorot Uniform.\n",
    "<br>\n",
    "<br>\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data.\n",
    "* Averaging: a collection of 100 estimations will be implemented, so performance metrics can be assessed in terms of average and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'One hidden layer: J1 = (num_inputs + num_outputs)*0.1.'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "es_param = None\n",
    "regularization = 'l2'\n",
    "input_dropout = 0\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.5,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regul_params = [1e-08, 1e-07, 1e-06, 1e-05, 0.0001, 0]\n",
    "regul_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 70.4 minutes.\n",
      "Start time: 2021-02-16, 23:22:21\n",
      "End time: 2021-02-17, 00:32:45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "test_bar = progressbar.ProgressBar(maxval=len(regul_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "test_bar.start()\n",
    "\n",
    "# Loop over regularization parameters:\n",
    "for r in range(len(regul_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "\n",
    "    nn_start_time = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_min_cost = []\n",
    "    epoch_min_cost = []\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "\n",
    "    # Loop over estimations:\n",
    "    for t in range(n_estimations):\n",
    "        # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "        model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                         output_activation = output_activation, cost_function = cost_function,\n",
    "                         num_epochs = num_epochs, batch_size = batch_size,\n",
    "                         default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                         regularization = regularization, regul_param = regul_params[r],\n",
    "                         input_dropout = input_dropout,\n",
    "                         weights_init = weights_init)\n",
    "\n",
    "        # Training the model:\n",
    "        model.run(train_inputs = X_train, train_output = y_train,\n",
    "                  val_inputs = X_val, val_output = y_val,\n",
    "                  verbose = 0)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[0] for p in model.predictions]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[0] for p in model.predictions]))\n",
    "        \n",
    "        # Cost function by training epoch:\n",
    "        model_costs = model.model_costs\n",
    "        \n",
    "        min_cost.append(model_costs.loss.min())\n",
    "        epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "        val_min_cost.append(model_costs.val_loss.min())\n",
    "        epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "\n",
    "    # Assessing running time:\n",
    "    nn_end_time = datetime.now()\n",
    "\n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment[estimation_id] = {\n",
    "        'architecture': {\n",
    "            'num_hidden_layers': len(model_architecture),\n",
    "            'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "            'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "            'output_activation': output_activation,\n",
    "            'cost_function': cost_function,\n",
    "        },\n",
    "        'hyper_parameters': {\n",
    "            'num_epochs': num_epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'es_param': es_param,\n",
    "            'regularization': regularization,\n",
    "            'regul_param': regul_params[r],\n",
    "            'input_dropout': input_dropout,\n",
    "            'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "            'default_adam': default_adam,\n",
    "            'optimizer': optimizer,\n",
    "            'opt_params': opt_params,\n",
    "            'weights_init': weights_init\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_min_cost': np.nanmean(min_cost),\n",
    "            'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": '{0} Grid search for L2 regularization parameter.'.format(model_architecture_def)\n",
    "    }\n",
    "    \n",
    "    if export:\n",
    "        with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "            json.dump(model_assessment, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(r+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>weights_init</th>\n",
       "      <th>regul_param</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1613507413</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Grid sear...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>0.937422</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>0.453413</td>\n",
       "      <td>0.006286</td>\n",
       "      <td>589.276382</td>\n",
       "      <td>72.132531</td>\n",
       "      <td>67.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1613473761</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Grid sear...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.937020</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.453680</td>\n",
       "      <td>0.006390</td>\n",
       "      <td>667.111547</td>\n",
       "      <td>71.003575</td>\n",
       "      <td>80.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1613432541</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Grid sear...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>0.936917</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.453971</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>604.356581</td>\n",
       "      <td>98.199658</td>\n",
       "      <td>81.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1613515311</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Grid sear...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>0.936823</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.427436</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>729.222978</td>\n",
       "      <td>43.397373</td>\n",
       "      <td>64.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1613441057</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Grid sear...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>0.936790</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.453518</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>668.135151</td>\n",
       "      <td>94.443130</td>\n",
       "      <td>64.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1613528541</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Grid sear...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>glorot_uniform</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.936585</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.453855</td>\n",
       "      <td>0.004928</td>\n",
       "      <td>586.873050</td>\n",
       "      <td>92.094651</td>\n",
       "      <td>70.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "3    1613507413  J1 = (num_inputs + num_outputs)*0.1. Grid sear...   \n",
       "2    1613473761  J1 = (num_inputs + num_outputs)*0.1. Grid sear...   \n",
       "0    1613432541  J1 = (num_inputs + num_outputs)*0.1. Grid sear...   \n",
       "4    1613515311  J1 = (num_inputs + num_outputs)*0.1. Grid sear...   \n",
       "1    1613441057  J1 = (num_inputs + num_outputs)*0.1. Grid sear...   \n",
       "5    1613528541  J1 = (num_inputs + num_outputs)*0.1. Grid sear...   \n",
       "\n",
       "   num_layers num_neurons activation_function    weights_init   regul_param  \\\n",
       "3           1       [209]                tanh  glorot_uniform  1.000000e-05   \n",
       "2           1       [209]                tanh  glorot_uniform  1.000000e-06   \n",
       "0           1       [209]                tanh  glorot_uniform  1.000000e-08   \n",
       "4           1       [209]                tanh  glorot_uniform  1.000000e-04   \n",
       "1           1       [209]                tanh  glorot_uniform  1.000000e-07   \n",
       "5           1       [209]                tanh  glorot_uniform  0.000000e+00   \n",
       "\n",
       "   avg_roc_auc  std_roc_auc  avg_prec  std_prec  ratio_roc_auc  ratio_prec  \\\n",
       "3     0.937422     0.001591  0.453413  0.006286     589.276382   72.132531   \n",
       "2     0.937020     0.001405  0.453680  0.006390     667.111547   71.003575   \n",
       "0     0.936917     0.001550  0.453971  0.004623     604.356581   98.199658   \n",
       "4     0.936823     0.001285  0.427436  0.009849     729.222978   43.397373   \n",
       "1     0.936790     0.001402  0.453518  0.004802     668.135151   94.443130   \n",
       "5     0.936585     0.001596  0.453855  0.004928     586.873050   92.094651   \n",
       "\n",
       "   running_time  \n",
       "3         67.57  \n",
       "2         80.87  \n",
       "0         81.55  \n",
       "4         64.23  \n",
       "1         64.45  \n",
       "5         70.40  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "activations = []\n",
    "regul_params = []\n",
    "weights_inits = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over regularization parameters:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Grid search for L2 regularization parameter.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    regul_params.append(e['hyper_parameters']['regul_param'])\n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/e['performance_metrics']['std_roc_auc'])\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/e['performance_metrics']['std_avg_prec_score'])\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by regularization parameter:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'activation_function': activations,\n",
    "    'weights_init': weights_inits,\n",
    "    'regul_param': regul_params,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='final_estimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final estimation with early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last hyper-parameter that needs to be specified is the number of epochs, $T$. As introducted earlier, the strategy here is to estimate the model using training data and then to monitor performance metrics using validation data. When the validation performance decreases ($\\delta = 0$) after $P^*$ consecutive epochs, the model stops training. The ensemble of models to be saved can be either those that have maximized the validation performance at each iteration or the last updated model at each iteration.\n",
    "<br>\n",
    "<br>\n",
    "In a first moment, a sensitivity analysis will occur in order to define the patiencie parameter, i.e., the early stopping parameter $P^*$. Then, the final estimation will take place leading to an ensemble of models that constitute the reference for the current dataset of the fully connected feedforward neural network paradigm.\n",
    "<br>\n",
    "<br>\n",
    "The setting for estimation is given by definitions and values of hyper-parameters previously picked as the best choices.\n",
    "* Activation function for hidden neurons: tanh.\n",
    "* Cost function: cross-entropy.\n",
    "* Arquitecture: one hidden layer with the number of neurons given by: $J_1 = (num\\_inputs + num\\_outputs)*0.1$.\n",
    "* Mini-batch size: $S = 512$.\n",
    "* Number of epoch defined through early stopping with $(\\delta, P^*) = (0, P^*)$.\n",
    "* Dropout parameters: $\\rho_{input} = \\rho_{hidden} = 0$.\n",
    "* L2 regularization parameter: $\\lambda = 1e^{-6}$.\n",
    "* Optimizer: Adam.\n",
    "* Optimizer hyper-parameters: $\\eta = 0.001$, $\\beta_1 = 0.5$, $\\beta_2 = 0.9999$.\n",
    "* Random distribution for weights initialization: Glorot Uniform.\n",
    "<br>\n",
    "<br>\n",
    "* Conclusions will be guided by performance metrics evaluated on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values\n",
    "\n",
    "X_test = df_test_scaled.drop(drop_vars, axis=1).values\n",
    "y_test = df_test_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Model architecture:\n",
    "model_architecture = {1: {'neurons': int(np.floor((X_train.shape[1] + 1)*0.1)),\n",
    "                          'activation': 'tanh',\n",
    "                          'dropout_param': 0.1}}\n",
    "model_architecture_def = 'One hidden layer: J1 = (num_inputs + num_outputs)*0.1.'\n",
    "\n",
    "# Functions:\n",
    "output_activation = 'sigmoid'\n",
    "cost_function = 'binary_crossentropy'\n",
    "\n",
    "# Hyper-parameters:\n",
    "num_epochs = 200\n",
    "batch_size = 512\n",
    "es_param = {'min_delta': 0, 'patience': 40, 'consecutive_patience': False}\n",
    "regularization = 'l2'\n",
    "regul_param = 1e-06\n",
    "input_dropout = 0\n",
    "weights_init = 'glorot_uniform'\n",
    "\n",
    "# Defining the optimizer:\n",
    "default_adam = False\n",
    "optimizer = 'adam'\n",
    "opt_params = {\n",
    "    'learning_rate': 0.001,\n",
    "    'beta_1': 0.5,\n",
    "    'beta_2': 0.9999,\n",
    "    'epsilon': 1e-07\n",
    "}\n",
    "\n",
    "# Declare whether to export models:\n",
    "export_model = False\n",
    "\n",
    "# Declare whether the best model (True) or the last model (False) should be exported:\n",
    "export_best_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early stoppping estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "if export_model:\n",
    "    os.makedirs('Models/{0}'.format(estimation_id))\n",
    "\n",
    "nn_start_time = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "min_cost = []\n",
    "epoch_min_cost = []\n",
    "val_min_cost = []\n",
    "val_epoch_min_cost = []\n",
    "effective_num_epochs = []\n",
    "test_roc_auc = []\n",
    "test_avg_prec_score = []\n",
    "test_brier_score = []\n",
    "\n",
    "for t in range(n_estimations):\n",
    "    # Creating neural network object, declaring its architecture and defining hyper-parameters:\n",
    "    model = KerasNN(model_architecture = model_architecture, num_inputs = X_train.shape[1],\n",
    "                     output_activation = output_activation, cost_function = cost_function,\n",
    "                     num_epochs = num_epochs, batch_size = batch_size,\n",
    "                     default_adam = default_adam, optimizer = optimizer, opt_params = opt_params,\n",
    "                     regularization = regularization, regul_param = regul_param,\n",
    "                     input_dropout = input_dropout,\n",
    "                     weights_init = weights_init)\n",
    "\n",
    "    # Training the model:\n",
    "    model.run(train_inputs = X_train, train_output = y_train,\n",
    "              val_inputs = X_val, val_output = y_val,\n",
    "              test_inputs = X_test, test_output = y_test,\n",
    "              verbose = 0, early_stopping = True, es_params = es_param, save_best_model = export_best_model)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    test_roc_auc.append(roc_auc_score(y_test, [p[0] for p in model.predictions['test']]))\n",
    "    test_avg_prec_score.append(average_precision_score(y_test, [p[0] for p in model.predictions['test']]))\n",
    "    test_brier_score.append(brier_score_loss(y_test, [p[0] for p in model.predictions['test']]))\n",
    "\n",
    "    # Effective number of epochs:\n",
    "    effective_num_epochs.append(len(model.epoch_performance['epoch_val_roc_auc']))\n",
    "\n",
    "    # Cost function by training epoch:\n",
    "    model_costs = model.model_costs\n",
    "\n",
    "    min_cost.append(model_costs.loss.min())\n",
    "    epoch_min_cost.append(model_costs.loss.idxmin() + 1)\n",
    "    val_min_cost.append(model_costs.val_loss.min())\n",
    "    val_epoch_min_cost.append(model_costs.val_loss.idxmin() + 1)\n",
    "    \n",
    "    # Exporting the model:\n",
    "    if export_model:\n",
    "        if export_best_model:\n",
    "            model.best_model.save('Models/{0}/best_model_{1}.h5'.format(estimation_id, t+1))\n",
    "        else:\n",
    "            model.model.save('Models/{0}/model_{1}.h5'.format(estimation_id, t+1))\n",
    "\n",
    "# Assessing running time:\n",
    "nn_end_time = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment[estimation_id] = {\n",
    "    'architecture': {\n",
    "        'num_hidden_layers': len(model_architecture),\n",
    "        'num_hidden_neurons': [model_architecture[l]['neurons'] for l in model_architecture.keys()],\n",
    "        'hidden_activations': [model_architecture[l]['activation'] for l in model_architecture.keys()],\n",
    "        'output_activation': output_activation,\n",
    "        'cost_function': cost_function,\n",
    "    },\n",
    "    'hyper_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'avg_effective_num_epochs': np.nanmean(effective_num_epochs),\n",
    "        'batch_size': batch_size,\n",
    "        'es_param': es_param,\n",
    "        'regularization': regularization,\n",
    "        'regul_param': regul_param,\n",
    "        'input_dropout': input_dropout,\n",
    "        'hidden_dropout': [model_architecture[l]['dropout_param'] for l in model_architecture.keys()],\n",
    "        'default_adam': default_adam,\n",
    "        'optimizer': optimizer,\n",
    "        'opt_params': opt_params,\n",
    "        'weights_init': weights_init,\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'test',\n",
    "        'avg_min_cost': np.nanmean(min_cost),\n",
    "        'avg_epoch_min_cost': np.nanmean(epoch_min_cost),\n",
    "        'avg_min_val_cost': np.nanmean(val_min_cost),\n",
    "        'avg_epoch_min_val_cost': np.nanmean(val_epoch_min_cost),\n",
    "        'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(val_brier_score),\n",
    "        'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(val_brier_score)\n",
    "    },\n",
    "    'running_time': str(round(((nn_end_time - nn_start_time).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": '{0} Final estimation.'.format(model_architecture_def)\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment.json', 'w') as json_file:\n",
    "        json.dump(model_assessment, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>architecture</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_neurons</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>effective_num_epochs</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>regularization</th>\n",
       "      <th>regul_param</th>\n",
       "      <th>input_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>min_delta</th>\n",
       "      <th>patience</th>\n",
       "      <th>consecutive_patience</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1615054094</td>\n",
       "      <td>J1 = (num_inputs + num_outputs)*0.1. Final est...</td>\n",
       "      <td>1</td>\n",
       "      <td>[209]</td>\n",
       "      <td>512</td>\n",
       "      <td>89.0725</td>\n",
       "      <td>tanh</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0.938703</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.457992</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>301.538196</td>\n",
       "      <td>34.959909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  estimation_id                                       architecture  \\\n",
       "0    1615054094  J1 = (num_inputs + num_outputs)*0.1. Final est...   \n",
       "\n",
       "   num_layers num_neurons  batch_size  effective_num_epochs  \\\n",
       "0           1       [209]         512               89.0725   \n",
       "\n",
       "  activation_function regularization  regul_param  input_dropout  ...  \\\n",
       "0                tanh             l2     0.000001              0  ...   \n",
       "\n",
       "  min_delta patience consecutive_patience  avg_roc_auc  std_roc_auc  avg_prec  \\\n",
       "0         0       40                False     0.938703     0.003113  0.457992   \n",
       "\n",
       "   std_prec  ratio_roc_auc  ratio_prec  running_time  \n",
       "0    0.0131     301.538196   34.959909           NaN  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "archs = []\n",
    "num_layers = []\n",
    "num_neurons = []\n",
    "batch_sizes = []\n",
    "effective_num_epochs = []\n",
    "activations = []\n",
    "regularizations = []\n",
    "regul_params = []\n",
    "input_dropouts = []\n",
    "hidden_dropouts = []\n",
    "weights_inits = []\n",
    "optimizers = []\n",
    "learning_rates = []\n",
    "beta1s = []\n",
    "beta2s = []\n",
    "min_deltas = []\n",
    "patiences = []\n",
    "consecutive_patiences = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for e in [model_assessment[e] for e in model_assessment.keys() if\n",
    "          ('Final estimation.' in model_assessment[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment.keys())[list(model_assessment.values()).index(e)])\n",
    "    archs.append(e['comment'].split(': ')[1])\n",
    "    num_layers.append(e['architecture']['num_hidden_layers'])\n",
    "    num_neurons.append(e['architecture']['num_hidden_neurons'])\n",
    "    batch_sizes.append(e['hyper_parameters']['batch_size'])\n",
    "    effective_num_epochs.append(e['hyper_parameters']['avg_effective_num_epochs'])\n",
    "    \n",
    "    activations.append(np.unique(e['architecture']['hidden_activations'])[0])\n",
    "    \n",
    "    regularizations.append(e['hyper_parameters']['regularization'])\n",
    "    regul_params.append(e['hyper_parameters']['regul_param'])\n",
    "    input_dropouts.append(e['hyper_parameters']['input_dropout'])\n",
    "    hidden_dropouts.append(e['hyper_parameters']['hidden_dropout'])\n",
    "    \n",
    "    weights_inits.append(e['hyper_parameters']['weights_init'])\n",
    "    \n",
    "    optimizers.append(e['hyper_parameters']['optimizer'])\n",
    "    learning_rates.append(e['hyper_parameters']['opt_params']['learning_rate'])\n",
    "    beta1s.append(e['hyper_parameters']['opt_params']['beta_1'])\n",
    "    beta2s.append(e['hyper_parameters']['opt_params']['beta_2'])\n",
    "    \n",
    "    min_deltas.append(e['hyper_parameters']['es_param']['min_delta'])\n",
    "    patiences.append(e['hyper_parameters']['es_param']['patience'])\n",
    "    consecutive_patiences.append(e['hyper_parameters']['es_param']['consecutive_patience'])\n",
    "\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/(e['performance_metrics']['std_roc_auc'] + 1e-7))\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/(e['performance_metrics']['std_avg_prec_score'] + 1e-7))\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by estimation:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'architecture': archs,\n",
    "    'num_layers': num_layers,\n",
    "    'num_neurons': num_neurons,\n",
    "    'batch_size': batch_sizes,\n",
    "    'effective_num_epochs': effective_num_epochs,\n",
    "    'activation_function': activations,\n",
    "    'regularization': regularizations,\n",
    "    'regul_param': regul_params,\n",
    "    'input_dropout': input_dropouts,\n",
    "    'hidden_dropout': hidden_dropouts,\n",
    "    'weights_init': weights_inits,\n",
    "    'optimizer': optimizers,\n",
    "    'learning_rate': learning_rates,\n",
    "    'beta1': beta1s,\n",
    "    'beta2': beta2s,\n",
    "    'min_delta': min_deltas,\n",
    "    'patience': patiences,\n",
    "    'consecutive_patience': consecutive_patiences,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance metrics by epoch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>",
         "name": "Val ROC-AUC",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "xaxis": "x",
         "y": [
          0.9196308878709735,
          0.9246715414844362,
          0.9324360118534003,
          0.9352444394041743,
          0.9362106591851527,
          0.9355194737957999,
          0.9366864716410845,
          0.935237141969617,
          0.9370614019949608,
          0.9342460714655517,
          0.9374849490412254,
          0.9320762680525218,
          0.9335040998762396,
          0.933297404973103,
          0.9302840575708418,
          0.9298978852231881,
          0.9309777083097072,
          0.9319050741823668,
          0.9305050515011513,
          0.9286845388070666,
          0.9301386019495985,
          0.9321819822396221,
          0.9301090177554471,
          0.9339407625819112,
          0.9317144533580525,
          0.9321775446104994,
          0.9313162501047774,
          0.9357811953000577,
          0.9330888364043369,
          0.9351297513448482,
          0.936268644205689,
          0.9354575442160434,
          0.9357409607960121,
          0.9368038222778843,
          0.9352251110639956,
          0.9364980203243414,
          0.9371600159754648,
          0.9365365783907185,
          0.9379571127798788,
          0.9375099969922737,
          0.9380507960613576,
          0.9367069833490294,
          0.9377603778887734,
          0.9376169931611205,
          0.9386657528437807,
          0.9387012538767621,
          0.9391900833781205,
          0.9397581985198041,
          0.9389361523783227,
          0.9383196177722116,
          0.9384854864874194,
          0.9383296763982231,
          0.9396300989591295,
          0.9389087376917425,
          0.9398320603912016,
          0.9385551079576551,
          0.9391326900414672,
          0.9396437076884389,
          0.939057348960362,
          0.9393892836187386,
          0.9392052699311181,
          0.9398376813880903,
          0.9396169832997223,
          0.9399946748450527,
          0.9396837449645234,
          0.9395805947409164,
          0.9400217936896914,
          0.9399856023588462,
          0.9404673316536086,
          0.9402794720207485,
          0.9401888457726654,
          0.9400689311723722,
          0.940305013041699,
          0.9406182110437797,
          0.940478376419425,
          0.9405184136955095,
          0.9402729634980351,
          0.940243773759806,
          0.9401274092628111,
          0.9398760422265064,
          0.9403136910719833,
          0.9403411057585632,
          0.9404228567484013,
          0.9402193174926409,
          0.940514370522309,
          0.9401228730197081,
          0.9402170493710894,
          0.9404092480190916,
          0.9403911030466789
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Avg precision = %{y:.4f}<br>epoch = %{x}<br>",
         "marker": {
          "color": "orange"
         },
         "mode": "lines",
         "name": "Val avg precision",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89
         ],
         "xaxis": "x",
         "y": [
          0.31678519929105836,
          0.3287129156711249,
          0.3776446095271452,
          0.4092259477027384,
          0.4121848462962114,
          0.42928544342720626,
          0.44155631344860097,
          0.43572067471930326,
          0.4551081578599097,
          0.43910884646783377,
          0.44650528153215396,
          0.4339272429575411,
          0.43578548315536525,
          0.43557113100877537,
          0.4218465563599119,
          0.4276810178424434,
          0.4333483275133479,
          0.4274983138453451,
          0.4338256219580825,
          0.4228420029311759,
          0.4236383291965411,
          0.43399242108125496,
          0.4255337168349513,
          0.43614717492502325,
          0.4286611000494724,
          0.43306545246156053,
          0.42938824773324497,
          0.4459162779062809,
          0.42820940601030455,
          0.44449449351471015,
          0.4547375502473885,
          0.4525495562614221,
          0.455690947858853,
          0.45613511155854336,
          0.4496405461979137,
          0.45491919973058903,
          0.4604606240694894,
          0.4531722672039877,
          0.45616696092013714,
          0.4588673984992509,
          0.4608755441681302,
          0.4574648258207521,
          0.4635860808588068,
          0.4579772675977681,
          0.46589813720740386,
          0.46313484862255244,
          0.4644260169044375,
          0.46721203387713595,
          0.46056120988138194,
          0.46341131503539124,
          0.46464780979018594,
          0.46277338925865125,
          0.4680370773636827,
          0.46356087797206985,
          0.46686775786481016,
          0.4651374296850444,
          0.46498768361515846,
          0.46548451113401607,
          0.46428828563342595,
          0.4660096843258979,
          0.4667475439557391,
          0.46742099452943286,
          0.4679296294328571,
          0.46360208717400686,
          0.46642374070263226,
          0.4628955864367155,
          0.463201136350993,
          0.4635742119583707,
          0.46904385878793015,
          0.47051468235532473,
          0.46671684569622496,
          0.4679280583450772,
          0.46795984334053653,
          0.4670390433307337,
          0.4669112848469886,
          0.46750905438737483,
          0.46864225545577337,
          0.46855706548827275,
          0.46918662065647676,
          0.4666535846930752,
          0.46646476689785915,
          0.4685478229968758,
          0.4670116369700551,
          0.46840081580414855,
          0.4708058671063503,
          0.4668116776191791,
          0.4684237352753347,
          0.46970994652500825,
          0.4689237601750256
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Validation performance by epoch of training<br>Effective number of epochs = 89"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "performance"
         }
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"4910b2a6-9c53-4744-a0f4-c96424f7cc1b\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"4910b2a6-9c53-4744-a0f4-c96424f7cc1b\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '4910b2a6-9c53-4744-a0f4-c96424f7cc1b',\n",
       "                        [{\"hovertemplate\": \"ROC-AUC = %{y:.4f}<br>epoch = %{x}<br>\", \"name\": \"Val ROC-AUC\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"xaxis\": \"x\", \"y\": [0.9196308878709735, 0.9246715414844362, 0.9324360118534003, 0.9352444394041743, 0.9362106591851527, 0.9355194737957999, 0.9366864716410845, 0.935237141969617, 0.9370614019949608, 0.9342460714655517, 0.9374849490412254, 0.9320762680525218, 0.9335040998762396, 0.933297404973103, 0.9302840575708418, 0.9298978852231881, 0.9309777083097072, 0.9319050741823668, 0.9305050515011513, 0.9286845388070666, 0.9301386019495985, 0.9321819822396221, 0.9301090177554471, 0.9339407625819112, 0.9317144533580525, 0.9321775446104994, 0.9313162501047774, 0.9357811953000577, 0.9330888364043369, 0.9351297513448482, 0.936268644205689, 0.9354575442160434, 0.9357409607960121, 0.9368038222778843, 0.9352251110639956, 0.9364980203243414, 0.9371600159754648, 0.9365365783907185, 0.9379571127798788, 0.9375099969922737, 0.9380507960613576, 0.9367069833490294, 0.9377603778887734, 0.9376169931611205, 0.9386657528437807, 0.9387012538767621, 0.9391900833781205, 0.9397581985198041, 0.9389361523783227, 0.9383196177722116, 0.9384854864874194, 0.9383296763982231, 0.9396300989591295, 0.9389087376917425, 0.9398320603912016, 0.9385551079576551, 0.9391326900414672, 0.9396437076884389, 0.939057348960362, 0.9393892836187386, 0.9392052699311181, 0.9398376813880903, 0.9396169832997223, 0.9399946748450527, 0.9396837449645234, 0.9395805947409164, 0.9400217936896914, 0.9399856023588462, 0.9404673316536086, 0.9402794720207485, 0.9401888457726654, 0.9400689311723722, 0.940305013041699, 0.9406182110437797, 0.940478376419425, 0.9405184136955095, 0.9402729634980351, 0.940243773759806, 0.9401274092628111, 0.9398760422265064, 0.9403136910719833, 0.9403411057585632, 0.9404228567484013, 0.9402193174926409, 0.940514370522309, 0.9401228730197081, 0.9402170493710894, 0.9404092480190916, 0.9403911030466789], \"yaxis\": \"y\"}, {\"hovertemplate\": \"Avg precision = %{y:.4f}<br>epoch = %{x}<br>\", \"marker\": {\"color\": \"orange\"}, \"mode\": \"lines\", \"name\": \"Val avg precision\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89], \"xaxis\": \"x\", \"y\": [0.31678519929105836, 0.3287129156711249, 0.3776446095271452, 0.4092259477027384, 0.4121848462962114, 0.42928544342720626, 0.44155631344860097, 0.43572067471930326, 0.4551081578599097, 0.43910884646783377, 0.44650528153215396, 0.4339272429575411, 0.43578548315536525, 0.43557113100877537, 0.4218465563599119, 0.4276810178424434, 0.4333483275133479, 0.4274983138453451, 0.4338256219580825, 0.4228420029311759, 0.4236383291965411, 0.43399242108125496, 0.4255337168349513, 0.43614717492502325, 0.4286611000494724, 0.43306545246156053, 0.42938824773324497, 0.4459162779062809, 0.42820940601030455, 0.44449449351471015, 0.4547375502473885, 0.4525495562614221, 0.455690947858853, 0.45613511155854336, 0.4496405461979137, 0.45491919973058903, 0.4604606240694894, 0.4531722672039877, 0.45616696092013714, 0.4588673984992509, 0.4608755441681302, 0.4574648258207521, 0.4635860808588068, 0.4579772675977681, 0.46589813720740386, 0.46313484862255244, 0.4644260169044375, 0.46721203387713595, 0.46056120988138194, 0.46341131503539124, 0.46464780979018594, 0.46277338925865125, 0.4680370773636827, 0.46356087797206985, 0.46686775786481016, 0.4651374296850444, 0.46498768361515846, 0.46548451113401607, 0.46428828563342595, 0.4660096843258979, 0.4667475439557391, 0.46742099452943286, 0.4679296294328571, 0.46360208717400686, 0.46642374070263226, 0.4628955864367155, 0.463201136350993, 0.4635742119583707, 0.46904385878793015, 0.47051468235532473, 0.46671684569622496, 0.4679280583450772, 0.46795984334053653, 0.4670390433307337, 0.4669112848469886, 0.46750905438737483, 0.46864225545577337, 0.46855706548827275, 0.46918662065647676, 0.4666535846930752, 0.46646476689785915, 0.4685478229968758, 0.4670116369700551, 0.46840081580414855, 0.4708058671063503, 0.4668116776191791, 0.4684237352753347, 0.46970994652500825, 0.4689237601750256], \"yaxis\": \"y2\"}],\n",
       "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Validation performance by epoch of training<br>Effective number of epochs = 89\"}, \"width\": 700, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.94], \"title\": {\"text\": \"epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"performance\"}}, \"yaxis2\": {\"anchor\": \"x\", \"overlaying\": \"y\", \"side\": \"right\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4910b2a6-9c53-4744-a0f4-c96424f7cc1b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure:\n",
    "fig = make_subplots(specs=[[{'secondary_y': True}]])\n",
    "\n",
    "# Create the plot (first axis):\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i+1 for i in range(len(model.epoch_performance['epoch_val_roc_auc']))],\n",
    "               y=model.epoch_performance['epoch_val_roc_auc'], name='Val ROC-AUC',\n",
    "               hovertemplate =\n",
    "                'ROC-AUC = %{y:.4f}<br>'+\n",
    "                'epoch = %{x}<br>'\n",
    "              ),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=[i+1 for i in range(len(model.epoch_performance['epoch_val_avg_prec_score']))],\n",
    "               y=model.epoch_performance['epoch_val_avg_prec_score'], name='Val avg precision',\n",
    "               hovertemplate = 'Avg precision = %{y:.4f}<br>'+\n",
    "                               'epoch = %{x}<br>',\n",
    "               marker_color='orange',\n",
    "               mode='lines'\n",
    "              ),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Changing layout:\n",
    "fig.update_layout(\n",
    "    title_text='Validation performance by epoch of training<br>' +\n",
    "#                'Patience parameter = {0}<br>'.format(es_param['patience']) +\n",
    "               'Effective number of epochs = {0}'.format(int(effective_num_epochs[-1])),\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Set labels:\n",
    "fig.update_xaxes(title_text='epoch')\n",
    "fig.update_yaxes(title_text='performance', secondary_y=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
