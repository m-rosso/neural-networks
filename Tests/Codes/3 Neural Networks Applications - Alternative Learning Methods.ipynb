{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks applications to fraud detection\n",
    "## Alternative learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are one of the most relevant learning methods currently available, and their widespread application is understood by theoretical robustness, flexible architecture design, and strong expected predictive accuracy.\n",
    "<br>\n",
    "<br>\n",
    "The main objective of this study is to develop a neural network application to fraud detection, and mainly to construct and implement a strategy for hyper-parameter tuning, since this learning method requires a proper definition of a large set of parameters in order to result in a competitive performance.\n",
    "<br>\n",
    "<br>\n",
    "Previously to empirical inquirements, it is necessary to review all details concerning neural networks structure, fitting, and specification, which will base experiments design and tests implementation. So, the theoretical presentation of this notebook will be followed by an empirical stage of tests in which hyper-parameters will be defined to improve neural networks predictive accuracy, after which the best specification obtained should be opposed to alternative learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After discussion and empirical application of neural network models, this notebook estimates additional models based on alternative learning methods (logistic regression, SVM and GBM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "1. [Libraries](#libraries)<a href='#libraries'></a>.\n",
    "2. [Functions and classes](#functions_classes)<a href='#functions_classes'></a>.\n",
    "3. [Settings](#settings)<a href='#settings'></a>.\n",
    "4. [Importing data](#imports)<a href='#imports'></a>.\n",
    "    * [Categorical features](#categorical_features)<a href='#categorical_features'></a>.\n",
    "    * [Model assessment](#model_assessment)<a href='#model_assessment'></a>.\n",
    "    * [Classifying features](#classif_feat)<a href='#classif_feat'></a>.\n",
    "<br>\n",
    "<br>\n",
    "5. [Data pre-processing](#data_pre_proc)<a href='#data_pre_proc'></a>.\n",
    "    * [Assessing missing values](#assessing_missing)<a href='#assessing_missing'></a>.\n",
    "    * [Transforming numerical features](#num_transf)<a href='#num_transf'></a>.\n",
    "    * [Transforming categorical features](#categorical_transf)<a href='#categorical_transf'></a>.\n",
    "    * [Datasets structure](#datasets_structure)<a href='#datasets_structure'></a>.\n",
    "<br>\n",
    "<br>\n",
    "6. [Logistic regression estimation](#logistic_regression)<a href='#logistic_regression'></a>.\n",
    "    * [Hyper-parameters definition](#lr_params)<a href='#lr_params'></a>.\n",
    "    * [Final estimation](#lr_estimation)<a href='#lr_estimation'></a>.\n",
    "<br>\n",
    "<br>\n",
    "7. [SVM estimation](#svm)<a href='#svm'></a>.\n",
    "    * [Hyper-parameters definition](#svm_params)<a href='#svm_params'></a>.\n",
    "    * [Final estimation](#svm_estimation)<a href='#svm_estimation'></a>.\n",
    "<br>\n",
    "<br>\n",
    "8. [GBM estimation](#gbm)<a href='#gbm'></a>.\n",
    "    * [Hyper-parameters definition](#gbm_params)<a href='#gbm_params'></a>.\n",
    "    * [Final estimation](#gbm_estimation)<a href='#gbm_estimation'></a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import progressbar\n",
    "from time import sleep\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LeakyReLU, PReLU\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
    "from tensorflow.nn import leaky_relu\n",
    "from tensorflow.keras.activations import swish\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from scipy.stats import uniform, norm, randint\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, auc, precision_recall_curve, brier_score_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# print(__version__) # requires version >= 1.9.0\n",
    "\n",
    "import cufflinks as cf\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functions_classes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import epoch_to_date, text_clean, is_velocity, balanced_sample, get_cat, permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformations import log_transformation, standard_scale, recreate_missings, impute_missing\n",
    "from transformations import one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nn\n",
    "from keras_nn import keras_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='settings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare whether to export results:\n",
    "export = True\n",
    "\n",
    "# Define a dataset id:\n",
    "s = 6044\n",
    "\n",
    "# Declare whether to apply logarithmic transformation over numerical data:\n",
    "log_transform = True\n",
    "\n",
    "# Declare whether to standardize numerical data:\n",
    "standardize = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train for store 6044:\u001b[0m (35897, 2173).\n",
      "\u001b[1mShape of df_val for store 6044:\u001b[0m (20940, 2173).\n",
      "\u001b[1mShape of df_test for store 6044:\u001b[0m (21791, 2173).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>ZIPFIRST3REPUTATION()</th>\n",
       "      <th>ZIPFIRST5REPUTATION()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>D48D0720681E4F5D9A2767F7174B5FA6-2782006</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.96</td>\n",
       "      <td>A0EB579C0AE0452D9020C91C54565B4F-2782009</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.72</td>\n",
       "      <td>17A1DF0F984E4B34AC512D7E9E23B7BB-2782011</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 2173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           0.0                         0.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "\n",
       "   ZIPFIRST3REPUTATION()  ZIPFIRST5REPUTATION()    y  order_amount  \\\n",
       "0               0.000000                    0.0  0.0        156.75   \n",
       "1               0.000992                    0.0  0.0         67.96   \n",
       "2               0.003344                    0.0  0.0        315.72   \n",
       "\n",
       "                                   order_id    status         epoch  store_id  \\\n",
       "0  D48D0720681E4F5D9A2767F7174B5FA6-2782006  APPROVED  1.577751e+12      6044   \n",
       "1  A0EB579C0AE0452D9020C91C54565B4F-2782009  APPROVED  1.577751e+12      6044   \n",
       "2  17A1DF0F984E4B34AC512D7E9E23B7BB-2782011  APPROVED  1.577751e+12      6044   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2019-12-30  \n",
       "1     1.0 2019-12-30  \n",
       "2     1.0 2019-12-30  \n",
       "\n",
       "[3 rows x 2173 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data:\n",
    "os.chdir('/home/matheus_rosso/Arquivo/Features/Datasets/')\n",
    "\n",
    "df_train = pd.read_csv('new_additional_datasets/dataset_' + str(s) + '.csv',\n",
    "                       dtype={'order_id': str, 'store_id': int})\n",
    "df_train.drop_duplicates(['order_id', 'epoch', 'order_amount'], inplace=True)\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_train['date'] = df_train.epoch.apply(epoch_to_date)\n",
    "\n",
    "# Dropping original categorical features:\n",
    "cat_vars = get_cat(df_train)\n",
    "c_vars = [c for c in list(df_train.columns) if 'C#' in c]\n",
    "na_vars = ['NA#' + c for c in cat_vars if 'NA#' + c in list(df_train.columns)]\n",
    "\n",
    "df_train = df_train.drop(c_vars, axis=1).drop(na_vars, axis=1)\n",
    "\n",
    "# Splitting data into train and test:\n",
    "df_test = df_train[(df_train.date > datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "df_train = df_train[(df_train.date <= datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "\n",
    "# Splitting data into validation and test:\n",
    "df_val = df_test[df_test.date < datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "df_test = df_test[df_test.date >= datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "\n",
    "print('\\033[1mShape of df_train for store ' + str(s) + ':\\033[0m ' + str(df_train.shape) + '.')\n",
    "print('\\033[1mShape of df_val for store ' + str(s) + ':\\033[0m ' + str(df_val.shape) + '.')\n",
    "print('\\033[1mShape of df_test for store ' + str(s) + ':\\033[0m ' + str(df_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "# Accessory variables:\n",
    "drop_vars = ['y', 'order_amount', 'store_id', 'order_id', 'status', 'epoch', 'date', 'weight']\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values:\n",
    "num_miss_train = df_train.isnull().sum().sum()\n",
    "num_miss_val = df_val.isnull().sum().sum()\n",
    "num_miss_test = df_test.isnull().sum().sum()\n",
    "\n",
    "if num_miss_train > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "if num_miss_val > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (validation data):\\033[0m ' +\n",
    "          str(df_val.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "    \n",
    "if num_miss_test > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_features'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of categorical_train (training data):\u001b[0m (35897, 22).\n",
      "\u001b[1mNumber of orders (training data):\u001b[0m 35897.\n",
      "\n",
      "\n",
      "\u001b[1mShape of categorical_val (validation data):\u001b[0m (20940, 22).\n",
      "\u001b[1mNumber of orders (validation data):\u001b[0m 20940.\n",
      "\n",
      "\n",
      "\u001b[1mShape of categorical_test (test data):\u001b[0m (21791, 22).\n",
      "\u001b[1mNumber of orders (test data):\u001b[0m 21791.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGSTATE()</th>\n",
       "      <th>BROWSER()</th>\n",
       "      <th>CREDITCARDBRAND()</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>...</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VISA</td>\n",
       "      <td>BR</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>Fartura</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>D48D0720681E4F5D9A2767F7174B5FA6-2782006</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.96</td>\n",
       "      <td>A0EB579C0AE0452D9020C91C54565B4F-2782009</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VISA</td>\n",
       "      <td>BR</td>\n",
       "      <td>CLASSIC</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>Recife</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.72</td>\n",
       "      <td>17A1DF0F984E4B34AC512D7E9E23B7BB-2782011</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MASTERCARD</td>\n",
       "      <td>BR</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>F</td>\n",
       "      <td>Guarapari</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.15</td>\n",
       "      <td>21CA5C8AA45B400DB55985466AEE0BCD-2782028</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ELO/DISCOVER</td>\n",
       "      <td>BR</td>\n",
       "      <td>NANJING DINERS</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>M</td>\n",
       "      <td>Curitiba</td>\n",
       "      <td>BR</td>\n",
       "      <td>...</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.74</td>\n",
       "      <td>FFC167F3C6C742C9AD26E7E07ED72115-2782055</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577752e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BILLINGCITY() BILLINGSTATE() BROWSER() CREDITCARDBRAND()  \\\n",
       "0           NaN            NaN       NaN              VISA   \n",
       "1           NaN            NaN       NaN        MASTERCARD   \n",
       "2           NaN            NaN       NaN              VISA   \n",
       "3           NaN            NaN       NaN        MASTERCARD   \n",
       "4           NaN            NaN       NaN      ELO/DISCOVER   \n",
       "\n",
       "  CREDITCARDCOUNTRY() CREDITCARDSUBTYPE() EMAILDOMAIN() GENDERBYNAMEPTBR()  \\\n",
       "0                  BR                GOLD   hotmail.com                  F   \n",
       "1                  BR                GOLD     gmail.com                  F   \n",
       "2                  BR             CLASSIC     gmail.com                  F   \n",
       "3                  BR            PLATINUM     gmail.com                  F   \n",
       "4                  BR      NANJING DINERS   hotmail.com                  M   \n",
       "\n",
       "  IPGEOLOCATIONCITY() IPGEOLOCATIONCOUNTRY()  ... SHIPPINGSTATE()  \\\n",
       "0             Fartura                     BR  ...              SP   \n",
       "1           São Paulo                     BR  ...              SP   \n",
       "2              Recife                     BR  ...              AL   \n",
       "3           Guarapari                     BR  ...              RJ   \n",
       "4            Curitiba                     BR  ...              SC   \n",
       "\n",
       "  UTMSOURCELASTCLICK()    y order_amount  \\\n",
       "0                  NaN  0.0       156.75   \n",
       "1                  NaN  0.0        67.96   \n",
       "2                  NaN  0.0       315.72   \n",
       "3                  NaN  0.0       514.15   \n",
       "4                  NaN  0.0        64.74   \n",
       "\n",
       "                                   order_id    status         epoch store_id  \\\n",
       "0  D48D0720681E4F5D9A2767F7174B5FA6-2782006  APPROVED  1.577751e+12     6044   \n",
       "1  A0EB579C0AE0452D9020C91C54565B4F-2782009  APPROVED  1.577751e+12     6044   \n",
       "2  17A1DF0F984E4B34AC512D7E9E23B7BB-2782011  APPROVED  1.577751e+12     6044   \n",
       "3  21CA5C8AA45B400DB55985466AEE0BCD-2782028  APPROVED  1.577751e+12     6044   \n",
       "4  FFC167F3C6C742C9AD26E7E07ED72115-2782055  APPROVED  1.577752e+12     6044   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2019-12-30  \n",
       "1     1.0 2019-12-30  \n",
       "2     1.0 2019-12-30  \n",
       "3     1.0 2019-12-30  \n",
       "4     1.0 2019-12-30  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_train = pd.read_csv('new_additional_datasets/categorical_features/dataset_' + str(s) + '.csv',\n",
    "                      dtype={'order_id': str, 'store_id': int})\n",
    "categorical_train.drop_duplicates(['order_id', 'epoch', 'order_amount'], inplace=True)\n",
    "\n",
    "categorical_train['date'] = categorical_train.epoch.apply(epoch_to_date)\n",
    "\n",
    "# Splitting data into train and test:\n",
    "categorical_test = categorical_train[(categorical_train.date > datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "categorical_train = categorical_train[(categorical_train.date <= datetime.strptime('2020-03-30', '%Y-%m-%d'))]\n",
    "\n",
    "# Splitting data into validation and test:\n",
    "categorical_val = categorical_test[categorical_test.date < datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "categorical_test = categorical_test[categorical_test.date >= datetime.strptime('2020-05-01', '%Y-%m-%d')]\n",
    "\n",
    "print('\\033[1mShape of categorical_train (training data):\\033[0m ' + str(categorical_train.shape) + '.')\n",
    "print('\\033[1mNumber of orders (training data):\\033[0m ' + str(categorical_train.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mShape of categorical_val (validation data):\\033[0m ' + str(categorical_val.shape) + '.')\n",
    "print('\\033[1mNumber of orders (validation data):\\033[0m ' + str(categorical_val.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mShape of categorical_test (test data):\\033[0m ' + str(categorical_test.shape) + '.')\n",
    "print('\\033[1mNumber of orders (test data):\\033[0m ' + str(categorical_test.order_id.nunique()) + '.')\n",
    "print('\\n')\n",
    "\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (training data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      35793\n",
      "BROWSER()                 35689\n",
      "BILLINGSTATE()            32920\n",
      "BILLINGCITY()             32920\n",
      "CREDITCARDSUBTYPE()         642\n",
      "IPGEOLOCATIONCITY()         522\n",
      "IPGEOLOCATIONCOUNTRY()       20\n",
      "GENDERBYNAMEPTBR()           12\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "CREDITCARDCOUNTRY()           0\n",
      "CREDITCARDBRAND()             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (training data):\\033[0m')\n",
    "print(categorical_train.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (validation data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      20896\n",
      "BROWSER()                 20846\n",
      "BILLINGSTATE()            19447\n",
      "BILLINGCITY()             19447\n",
      "CREDITCARDSUBTYPE()         350\n",
      "IPGEOLOCATIONCITY()         274\n",
      "GENDERBYNAMEPTBR()           10\n",
      "IPGEOLOCATIONCOUNTRY()        5\n",
      "CREDITCARDCOUNTRY()           1\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "CREDITCARDBRAND()             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (validation data):\\033[0m')\n",
    "print(categorical_val.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAssessing missing values in categorical data (test data):\u001b[0m\n",
      "UTMSOURCELASTCLICK()      21757\n",
      "BROWSER()                 21689\n",
      "BILLINGSTATE()            20084\n",
      "BILLINGCITY()             20084\n",
      "IPGEOLOCATIONCITY()        1927\n",
      "IPGEOLOCATIONCOUNTRY()      492\n",
      "CREDITCARDSUBTYPE()         455\n",
      "CREDITCARDCOUNTRY()           2\n",
      "GENDERBYNAMEPTBR()            1\n",
      "SHIPPINGSTATE()               0\n",
      "SHIPPINGCITY()                0\n",
      "SELLERID()                    0\n",
      "EMAILDOMAIN()                 0\n",
      "CREDITCARDBRAND()             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1mAssessing missing values in categorical data (test data):\\033[0m')\n",
    "print(categorical_test.drop(drop_vars, axis=1).isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over categorical features:\n",
    "for f in categorical_train.drop(drop_vars, axis=1).columns:\n",
    "    # Training data\n",
    "    categorical_train[f] = categorical_train[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)\n",
    "    \n",
    "    # Validation data:\n",
    "    categorical_val[f] = categorical_val[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)\n",
    "    \n",
    "    # Test data:\n",
    "    categorical_test[f] = categorical_test[f].apply(lambda x: 'NA_VALUE' if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values:\n",
    "if categorical_train.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(categorical_train.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "if categorical_val.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (validation data):\\033[0m ' +\n",
    "          str(categorical_val.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "    \n",
    "if categorical_test.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(categorical_test.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGCITY()</th>\n",
       "      <th>BILLINGSTATE()</th>\n",
       "      <th>BROWSER()</th>\n",
       "      <th>CREDITCARDBRAND()</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>...</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "      <th>y</th>\n",
       "      <th>order_amount</th>\n",
       "      <th>order_id</th>\n",
       "      <th>status</th>\n",
       "      <th>epoch</th>\n",
       "      <th>store_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>visa</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>fartura</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.75</td>\n",
       "      <td>D48D0720681E4F5D9A2767F7174B5FA6-2782006</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.96</td>\n",
       "      <td>A0EB579C0AE0452D9020C91C54565B4F-2782009</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>visa</td>\n",
       "      <td>br</td>\n",
       "      <td>classic</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>recife</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>al</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315.72</td>\n",
       "      <td>17A1DF0F984E4B34AC512D7E9E23B7BB-2782011</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>guarapari</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>rj</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>514.15</td>\n",
       "      <td>21CA5C8AA45B400DB55985466AEE0BCD-2782028</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577751e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>na_value</td>\n",
       "      <td>elo/discover</td>\n",
       "      <td>br</td>\n",
       "      <td>nanjing_diners</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>br</td>\n",
       "      <td>...</td>\n",
       "      <td>sc</td>\n",
       "      <td>na_value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.74</td>\n",
       "      <td>FFC167F3C6C742C9AD26E7E07ED72115-2782055</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>1.577752e+12</td>\n",
       "      <td>6044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  BILLINGCITY() BILLINGSTATE() BROWSER() CREDITCARDBRAND()  \\\n",
       "0      na_value       na_value  na_value              visa   \n",
       "1      na_value       na_value  na_value        mastercard   \n",
       "2      na_value       na_value  na_value              visa   \n",
       "3      na_value       na_value  na_value        mastercard   \n",
       "4      na_value       na_value  na_value      elo/discover   \n",
       "\n",
       "  CREDITCARDCOUNTRY() CREDITCARDSUBTYPE() EMAILDOMAIN() GENDERBYNAMEPTBR()  \\\n",
       "0                  br                gold   hotmail.com                  f   \n",
       "1                  br                gold     gmail.com                  f   \n",
       "2                  br             classic     gmail.com                  f   \n",
       "3                  br            platinum     gmail.com                  f   \n",
       "4                  br      nanjing_diners   hotmail.com                  m   \n",
       "\n",
       "  IPGEOLOCATIONCITY() IPGEOLOCATIONCOUNTRY()  ... SHIPPINGSTATE()  \\\n",
       "0             fartura                     br  ...              sp   \n",
       "1           sao_paulo                     br  ...              sp   \n",
       "2              recife                     br  ...              al   \n",
       "3           guarapari                     br  ...              rj   \n",
       "4            curitiba                     br  ...              sc   \n",
       "\n",
       "  UTMSOURCELASTCLICK()    y order_amount  \\\n",
       "0             na_value  0.0       156.75   \n",
       "1             na_value  0.0        67.96   \n",
       "2             na_value  0.0       315.72   \n",
       "3             na_value  0.0       514.15   \n",
       "4             na_value  0.0        64.74   \n",
       "\n",
       "                                   order_id    status         epoch store_id  \\\n",
       "0  D48D0720681E4F5D9A2767F7174B5FA6-2782006  APPROVED  1.577751e+12     6044   \n",
       "1  A0EB579C0AE0452D9020C91C54565B4F-2782009  APPROVED  1.577751e+12     6044   \n",
       "2  17A1DF0F984E4B34AC512D7E9E23B7BB-2782011  APPROVED  1.577751e+12     6044   \n",
       "3  21CA5C8AA45B400DB55985466AEE0BCD-2782028  APPROVED  1.577751e+12     6044   \n",
       "4  FFC167F3C6C742C9AD26E7E07ED72115-2782055  APPROVED  1.577752e+12     6044   \n",
       "\n",
       "   weight       date  \n",
       "0     1.0 2019-12-30  \n",
       "1     1.0 2019-12-30  \n",
       "2     1.0 2019-12-30  \n",
       "3     1.0 2019-12-30  \n",
       "4     1.0 2019-12-30  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_vars = [c for c in categorical_train.drop(drop_vars, axis=1) if 'NA#' in c]\n",
    "\n",
    "# Loop over categorical features:\n",
    "for f in categorical_train.drop(drop_vars, axis=1).drop(na_vars, axis=1).columns:\n",
    "    # Training data:\n",
    "    categorical_train[f] = categorical_train[f].apply(lambda x: text_clean(str(x)))\n",
    "    \n",
    "    # Validation data:\n",
    "    categorical_val[f] = categorical_val[f].apply(lambda x: text_clean(str(x)))\n",
    "    \n",
    "    # Test data:\n",
    "    categorical_test[f] = categorical_test[f].apply(lambda x: text_clean(str(x)))\n",
    "\n",
    "categorical_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train for store 6044:\u001b[0m (35897, 2187).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>fartura</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>fartura</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>santos</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>classic</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>recife</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>maceio</td>\n",
       "      <td>al</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>guarapari</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>itaperuna</td>\n",
       "      <td>rj</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>nanjing_diners</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>curitiba</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_jose</td>\n",
       "      <td>sc</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           0.0                         0.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "3                           0.0                         0.0  ...   \n",
       "4                           0.0                         0.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0                   br                 gold    hotmail.com   \n",
       "1                   br                 gold      gmail.com   \n",
       "2                   br              classic      gmail.com   \n",
       "3                   br             platinum      gmail.com   \n",
       "4                   br       nanjing_diners    hotmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   f              fartura                      br   \n",
       "1                   f            sao_paulo                      br   \n",
       "2                   f               recife                      br   \n",
       "3                   f            guarapari                      br   \n",
       "4                   m             curitiba                      br   \n",
       "\n",
       "   SELLERID()  SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none         fartura               sp              na_value  \n",
       "1        none          santos               sp              na_value  \n",
       "2        none          maceio               al              na_value  \n",
       "3        none       itaperuna               rj              na_value  \n",
       "4        none        sao_jose               sc              na_value  \n",
       "\n",
       "[5 rows x 2187 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data:\n",
    "df_train = df_train.merge(categorical_train[[f for f in categorical_train.columns if (f not in drop_vars) |\n",
    "                                             (f == 'order_id')]],\n",
    "                          on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_train for store ' + str(s) + ':\\033[0m ' + str(df_train.shape) + '.')\n",
    "print('\\n')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_val for store 6044:\u001b[0m (20940, 2187).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>itapecerica_da_serra</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>infinite</td>\n",
       "      <td>karseg.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>campinas</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>campinas</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>mairinque</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>mairinque</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>hotmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>salvador</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>joao_pessoa</td>\n",
       "      <td>pb</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           1.0                          1.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           1.0                         1.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           1.0                        1.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           1.0                         1.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "3                           0.0                         0.0  ...   \n",
       "4                           0.0                         0.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0                   br                 gold    hotmail.com   \n",
       "1                   br             infinite  karseg.com.br   \n",
       "2                   br                 gold      gmail.com   \n",
       "3                   br             platinum      gmail.com   \n",
       "4                   br             platinum    hotmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   f            sao_paulo                      br   \n",
       "1                   m             campinas                      br   \n",
       "2                   m            sao_paulo                      br   \n",
       "3                   f            mairinque                      br   \n",
       "4                   f             salvador                      br   \n",
       "\n",
       "   SELLERID()        SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none  itapecerica_da_serra               sp              na_value  \n",
       "1        none              campinas               sp              na_value  \n",
       "2        none             sao_paulo               sp              na_value  \n",
       "3        none             mairinque               sp              na_value  \n",
       "4        none           joao_pessoa               pb              na_value  \n",
       "\n",
       "[5 rows x 2187 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation data:\n",
    "df_val = df_val.merge(categorical_val[[f for f in categorical_val.columns if (f not in drop_vars) |\n",
    "                                       (f == 'order_id')]],\n",
    "                      on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_val for store ' + str(s) + ':\\033[0m ' + str(df_val.shape) + '.')\n",
    "print('\\n')\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_test for store 6044:\u001b[0m (21791, 2187).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILLINGLARGEAREAREPUTATION()</th>\n",
       "      <th>BILLINGSMALLAREAREPUTATION()</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,10080)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,1440)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,21600)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,360)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,43200)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,60)</th>\n",
       "      <th>BILLINGZIP(CREDITCARD,64800)</th>\n",
       "      <th>BILLINGZIP(DOCUMENT,10080)</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITCARDCOUNTRY()</th>\n",
       "      <th>CREDITCARDSUBTYPE()</th>\n",
       "      <th>EMAILDOMAIN()</th>\n",
       "      <th>GENDERBYNAMEPTBR()</th>\n",
       "      <th>IPGEOLOCATIONCITY()</th>\n",
       "      <th>IPGEOLOCATIONCOUNTRY()</th>\n",
       "      <th>SELLERID()</th>\n",
       "      <th>SHIPPINGCITY()</th>\n",
       "      <th>SHIPPINGSTATE()</th>\n",
       "      <th>UTMSOURCELASTCLICK()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>nanjing</td>\n",
       "      <td>adp.com</td>\n",
       "      <td>m</td>\n",
       "      <td>porto_alegre</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>porto_alegre</td>\n",
       "      <td>rs</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>platinum</td>\n",
       "      <td>uol.com.br</td>\n",
       "      <td>f</td>\n",
       "      <td>jundiai</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>jundiai</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>black</td>\n",
       "      <td>uol.com.br</td>\n",
       "      <td>m</td>\n",
       "      <td>itanhaem</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>itanhaem</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>f</td>\n",
       "      <td>santa_maria</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>santa_maria</td>\n",
       "      <td>rs</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>gold</td>\n",
       "      <td>gmail.com</td>\n",
       "      <td>m</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>br</td>\n",
       "      <td>none</td>\n",
       "      <td>sao_paulo</td>\n",
       "      <td>sp</td>\n",
       "      <td>na_value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BILLINGLARGEAREAREPUTATION()  BILLINGSMALLAREAREPUTATION()  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,10080)  BILLINGZIP(CREDITCARD,1440)  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,21600)  BILLINGZIP(CREDITCARD,360)  \\\n",
       "0                           0.0                         0.0   \n",
       "1                           0.0                         0.0   \n",
       "2                           0.0                         0.0   \n",
       "3                           0.0                         0.0   \n",
       "4                           0.0                         0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,43200)  BILLINGZIP(CREDITCARD,60)  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   BILLINGZIP(CREDITCARD,64800)  BILLINGZIP(DOCUMENT,10080)  ...  \\\n",
       "0                           0.0                         0.0  ...   \n",
       "1                           0.0                         0.0  ...   \n",
       "2                           0.0                         0.0  ...   \n",
       "3                           0.0                         0.0  ...   \n",
       "4                           0.0                         0.0  ...   \n",
       "\n",
       "   CREDITCARDCOUNTRY()  CREDITCARDSUBTYPE()  EMAILDOMAIN()  \\\n",
       "0                   br              nanjing        adp.com   \n",
       "1                   br             platinum     uol.com.br   \n",
       "2                   br                black     uol.com.br   \n",
       "3                   br                 gold      gmail.com   \n",
       "4                   br                 gold      gmail.com   \n",
       "\n",
       "   GENDERBYNAMEPTBR()  IPGEOLOCATIONCITY()  IPGEOLOCATIONCOUNTRY()  \\\n",
       "0                   m         porto_alegre                      br   \n",
       "1                   f              jundiai                      br   \n",
       "2                   m             itanhaem                      br   \n",
       "3                   f          santa_maria                      br   \n",
       "4                   m            sao_paulo                      br   \n",
       "\n",
       "   SELLERID()  SHIPPINGCITY()  SHIPPINGSTATE()  UTMSOURCELASTCLICK()  \n",
       "0        none    porto_alegre               rs              na_value  \n",
       "1        none         jundiai               sp              na_value  \n",
       "2        none        itanhaem               sp              na_value  \n",
       "3        none     santa_maria               rs              na_value  \n",
       "4        none       sao_paulo               sp              na_value  \n",
       "\n",
       "[5 rows x 2187 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data:\n",
    "df_test = df_test.merge(categorical_test[[f for f in categorical_test.columns if (f not in drop_vars) |\n",
    "                                          (f == 'order_id')]],\n",
    "                        on='order_id', how='left')\n",
    "\n",
    "print('\\033[1mShape of df_test for store ' + str(s) + ':\\033[0m ' + str(df_test.shape) + '.')\n",
    "print('\\n')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "if df_train.isnull().sum().sum() != num_miss_train:\n",
    "    print('\\033[1mInconsistent number of overall missings values (training data)!\\033[0m')\n",
    "    print('\\n')\n",
    "\n",
    "# Assessing missing values (validation data):\n",
    "if df_val.isnull().sum().sum() != num_miss_val:\n",
    "    print('\\033[1mInconsistent number of overall missings values (validation data)!\\033[0m')\n",
    "    print('\\n')\n",
    "    \n",
    "# Assessing missing values (test data):\n",
    "if df_test.isnull().sum().sum() != num_miss_test:\n",
    "    print('\\033[1mInconsistent number of overall missings values (test data)!\\033[0m')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model_assessment'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/matheus_rosso/Arquivo/Materiais/Codes/neural_nets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression estimations:\n",
    "if 'model_assessment_LR.json' not in os.listdir('Datasets'):\n",
    "    model_assessment_LR = {}\n",
    "\n",
    "else:\n",
    "    with open('Datasets/model_assessment_LR.json') as json_file:\n",
    "        model_assessment_LR = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM estimations:\n",
    "if 'model_assessment_SVM.json' not in os.listdir('Datasets'):\n",
    "    model_assessment_SVM = {}\n",
    "\n",
    "else:\n",
    "    with open('Datasets/model_assessment_SVM.json') as json_file:\n",
    "        model_assessment_SVM = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM estimations:\n",
    "if 'model_assessment_GBM.json' not in os.listdir('Datasets'):\n",
    "    model_assessment_GBM = {}\n",
    "\n",
    "else:\n",
    "    with open('Datasets/model_assessment_GBM.json') as json_file:\n",
    "        model_assessment_GBM = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classif_feat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cont_vars</td>\n",
       "      <td>1619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>missing_vars</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>binary_vars</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cat_vars</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>drop_vars</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class  frequency\n",
       "3     cont_vars       1619\n",
       "1  missing_vars        415\n",
       "2   binary_vars         27\n",
       "0      cat_vars         14\n",
       "4     drop_vars          8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical features:\n",
    "cat_vars = list(categorical_train.drop(drop_vars, axis=1).columns)\n",
    "\n",
    "# Dummy variables indicating missing value status:\n",
    "missing_vars = [c for c in list(df_train.drop(drop_vars, axis=1).columns) if ('NA#' in c)]\n",
    "\n",
    "# Dropping features with no variance:\n",
    "no_variance = [c for c in df_train.drop(drop_vars, axis=1).drop(cat_vars,\n",
    "                                                                axis=1).drop(missing_vars,\n",
    "                                                                             axis=1) if df_train[c].var()==0]\n",
    "\n",
    "if len(no_variance) > 0:\n",
    "    df_train.drop(no_variance, axis=1, inplace=True)\n",
    "    df_val.drop(no_variance, axis=1, inplace=True)\n",
    "    df_test.drop(no_variance, axis=1, inplace=True)\n",
    "\n",
    "# Numerical features:\n",
    "cont_vars = [c for c in  list(df_train.drop(drop_vars, axis=1).columns) if is_velocity(c)]\n",
    "\n",
    "# Binary features:\n",
    "binary_vars = [c for c in list(df_train.drop([c for c in df_train.columns if (c in drop_vars) |\n",
    "                                             (c in cat_vars) | (c in missing_vars) | (c in cont_vars)],\n",
    "                                             axis=1).columns) if set(df_train[c].unique()) == set([0,1])]\n",
    "\n",
    "# Updating the list of numerical features:\n",
    "for c in list(df_train.drop(drop_vars, axis=1).columns):\n",
    "    if (c not in cat_vars) & (c not in missing_vars) & (c not in cont_vars) & (c not in binary_vars):\n",
    "        cont_vars.append(c)\n",
    "\n",
    "# Dataframe presenting the frequency of features by class:\n",
    "feats_assess = pd.DataFrame(data={\n",
    "    'class': ['cat_vars', 'missing_vars', 'binary_vars', 'cont_vars', 'drop_vars'],\n",
    "    'frequency': [len(cat_vars), len(missing_vars), len(binary_vars), len(cont_vars), len(drop_vars)]\n",
    "})\n",
    "feats_assess.sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_pre_proc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing_missing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_vars = [f for f in df_train.columns if 'NA#' in f]\n",
    "\n",
    "# Loop over variables with missing values:\n",
    "for f in [c for c in missing_vars if c.replace('NA#', '') not in cat_vars]:\n",
    "    if f.replace('NA#', '') in df_train.columns:\n",
    "        # Training data:\n",
    "        df_train[f.replace('NA#', '')] = recreate_missings(df_train[f.replace('NA#', '')], df_train[f])\n",
    "        \n",
    "        # Validation data:\n",
    "        df_val[f.replace('NA#', '')] = recreate_missings(df_val[f.replace('NA#', '')], df_val[f])\n",
    "        \n",
    "        # Test data:\n",
    "        df_test[f.replace('NA#', '')] = recreate_missings(df_test[f.replace('NA#', '')], df_test[f])\n",
    "    else:\n",
    "        df_train.drop([f], axis=1, inplace=True)\n",
    "        \n",
    "        df_val.drop([f], axis=1, inplace=True)\n",
    "        \n",
    "        df_test.drop([f], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping all variables with missing value status:\n",
    "df_train.drop([f for f in df_train.columns if 'NA#' in f], axis=1, inplace=True)\n",
    "\n",
    "df_val.drop([f for f in df_val.columns if 'NA#' in f], axis=1, inplace=True)\n",
    "\n",
    "df_test.drop([f for f in df_test.columns if 'NA#' in f], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describing the frequency of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 389 out of 1668 features (23.32%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 7108 out of 35897 observations (19.8%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CUSTNAVCOUNT(cv,6M)</td>\n",
       "      <td>35601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GDOCUMENT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>35574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>35540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>IP(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DOCUMENT(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>35447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>GEMAIL(TOTAL_AMOUNT,360)</td>\n",
       "      <td>35387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     feature  missings\n",
       "training_data                                         \n",
       "0                        CUSTNAVCOUNT(cv,6M)     35601\n",
       "1                 GDOCUMENT(TOTAL_AMOUNT,60)     35574\n",
       "2               GTELEPHONE(TOTAL_AMOUNT,360)     35540\n",
       "3                    NAME(TOTAL_AMOUNT,1440)     35494\n",
       "4                      IP(TOTAL_AMOUNT,1440)     35490\n",
       "5                   EMAIL(TOTAL_AMOUNT,1440)     35482\n",
       "6                DOCUMENT(TOTAL_AMOUNT,1440)     35459\n",
       "7              CREDITCARD(TOTAL_AMOUNT,1440)     35458\n",
       "8               TELEPHONE(TOTAL_AMOUNT,1440)     35447\n",
       "9                   GEMAIL(TOTAL_AMOUNT,360)     35387"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (training data):\n",
    "missings_dict = df_train.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_train = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_train.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_train)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_train.missings > 0)/len(missings_assess_train))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_train.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_train)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_train.missings.mean())/len(df_train))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_train.index.name = 'training_data'\n",
    "missings_assess_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 389 out of 1668 features (23.32%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 4176 out of 20940 observations (19.94%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CUSTNAVCOUNT(cv,6M)</td>\n",
       "      <td>20741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GDOCUMENT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>20731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>20710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>IP(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DOCUMENT(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>20654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>FSBZIPPHONE()</td>\n",
       "      <td>20630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  missings\n",
       "val_data                                         \n",
       "0                   CUSTNAVCOUNT(cv,6M)     20741\n",
       "1            GDOCUMENT(TOTAL_AMOUNT,60)     20731\n",
       "2          GTELEPHONE(TOTAL_AMOUNT,360)     20710\n",
       "3               NAME(TOTAL_AMOUNT,1440)     20685\n",
       "4              EMAIL(TOTAL_AMOUNT,1440)     20674\n",
       "5         CREDITCARD(TOTAL_AMOUNT,1440)     20658\n",
       "6                 IP(TOTAL_AMOUNT,1440)     20657\n",
       "7           DOCUMENT(TOTAL_AMOUNT,1440)     20657\n",
       "8          TELEPHONE(TOTAL_AMOUNT,1440)     20654\n",
       "9                         FSBZIPPHONE()     20630"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (validation data):\n",
    "missings_dict = df_val.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_val = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_val.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_val)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_val.missings > 0)/len(missings_assess_val))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_val.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_val)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_val.missings.mean())/len(df_val))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_val.index.name = 'val_data'\n",
    "missings_assess_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of features with missings:\u001b[0m 389 out of 1668 features (23.32%).\n",
      "\u001b[1mAverage number of missings:\u001b[0m 4302 out of 21791 observations (19.74%).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>missings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>GDOCUMENT(TOTAL_AMOUNT,60)</td>\n",
       "      <td>21521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>GTELEPHONE(TOTAL_AMOUNT,360)</td>\n",
       "      <td>21512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EMAIL(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CUSTNAVCOUNT(cv,6M)</td>\n",
       "      <td>21490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NAME(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TELEPHONE(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DOCUMENT(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CREDITCARD(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>IP(TOTAL_AMOUNT,1440)</td>\n",
       "      <td>21466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>FSBZIPPHONE()</td>\n",
       "      <td>21444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature  missings\n",
       "test_data                                         \n",
       "0             GDOCUMENT(TOTAL_AMOUNT,60)     21521\n",
       "1           GTELEPHONE(TOTAL_AMOUNT,360)     21512\n",
       "2               EMAIL(TOTAL_AMOUNT,1440)     21493\n",
       "3                    CUSTNAVCOUNT(cv,6M)     21490\n",
       "4                NAME(TOTAL_AMOUNT,1440)     21482\n",
       "5           TELEPHONE(TOTAL_AMOUNT,1440)     21476\n",
       "6            DOCUMENT(TOTAL_AMOUNT,1440)     21475\n",
       "7          CREDITCARD(TOTAL_AMOUNT,1440)     21472\n",
       "8                  IP(TOTAL_AMOUNT,1440)     21466\n",
       "9                          FSBZIPPHONE()     21444"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with the number of missings by feature (test data):\n",
    "missings_dict = df_test.isnull().sum().sort_values(ascending=False).to_dict()\n",
    "\n",
    "missings_assess_test = pd.DataFrame(data={\n",
    "    'feature': list(missings_dict.keys()),\n",
    "    'missings': list(missings_dict.values())\n",
    "})\n",
    "\n",
    "print('\\033[1mNumber of features with missings:\\033[0m {}'.format(sum(missings_assess_test.missings > 0)) +\n",
    "      ' out of {} features'.format(len(missings_assess_test)) +\n",
    "      ' ({}%).'.format(round((sum(missings_assess_test.missings > 0)/len(missings_assess_test))*100, 2)))\n",
    "print('\\033[1mAverage number of missings:\\033[0m {}'.format(int(missings_assess_test.missings.mean())) +\n",
    "      ' out of {} observations'.format(len(df_test)) +\n",
    "      ' ({}%).'.format(round((int(missings_assess_test.missings.mean())/len(df_test))*100,2)))\n",
    "print('\\n')\n",
    "missings_assess_test.index.name = 'test_data'\n",
    "missings_assess_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='num_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logarithmic transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 11856255.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1619.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 11856255.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 6967103.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1619.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 6967103.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of overall missings detected (before logarithmic transformation):\u001b[0m 7177024.\n",
      "\u001b[1mNumber of numerical variables log-transformed:\u001b[0m 1619.\n",
      "\u001b[1mNumber of overall missings detected (after logarithmic transformation):\u001b[0m 7177024.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING LOGARITHMIC TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "# Variables that should not be log-transformed:\n",
    "not_log = [c for c in df_train.columns if c not in cont_vars]\n",
    "\n",
    "if log_transform:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_train = df_train.isnull().sum().sum()\n",
    "    if num_miss_train > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_train) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_train)\n",
    "    df_train = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_train_log = df_train.isnull().sum().sum()\n",
    "    if num_miss_train_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_train_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_train_log != num_miss_train:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "    print('\\n')\n",
    "    print('\\033[1mValidation data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_val = df_val.isnull().sum().sum()\n",
    "    if num_miss_val > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_val) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_val)\n",
    "    df_val = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_val_log = df_val.isnull().sum().sum()\n",
    "    if num_miss_val_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_val_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_val_log != num_miss_val:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "        \n",
    "    print('\\n')\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "\n",
    "    # Assessing missing values (before logarithmic transformation):\n",
    "    num_miss_test = df_test.isnull().sum().sum()\n",
    "    if num_miss_test > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (before logarithmic transformation):\\033[0m ' +\n",
    "              str(num_miss_test) + '.')\n",
    "\n",
    "    log_transf = log_transformation(not_log=not_log)\n",
    "    log_transf.transform(df_test)\n",
    "    df_test = log_transf.log_transformed\n",
    "\n",
    "    # Assessing missing values (after logarithmic transformation):\n",
    "    num_miss_test_log = df_test.isnull().sum().sum()\n",
    "    if num_miss_test_log > 0:\n",
    "        print('\\033[1mNumber of overall missings detected (after logarithmic transformation):\\033[0m ' + \n",
    "              str(num_miss_test_log) + '.')\n",
    "\n",
    "    # Checking consistency in the number of missings:\n",
    "    if num_miss_test_log != num_miss_test:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "else:\n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mShape of df_train_scaled (after scaling):\u001b[0m (35897, 1668).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 11856255.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "\u001b[1mShape of df_val_scaled (after scaling):\u001b[0m (20940, 1668).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 6967103.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mShape of df_test_scaled (after scaling):\u001b[0m (21791, 1668).\n",
      "\u001b[1mNumber of overall missings:\u001b[0m 7177024.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mAPPLYING STANDARD SCALE TRANSFORMATION OVER NUMERICAL DATA\\033[0m')\n",
    "print('\\n')\n",
    "# Inputs that should not be standardized:\n",
    "not_stand = [c for c in df_train.columns if c.replace('L#', '') not in cont_vars]\n",
    "\n",
    "if standardize:\n",
    "    print('\\033[1mTraining data:\\033[0m')\n",
    "\n",
    "    stand_scale = standard_scale(not_stand = not_stand)\n",
    "    \n",
    "    stand_scale.scale(train = df_train, test = df_val)\n",
    "    \n",
    "    df_train_scaled = stand_scale.train_scaled\n",
    "    print('\\033[1mShape of df_train_scaled (after scaling):\\033[0m ' + str(df_train_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_train = df_train.isnull().sum().sum()\n",
    "    num_miss_train_scaled = df_train_scaled.isnull().sum().sum()\n",
    "    if num_miss_train_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_train_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (training data)!\\033[0m')\n",
    "\n",
    "    if num_miss_train_scaled != num_miss_train:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\033[1mValidation data:\\033[0m')\n",
    "    df_val_scaled = stand_scale.test_scaled\n",
    "    print('\\033[1mShape of df_val_scaled (after scaling):\\033[0m ' + str(df_val_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_val = df_val.isnull().sum().sum()\n",
    "    num_miss_val_scaled = df_val_scaled.isnull().sum().sum()\n",
    "    if num_miss_val_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_val_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (val data)!\\033[0m')\n",
    "\n",
    "    if num_miss_val_scaled != num_miss_val:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "        \n",
    "    print('\\n')\n",
    "    print('\\033[1mTest data:\\033[0m')\n",
    "    stand_scale.scale(train = df_train, test = df_test)\n",
    "    df_test_scaled = stand_scale.test_scaled\n",
    "    print('\\033[1mShape of df_test_scaled (after scaling):\\033[0m ' + str(df_test_scaled.shape) + '.')\n",
    "\n",
    "    # Assessing missing values (after standardizing numerical features):\n",
    "    num_miss_test = df_test.isnull().sum().sum()\n",
    "    num_miss_test_scaled = df_test_scaled.isnull().sum().sum()\n",
    "    if num_miss_test_scaled > 0:\n",
    "        print('\\033[1mNumber of overall missings:\\033[0m ' + str(num_miss_test_scaled) + '.')\n",
    "    else:\n",
    "        print('\\033[1mNo missing values detected (test data)!\\033[0m')\n",
    "\n",
    "    if num_miss_test_scaled != num_miss_test:\n",
    "        print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "else:\n",
    "    df_train_scaled = df_train.copy()\n",
    "    df_val_scaled = df_val.copy()\n",
    "    df_test_scaled = df_test.copy()\n",
    "    \n",
    "    print('\\033[1mNo transformation performed!\\033[0m')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------\n",
      "\u001b[1mTREATING MISSING VALUES\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1mTraining data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 11856255.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 11856255.\n",
      "\n",
      "\n",
      "\u001b[1mValidation data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 6967103.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 6967103.\n",
      "\n",
      "\n",
      "\u001b[1mTest data:\u001b[0m\n",
      "\u001b[1mNumber of overall missing values detected before treatment:\u001b[0m 7177024.\n",
      "\u001b[1mNumber of overall missing values detected during treatment:\u001b[0m 7177024.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\033[1mTREATING MISSING VALUES\\033[0m')\n",
    "print('\\n')\n",
    "\n",
    "print('\\033[1mTraining data:\\033[0m')\n",
    "num_miss_train = df_train_scaled.isnull().sum().sum()\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' +\n",
    "      str(num_miss_train) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_train_scaled.drop(drop_vars, axis=1):\n",
    "    # Checking if there is missing values for a given feature:\n",
    "    if df_train_scaled[f].isnull().sum() > 0:\n",
    "        check_missing = impute_missing(df_train_scaled[f])\n",
    "        df_train_scaled[f] = check_missing['var']\n",
    "        df_train_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "\n",
    "num_miss_train_treat = int(sum([sum(df_train_scaled[f]) for f in df_train_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_train_treat) + '.')\n",
    "\n",
    "if num_miss_train_treat != num_miss_train:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_train_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train_scaled.isnull().sum().sum()) + '.')\n",
    "\n",
    "print('\\n')\n",
    "print('\\033[1mValidation data:\\033[0m')\n",
    "num_miss_val = df_val_scaled.isnull().sum().sum()\n",
    "num_miss_val_treat = 0\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' + str(num_miss_val) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_val_scaled.drop(drop_vars, axis=1):\n",
    "    # Check if there is dummy variable of missing value status for training data:\n",
    "    if 'NA#' + f.replace('L#', '') in list(df_train_scaled.columns):\n",
    "        check_missing = impute_missing(df_val_scaled[f])\n",
    "        df_val_scaled[f] = check_missing['var']\n",
    "        df_val_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "    else:\n",
    "        # Checking if there are missings for variables without missings in training data:\n",
    "        if df_val_scaled[f].isnull().sum() > 0:\n",
    "            num_miss_val_treat += df_val_scaled[f].isnull().sum()\n",
    "            df_val_scaled[f].fillna(0, axis=0, inplace=True)\n",
    "\n",
    "num_miss_val_treat += int(sum([sum(df_val_scaled[f]) for f in df_val_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_val_treat) + '.')\n",
    "\n",
    "if num_miss_val_treat != num_miss_val:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_val_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (val data):\\033[0m ' +\n",
    "          str(df_val_scaled.isnull().sum().sum()) + '.')\n",
    "    \n",
    "print('\\n')\n",
    "print('\\033[1mTest data:\\033[0m')\n",
    "num_miss_test = df_test_scaled.isnull().sum().sum()\n",
    "num_miss_test_treat = 0\n",
    "print('\\033[1mNumber of overall missing values detected before treatment:\\033[0m ' + str(num_miss_test) + '.')\n",
    "\n",
    "# Loop over features:\n",
    "for f in df_test_scaled.drop(drop_vars, axis=1):\n",
    "    # Check if there is dummy variable of missing value status for training data:\n",
    "    if 'NA#' + f.replace('L#', '') in list(df_train_scaled.columns):\n",
    "        check_missing = impute_missing(df_test_scaled[f])\n",
    "        df_test_scaled[f] = check_missing['var']\n",
    "        df_test_scaled['NA#' + f.replace('L#', '')] = check_missing['missing_var']\n",
    "    else:\n",
    "        # Checking if there are missings for variables without missings in training data:\n",
    "        if df_test_scaled[f].isnull().sum() > 0:\n",
    "            num_miss_test_treat += df_test_scaled[f].isnull().sum()\n",
    "            df_test_scaled[f].fillna(0, axis=0, inplace=True)\n",
    "\n",
    "num_miss_test_treat += int(sum([sum(df_test_scaled[f]) for f in df_test_scaled.columns if 'NA#' in f]))\n",
    "print('\\033[1mNumber of overall missing values detected during treatment:\\033[0m ' +\n",
    "      str(num_miss_test_treat) + '.')\n",
    "\n",
    "if num_miss_test_treat != num_miss_test:\n",
    "    print('\\033[1mProblem - Inconsistent number of overall missings!\\033[0m')\n",
    "\n",
    "if df_test_scaled.isnull().sum().sum() > 0:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test_scaled.isnull().sum().sum()) + '.')\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical_transf'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating dummies through one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNumber of categorical features:\u001b[0m 14.\n",
      "\u001b[1mNumber of overall selected dummies:\u001b[0m 62.\n",
      "\u001b[1mShape of dummies_train for store 6044:\u001b[0m (35897, 62).\n",
      "\u001b[1mShape of dummies_val for store 6044:\u001b[0m (20940, 62).\n",
      "\u001b[1mShape of dummies_test for store 6044:\u001b[0m (21791, 62).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C#BILLINGCITY()#NA_VALUE</th>\n",
       "      <th>C#BILLINGCITY()#SAO_PAULO</th>\n",
       "      <th>C#BILLINGSTATE()#NA_VALUE</th>\n",
       "      <th>C#BILLINGSTATE()#SP</th>\n",
       "      <th>C#CREDITCARDBRAND()#AMERICAN_EXPRESS</th>\n",
       "      <th>C#CREDITCARDBRAND()#ELO/DISCOVER</th>\n",
       "      <th>C#CREDITCARDBRAND()#HIPERCARD</th>\n",
       "      <th>C#CREDITCARDBRAND()#MASTERCARD</th>\n",
       "      <th>C#CREDITCARDBRAND()#VISA</th>\n",
       "      <th>C#CREDITCARDSUBTYPE()#BLACK</th>\n",
       "      <th>...</th>\n",
       "      <th>C#SHIPPINGSTATE()#DF</th>\n",
       "      <th>C#SHIPPINGSTATE()#ES</th>\n",
       "      <th>C#SHIPPINGSTATE()#GO</th>\n",
       "      <th>C#SHIPPINGSTATE()#MG</th>\n",
       "      <th>C#SHIPPINGSTATE()#PE</th>\n",
       "      <th>C#SHIPPINGSTATE()#PR</th>\n",
       "      <th>C#SHIPPINGSTATE()#RJ</th>\n",
       "      <th>C#SHIPPINGSTATE()#RS</th>\n",
       "      <th>C#SHIPPINGSTATE()#SC</th>\n",
       "      <th>C#SHIPPINGSTATE()#SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   C#BILLINGCITY()#NA_VALUE  C#BILLINGCITY()#SAO_PAULO  \\\n",
       "0                         1                          0   \n",
       "1                         1                          0   \n",
       "2                         1                          0   \n",
       "3                         1                          0   \n",
       "4                         1                          0   \n",
       "\n",
       "   C#BILLINGSTATE()#NA_VALUE  C#BILLINGSTATE()#SP  \\\n",
       "0                          1                    0   \n",
       "1                          1                    0   \n",
       "2                          1                    0   \n",
       "3                          1                    0   \n",
       "4                          1                    0   \n",
       "\n",
       "   C#CREDITCARDBRAND()#AMERICAN_EXPRESS  C#CREDITCARDBRAND()#ELO/DISCOVER  \\\n",
       "0                                     0                                 0   \n",
       "1                                     0                                 0   \n",
       "2                                     0                                 0   \n",
       "3                                     0                                 0   \n",
       "4                                     0                                 1   \n",
       "\n",
       "   C#CREDITCARDBRAND()#HIPERCARD  C#CREDITCARDBRAND()#MASTERCARD  \\\n",
       "0                              0                               0   \n",
       "1                              0                               1   \n",
       "2                              0                               0   \n",
       "3                              0                               1   \n",
       "4                              0                               0   \n",
       "\n",
       "   C#CREDITCARDBRAND()#VISA  C#CREDITCARDSUBTYPE()#BLACK  ...  \\\n",
       "0                         1                            0  ...   \n",
       "1                         0                            0  ...   \n",
       "2                         1                            0  ...   \n",
       "3                         0                            0  ...   \n",
       "4                         0                            0  ...   \n",
       "\n",
       "   C#SHIPPINGSTATE()#DF  C#SHIPPINGSTATE()#ES  C#SHIPPINGSTATE()#GO  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#MG  C#SHIPPINGSTATE()#PE  C#SHIPPINGSTATE()#PR  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#RJ  C#SHIPPINGSTATE()#RS  C#SHIPPINGSTATE()#SC  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     1                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   C#SHIPPINGSTATE()#SP  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create object for one-hot encoding:\n",
    "categorical_transf = one_hot_encoding(categorical_features = cat_vars)\n",
    "\n",
    "# Creating dummies:\n",
    "categorical_transf.create_dummies(categorical_train = categorical_train,\n",
    "                                  categorical_test = categorical_val)\n",
    "\n",
    "# Selected dummies:\n",
    "dummy_vars = list(categorical_transf.dummies_train.columns)\n",
    "\n",
    "# Training data:\n",
    "dummies_train = categorical_transf.dummies_train\n",
    "dummies_train.index = df_train_scaled.index\n",
    "\n",
    "# Validation data:\n",
    "dummies_val = categorical_transf.dummies_test\n",
    "dummies_val.index = df_val_scaled.index\n",
    "\n",
    "# Create object for one-hot encoding:\n",
    "categorical_transf = one_hot_encoding(categorical_features = cat_vars)\n",
    "\n",
    "# Creating dummies:\n",
    "categorical_transf.create_dummies(categorical_train = categorical_train,\n",
    "                                  categorical_test = categorical_test)\n",
    "\n",
    "# Test data:\n",
    "dummies_test = categorical_transf.dummies_test\n",
    "dummies_test.index = df_test_scaled.index\n",
    "\n",
    "# Dropping original categorical features:\n",
    "df_train_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "df_val_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "df_test_scaled.drop(cat_vars, axis=1, inplace=True)\n",
    "\n",
    "print('\\033[1mNumber of categorical features:\\033[0m {}.'.format(len(categorical_transf.categorical_features)))\n",
    "print('\\033[1mNumber of overall selected dummies:\\033[0m {}.'.format(dummies_train.shape[1]))\n",
    "print('\\033[1mShape of dummies_train for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_train.shape) + '.')\n",
    "print('\\033[1mShape of dummies_val for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_val.shape) + '.')\n",
    "print('\\033[1mShape of dummies_test for store ' + str(s) + ':\\033[0m ' +\n",
    "      str(dummies_test.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "dummies_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mShape of df_train_scaled for store 6044:\u001b[0m (35897, 2105).\n",
      "\u001b[1mShape of df_val_scaled for store 6044:\u001b[0m (20940, 2105).\n",
      "\u001b[1mShape of df_test_scaled for store 6044:\u001b[0m (21791, 2105).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BUREAUBILLCITY()</th>\n",
       "      <th>BUREAUBILLSTATE()</th>\n",
       "      <th>BUREAUEMAIL()</th>\n",
       "      <th>BUREAUPHONE()</th>\n",
       "      <th>BUREAUPHONEAREACODE()</th>\n",
       "      <th>BUREAUSHIPCITY()</th>\n",
       "      <th>BUREAUSHIPSTATE()</th>\n",
       "      <th>CREDITCARDCOUNTRYSAMEASSHIPPING()</th>\n",
       "      <th>EMAILHASFRAUD()</th>\n",
       "      <th>EMAILSAMEAMOUNT()</th>\n",
       "      <th>...</th>\n",
       "      <th>C#SHIPPINGSTATE()#DF</th>\n",
       "      <th>C#SHIPPINGSTATE()#ES</th>\n",
       "      <th>C#SHIPPINGSTATE()#GO</th>\n",
       "      <th>C#SHIPPINGSTATE()#MG</th>\n",
       "      <th>C#SHIPPINGSTATE()#PE</th>\n",
       "      <th>C#SHIPPINGSTATE()#PR</th>\n",
       "      <th>C#SHIPPINGSTATE()#RJ</th>\n",
       "      <th>C#SHIPPINGSTATE()#RS</th>\n",
       "      <th>C#SHIPPINGSTATE()#SC</th>\n",
       "      <th>C#SHIPPINGSTATE()#SP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BUREAUBILLCITY()  BUREAUBILLSTATE()  BUREAUEMAIL()  BUREAUPHONE()  \\\n",
       "0               0.0                0.0            0.0            0.0   \n",
       "1               0.0                0.0            0.0            0.0   \n",
       "2               0.0                0.0            0.0            0.0   \n",
       "3               0.0                0.0            0.0            0.0   \n",
       "4               0.0                0.0            0.0            0.0   \n",
       "\n",
       "   BUREAUPHONEAREACODE()  BUREAUSHIPCITY()  BUREAUSHIPSTATE()  \\\n",
       "0                    0.0               0.0                0.0   \n",
       "1                    0.0               0.0                0.0   \n",
       "2                    0.0               0.0                0.0   \n",
       "3                    0.0               0.0                0.0   \n",
       "4                    0.0               0.0                0.0   \n",
       "\n",
       "   CREDITCARDCOUNTRYSAMEASSHIPPING()  EMAILHASFRAUD()  EMAILSAMEAMOUNT()  ...  \\\n",
       "0                                1.0              0.0                0.0  ...   \n",
       "1                                1.0              0.0                0.0  ...   \n",
       "2                                1.0              0.0                0.0  ...   \n",
       "3                                1.0              0.0                0.0  ...   \n",
       "4                                1.0              0.0                0.0  ...   \n",
       "\n",
       "   C#SHIPPINGSTATE()#DF  C#SHIPPINGSTATE()#ES  C#SHIPPINGSTATE()#GO  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#MG  C#SHIPPINGSTATE()#PE  C#SHIPPINGSTATE()#PR  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   C#SHIPPINGSTATE()#RJ  C#SHIPPINGSTATE()#RS  C#SHIPPINGSTATE()#SC  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     1                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "   C#SHIPPINGSTATE()#SP  \n",
       "0                     1  \n",
       "1                     1  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 2105 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled = pd.concat([df_train_scaled, dummies_train], axis=1)\n",
    "df_val_scaled = pd.concat([df_val_scaled, dummies_val], axis=1)\n",
    "df_test_scaled = pd.concat([df_test_scaled, dummies_test], axis=1)\n",
    "\n",
    "print('\\033[1mShape of df_train_scaled for store ' + str(s) + ':\\033[0m ' + str(df_train_scaled.shape) + '.')\n",
    "print('\\033[1mShape of df_val_scaled for store ' + str(s) + ':\\033[0m ' + str(df_val_scaled.shape) + '.')\n",
    "print('\\033[1mShape of df_test_scaled for store ' + str(s) + ':\\033[0m ' + str(df_test_scaled.shape) + '.')\n",
    "print('\\n')\n",
    "\n",
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing missing values (training data):\n",
    "num_miss_train = df_train_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_train:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (training data):\\033[0m ' +\n",
    "          str(df_train_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "\n",
    "# Assessing missing values (validation data):\n",
    "num_miss_val = df_val_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_val:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (validation data):\\033[0m ' +\n",
    "          str(df_val_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')\n",
    "    \n",
    "# Assessing missing values (test data):\n",
    "num_miss_test = df_test_scaled.isnull().sum().sum() > 0\n",
    "if num_miss_test:\n",
    "    print('\\033[1mProblem - Number of overall missings detected (test data):\\033[0m ' +\n",
    "          str(df_test_scaled.isnull().sum().sum()) + '.')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datasets_structure'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking consistency of structure between training and validation dataframes:\n",
    "if len(list(df_train_scaled.columns)) != len(list(df_val_scaled.columns)):\n",
    "    print('\\033[1mProblem - Inconsistent number of columns between dataframes for training and validation data!\\033[0m')\n",
    "\n",
    "else:\n",
    "    consistency_check = 0\n",
    "    \n",
    "    # Loop over variables:\n",
    "    for c in list(df_train_scaled.columns):\n",
    "        if list(df_train_scaled.columns).index(c) != list(df_val_scaled.columns).index(c):\n",
    "            print('\\033[1mProblem - Feature {0} was positioned differently in training and val validation!\\033[0m'.format(c))\n",
    "            consistency_check += 1\n",
    "            \n",
    "    # Reordering columns of val dataframe:\n",
    "    if consistency_check > 0:\n",
    "        ordered_columns = list(df_train_scaled.columns)\n",
    "        df_val_scaled = df_val_scaled[ordered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking consistency of structure between training and test dataframes:\n",
    "if len(list(df_train_scaled.columns)) != len(list(df_test_scaled.columns)):\n",
    "    print('\\033[1mProblem - Inconsistent number of columns between dataframes for training and test data!\\033[0m')\n",
    "\n",
    "else:\n",
    "    consistency_check = 0\n",
    "    \n",
    "    # Loop over variables:\n",
    "    for c in list(df_train_scaled.columns):\n",
    "        if list(df_train_scaled.columns).index(c) != list(df_test_scaled.columns).index(c):\n",
    "            print('\\033[1mProblem - Feature {0} was positioned differently in training and test dataframes!\\033[0m'.format(c))\n",
    "            consistency_check += 1\n",
    "            \n",
    "    # Reordering columns of test dataframe:\n",
    "    if consistency_check > 0:\n",
    "        ordered_columns = list(df_train_scaled.columns)\n",
    "        df_test_scaled = df_test_scaled[ordered_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logistic_regression'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 10\n",
    "\n",
    "# Grid of values for regularization parameter:\n",
    "regul_params = [0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.25, 0.3, 0.5, 0.75, 1, 3, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 57.95 minutes.\n",
      "Start time: 2021-03-06, 16:07:15\n",
      "End time: 2021-03-06, 17:05:12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_bar = progressbar.ProgressBar(maxval=len(regul_params),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for c in range(len(regul_params)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "    \n",
    "    start_time_estimation = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "    \n",
    "    for t in range(n_estimations):\n",
    "        # Creating the model object:\n",
    "        model = LogisticRegression(solver='liblinear', penalty = 'l1', C = regul_params[c],\n",
    "                                   warm_start=True)\n",
    "\n",
    "        # Training the model:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "\n",
    "    end_time_estimation = datetime.now()\n",
    "        \n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment_LR[estimation_id] = {\n",
    "        'hyper_parameters': {\n",
    "            'regul_param': regul_params[c]\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((end_time_estimation - start_time_estimation).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": 'Defining regularization parameter.'\n",
    "    }\n",
    "\n",
    "    if export:\n",
    "        with open('Datasets/model_assessment_LR.json', 'w') as json_file:\n",
    "            json.dump(model_assessment_LR, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(c+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>regul_param</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1615057981</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.955959</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.494911</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>4.637836e+04</td>\n",
       "      <td>1855.338737</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1615057890</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.955629</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.506327</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>2.249887e+04</td>\n",
       "      <td>2477.968175</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1615058125</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.955378</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.490183</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>2.766967e+04</td>\n",
       "      <td>2341.526233</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1615058288</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.952854</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.479803</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>1.669246e+04</td>\n",
       "      <td>797.649401</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1615058500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.950577</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.474750</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>8.435548e+03</td>\n",
       "      <td>788.312979</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1615058752</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.947863</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>1.261775e+04</td>\n",
       "      <td>1056.523430</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1615057832</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.947221</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.483245</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>2.996569e+04</td>\n",
       "      <td>1511.267070</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1615057787</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.934738</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.410640</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>1.865915e+04</td>\n",
       "      <td>1006.517687</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1615059038</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>0.934620</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.410909</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>7.929845e+03</td>\n",
       "      <td>734.441767</td>\n",
       "      <td>9.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1615059637</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.916468</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.353622</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>8.781780e+03</td>\n",
       "      <td>652.266124</td>\n",
       "      <td>24.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1615057749</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.887300</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.242735</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>2.762006e+03</td>\n",
       "      <td>615.799251</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1615057710</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.764715</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.090780</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>9.826728e+02</td>\n",
       "      <td>128.030234</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1615057671</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.018614</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>2.269218e+04</td>\n",
       "      <td>221.944196</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1615057635</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>117000.955110</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id  regul_param  avg_roc_auc  std_roc_auc  avg_prec  std_prec  \\\n",
       "7     1615057981       0.2500     0.955959     0.000021  0.494911  0.000267   \n",
       "6     1615057890       0.1000     0.955629     0.000042  0.506327  0.000204   \n",
       "8     1615058125       0.3000     0.955378     0.000034  0.490183  0.000209   \n",
       "9     1615058288       0.5000     0.952854     0.000057  0.479803  0.000601   \n",
       "10    1615058500       0.7500     0.950577     0.000113  0.474750  0.000602   \n",
       "11    1615058752       1.0000     0.947863     0.000075  0.465347  0.000440   \n",
       "5     1615057832       0.0300     0.947221     0.000032  0.483245  0.000320   \n",
       "4     1615057787       0.0100     0.934738     0.000050  0.410640  0.000408   \n",
       "12    1615059038       3.0000     0.934620     0.000118  0.410909  0.000559   \n",
       "13    1615059637      10.0000     0.916468     0.000104  0.353622  0.000542   \n",
       "3     1615057749       0.0030     0.887300     0.000321  0.242735  0.000394   \n",
       "2     1615057710       0.0010     0.764715     0.000778  0.090780  0.000709   \n",
       "1     1615057671       0.0003     0.550642     0.000024  0.018614  0.000084   \n",
       "0     1615057635       0.0001     0.500000     0.000000  0.011700  0.000000   \n",
       "\n",
       "    ratio_roc_auc     ratio_prec  running_time  \n",
       "7    4.637836e+04    1855.338737          2.40  \n",
       "6    2.249887e+04    2477.968175          1.50  \n",
       "8    2.766967e+04    2341.526233          2.70  \n",
       "9    1.669246e+04     797.649401          3.53  \n",
       "10   8.435548e+03     788.312979          4.20  \n",
       "11   1.261775e+04    1056.523430          4.75  \n",
       "5    2.996569e+04    1511.267070          0.95  \n",
       "4    1.865915e+04    1006.517687          0.73  \n",
       "12   7.929845e+03     734.441767          9.97  \n",
       "13   8.781780e+03     652.266124         24.58  \n",
       "3    2.762006e+03     615.799251          0.63  \n",
       "2    9.826728e+02     128.030234          0.63  \n",
       "1    2.269218e+04     221.944196          0.63  \n",
       "0    5.000000e+06  117000.955110          0.60  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "regul_params = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for e in [model_assessment_LR[e] for e in model_assessment_LR.keys() if\n",
    "          ('Defining regularization parameter.' in model_assessment_LR[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment_LR.keys())[list(model_assessment_LR.values()).index(e)])\n",
    "    regul_params.append(e['hyper_parameters']['regul_param'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/(e['performance_metrics']['std_roc_auc'] + 1e-7))\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/(e['performance_metrics']['std_avg_prec_score'] + 1e-7))\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by mini-batch size:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'regul_param': regul_params,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr_estimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values\n",
    "\n",
    "X_test = df_test_scaled.drop(drop_vars, axis=1).values\n",
    "y_test = df_test_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Best value for regularization parameter:\n",
    "regul_param = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 25.68 minutes.\n",
      "Start time: 2021-03-06, 17:15:29\n",
      "End time: 2021-03-06, 17:41:10\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "start_time_estimation = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "test_roc_auc = []\n",
    "test_avg_prec_score = []\n",
    "test_brier_score = []\n",
    "\n",
    "for t in range(n_estimations):\n",
    "    # Creating the model object:\n",
    "    model = LogisticRegression(solver='liblinear', penalty = 'l1', C = regul_param,\n",
    "                               warm_start=True)\n",
    "\n",
    "    # Training the model:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    test_roc_auc.append(roc_auc_score(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "    test_avg_prec_score.append(average_precision_score(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "    test_brier_score.append(brier_score_loss(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "\n",
    "end_time_estimation = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment_LR[estimation_id] = {\n",
    "    'hyper_parameters': {\n",
    "        'regul_param': regul_param\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'test',\n",
    "        'avg_roc_auc': np.nanmean(test_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(test_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(test_brier_score),\n",
    "        'std_roc_auc': np.nanstd(test_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(test_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(test_brier_score),\n",
    "    },\n",
    "    'running_time': str(round(((end_time_estimation - start_time_estimation).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": 'Final estimation.'\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment_LR.json', 'w') as json_file:\n",
    "        json.dump(model_assessment_LR, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Grid of values for the hyper-parameters:\n",
    "grid_param = []\n",
    "dict_param = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'kernel': ['poly'],\n",
    "    'degree': [1, 2, 3, 4],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "list_param = [dict_param[k] for k in dict_param.keys()]\n",
    "list_param = [list(x) for x in np.array(np.meshgrid(*list_param)).T.reshape(-1,len(list_param))]\n",
    "\n",
    "for i in list_param:\n",
    "    grid_param.append(dict(zip(dict_param.keys(), i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 337.5 minutes.\n",
      "Start time: 2021-03-09, 23:10:52\n",
      "End time: 2021-03-10, 04:48:23\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_bar = progressbar.ProgressBar(maxval=len(grid_param),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(len(grid_param)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "    \n",
    "    start_time_estimation = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "    \n",
    "    for t in range(n_estimations):\n",
    "        # Creating the model object:\n",
    "        model = SVC(C = float(grid_param[j]['C']),\n",
    "                    kernel = grid_param[j]['kernel'],\n",
    "                    degree = int(grid_param[j]['degree']),\n",
    "                    gamma = grid_param[j]['gamma'],\n",
    "                    probability = True, coef0 = 0.0, shrinking = True, tol = 0.001, max_iter = -1,\n",
    "                    cache_size = 200, class_weight = None, decision_function_shape = 'ovr',\n",
    "                    verbose = False, random_state = None)\n",
    "\n",
    "        # Training the model:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "\n",
    "    end_time_estimation = datetime.now()\n",
    "        \n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment_SVM[estimation_id] = {\n",
    "        'hyper_parameters': {\n",
    "            'C': grid_param[j]['C'],\n",
    "            'kernel': grid_param[j]['kernel'],\n",
    "            'degree': int(grid_param[j]['degree']),\n",
    "            'gamma': grid_param[j]['gamma']\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((end_time_estimation - start_time_estimation).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": 'Defining hyper-parameters.'\n",
    "    }\n",
    "\n",
    "    if export:\n",
    "        with open('Datasets/model_assessment_SVM.json', 'w') as json_file:\n",
    "            json.dump(model_assessment_SVM, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(j+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>C</th>\n",
       "      <th>kernel</th>\n",
       "      <th>degree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1615345366</td>\n",
       "      <td>10.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.949295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.492951e+06</td>\n",
       "      <td>4.908122e+06</td>\n",
       "      <td>10.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1615344669</td>\n",
       "      <td>1.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.940714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.407142e+06</td>\n",
       "      <td>4.624481e+06</td>\n",
       "      <td>11.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1615348625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.929405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.294052e+06</td>\n",
       "      <td>3.997050e+06</td>\n",
       "      <td>14.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1615349516</td>\n",
       "      <td>10.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.928807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.288068e+06</td>\n",
       "      <td>4.355247e+06</td>\n",
       "      <td>15.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1615354482</td>\n",
       "      <td>10.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.917996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179965e+06</td>\n",
       "      <td>4.007696e+06</td>\n",
       "      <td>20.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1615343896</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.915404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.342095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.154044e+06</td>\n",
       "      <td>3.420952e+06</td>\n",
       "      <td>12.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1615353349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.914734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.147338e+06</td>\n",
       "      <td>3.385124e+06</td>\n",
       "      <td>18.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1615347748</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.912896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.128958e+06</td>\n",
       "      <td>3.231240e+06</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1615343069</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.899856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.998559e+06</td>\n",
       "      <td>3.086969e+06</td>\n",
       "      <td>13.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1615342252</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.898669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.986690e+06</td>\n",
       "      <td>3.080385e+06</td>\n",
       "      <td>13.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1615352310</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.896876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.968764e+06</td>\n",
       "      <td>2.749122e+06</td>\n",
       "      <td>17.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1615360694</td>\n",
       "      <td>10.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.894933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.949333e+06</td>\n",
       "      <td>3.556504e+06</td>\n",
       "      <td>30.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1615359133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>poly</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.891987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.919869e+06</td>\n",
       "      <td>2.907620e+06</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1615346869</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.846151e+06</td>\n",
       "      <td>2.658544e+06</td>\n",
       "      <td>14.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1615351353</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.876153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.761535e+06</td>\n",
       "      <td>2.451216e+06</td>\n",
       "      <td>15.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1615357908</td>\n",
       "      <td>0.1</td>\n",
       "      <td>poly</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.875679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.246121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.756793e+06</td>\n",
       "      <td>2.461214e+06</td>\n",
       "      <td>20.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1615356788</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.858764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.587645e+06</td>\n",
       "      <td>2.187315e+06</td>\n",
       "      <td>18.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1615345976</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>2</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.856475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.564750e+06</td>\n",
       "      <td>2.388836e+06</td>\n",
       "      <td>14.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1615355742</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.842012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.420115e+06</td>\n",
       "      <td>2.082218e+06</td>\n",
       "      <td>17.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1615350431</td>\n",
       "      <td>0.001</td>\n",
       "      <td>poly</td>\n",
       "      <td>3</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.841128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.411277e+06</td>\n",
       "      <td>2.168593e+06</td>\n",
       "      <td>15.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id      C kernel  degree  gamma  avg_roc_auc  std_roc_auc  \\\n",
       "4     1615345366   10.0   poly       1  scale     0.949295          0.0   \n",
       "3     1615344669    1.0   poly       1  scale     0.940714          0.0   \n",
       "8     1615348625    1.0   poly       2  scale     0.929405          0.0   \n",
       "9     1615349516   10.0   poly       2  scale     0.928807          0.0   \n",
       "14    1615354482   10.0   poly       3  scale     0.917996          0.0   \n",
       "2     1615343896    0.1   poly       1  scale     0.915404          0.0   \n",
       "13    1615353349    1.0   poly       3  scale     0.914734          0.0   \n",
       "7     1615347748    0.1   poly       2  scale     0.912896          0.0   \n",
       "1     1615343069   0.01   poly       1  scale     0.899856          0.0   \n",
       "0     1615342252  0.001   poly       1  scale     0.898669          0.0   \n",
       "12    1615352310    0.1   poly       3  scale     0.896876          0.0   \n",
       "19    1615360694   10.0   poly       4  scale     0.894933          0.0   \n",
       "18    1615359133    1.0   poly       4  scale     0.891987          0.0   \n",
       "6     1615346869   0.01   poly       2  scale     0.884615          0.0   \n",
       "11    1615351353   0.01   poly       3  scale     0.876153          0.0   \n",
       "17    1615357908    0.1   poly       4  scale     0.875679          0.0   \n",
       "16    1615356788   0.01   poly       4  scale     0.858764          0.0   \n",
       "5     1615345976  0.001   poly       2  scale     0.856475          0.0   \n",
       "15    1615355742  0.001   poly       4  scale     0.842012          0.0   \n",
       "10    1615350431  0.001   poly       3  scale     0.841128          0.0   \n",
       "\n",
       "    avg_prec  std_prec  ratio_roc_auc    ratio_prec  running_time  \n",
       "4   0.490812       0.0   9.492951e+06  4.908122e+06         10.15  \n",
       "3   0.462448       0.0   9.407142e+06  4.624481e+06         11.60  \n",
       "8   0.399705       0.0   9.294052e+06  3.997050e+06         14.85  \n",
       "9   0.435525       0.0   9.288068e+06  4.355247e+06         15.23  \n",
       "14  0.400770       0.0   9.179965e+06  4.007696e+06         20.98  \n",
       "2   0.342095       0.0   9.154044e+06  3.420952e+06         12.88  \n",
       "13  0.338512       0.0   9.147338e+06  3.385124e+06         18.87  \n",
       "7   0.323124       0.0   9.128958e+06  3.231240e+06         14.62  \n",
       "1   0.308697       0.0   8.998559e+06  3.086969e+06         13.77  \n",
       "0   0.308039       0.0   8.986690e+06  3.080385e+06         13.60  \n",
       "12  0.274912       0.0   8.968764e+06  2.749122e+06         17.32  \n",
       "19  0.355650       0.0   8.949333e+06  3.556504e+06         30.13  \n",
       "18  0.290762       0.0   8.919869e+06  2.907620e+06         26.00  \n",
       "6   0.265854       0.0   8.846151e+06  2.658544e+06         14.63  \n",
       "11  0.245122       0.0   8.761535e+06  2.451216e+06         15.93  \n",
       "17  0.246121       0.0   8.756793e+06  2.461214e+06         20.42  \n",
       "16  0.218732       0.0   8.587645e+06  2.187315e+06         18.65  \n",
       "5   0.238884       0.0   8.564750e+06  2.388836e+06         14.88  \n",
       "15  0.208222       0.0   8.420115e+06  2.082218e+06         17.43  \n",
       "10  0.216859       0.0   8.411277e+06  2.168593e+06         15.37  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "c_list = []\n",
    "kernels = []\n",
    "degrees = []\n",
    "gammas = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for e in [model_assessment_SVM[e] for e in model_assessment_SVM.keys() if\n",
    "          ('Defining hyper-parameters.' in model_assessment_SVM[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment_SVM.keys())[list(model_assessment_SVM.values()).index(e)])\n",
    "    c_list.append(e['hyper_parameters']['C'])\n",
    "    kernels.append(e['hyper_parameters']['kernel'])\n",
    "    degrees.append(e['hyper_parameters']['degree'])\n",
    "    gammas.append(e['hyper_parameters']['gamma'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/(e['performance_metrics']['std_roc_auc'] + 1e-7))\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/(e['performance_metrics']['std_avg_prec_score'] + 1e-7))\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by mini-batch size:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'C': c_list,\n",
    "    'kernel': kernels,\n",
    "    'degree': degrees,\n",
    "    'gamma': gammas,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='svm_estimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values\n",
    "\n",
    "X_test = df_test_scaled.drop(drop_vars, axis=1).values\n",
    "y_test = df_test_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Best value for the hyper-parameters:\n",
    "grid_param = {\n",
    "    'C': 10,\n",
    "    'kernel': 'poly',\n",
    "    'degree': 1,\n",
    "    'gamma': 'scale'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 1008.53 minutes.\n",
      "Start time: 2021-03-10, 15:50:05\n",
      "End time: 2021-03-11, 08:38:38\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "start_time_estimation = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "test_roc_auc = []\n",
    "test_avg_prec_score = []\n",
    "test_brier_score = []\n",
    "\n",
    "for t in range(n_estimations):\n",
    "    # Creating the model object:\n",
    "    model = SVC(C = float(grid_param['C']),\n",
    "                kernel = grid_param['kernel'],\n",
    "                degree = int(grid_param['degree']),\n",
    "                gamma = grid_param['gamma'],\n",
    "                probability = True)\n",
    "\n",
    "    # Training the model:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    test_roc_auc.append(roc_auc_score(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "    test_avg_prec_score.append(average_precision_score(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "    test_brier_score.append(brier_score_loss(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "\n",
    "end_time_estimation = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment_SVM[estimation_id] = {\n",
    "    'hyper_parameters': {\n",
    "        'C': 10,\n",
    "        'kernel': 'poly',\n",
    "        'degree': 1,\n",
    "        'gamma': 'scale'\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'test',\n",
    "        'avg_roc_auc': np.nanmean(test_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(test_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(test_brier_score),\n",
    "        'std_roc_auc': np.nanstd(test_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(test_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(test_brier_score),\n",
    "    },\n",
    "    'running_time': str(round(((end_time_estimation - start_time_estimation).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": 'Final estimation.'\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment_SVM.json', 'w') as json_file:\n",
    "        json.dump(model_assessment_SVM, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gbm'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gbm_params'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 1\n",
    "\n",
    "# Grid of values for the hyper-parameters:\n",
    "grid_param = []\n",
    "dict_param = {\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'learning_rate': uniform(0.0001, 0.1),\n",
    "    'max_depth': randint(1, 5+1),\n",
    "    'n_estimators': randint(100, 1000+1)\n",
    "}\n",
    "\n",
    "for i in range(1, 15+1):\n",
    "    list_param = []\n",
    "\n",
    "    for k in dict_param.keys():\n",
    "        try:\n",
    "            list_param.append(dict_param[k].rvs(1)[0])\n",
    "        except:\n",
    "            list_param.append(np.random.choice(dict_param[k]))\n",
    "    grid_param.append(dict(zip(dict_param.keys(), list_param)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mTest progress:\u001b[0m [---------------------------------------------------------] 100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 155.17 minutes.\n",
      "Start time: 2021-03-12, 10:44:26\n",
      "End time: 2021-03-12, 13:19:37\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_bar = progressbar.ProgressBar(maxval=len(grid_param),\n",
    "                                   widgets=['\\033[1mTest progress:\\033[0m ',\n",
    "                                   progressbar.Bar('-', '[', ']'), ' ',\n",
    "                                   progressbar.Percentage()])\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for j in range(len(grid_param)):\n",
    "    estimation_id = str(int(time.time()))\n",
    "    \n",
    "    start_time_estimation = datetime.now()\n",
    "    \n",
    "    # Lists to store results:\n",
    "    val_roc_auc = []\n",
    "    val_avg_prec_score = []\n",
    "    val_brier_score = []\n",
    "    \n",
    "    for t in range(n_estimations):\n",
    "        # Creating the model object:\n",
    "        model = GradientBoostingClassifier(subsample = float(grid_param[j]['subsample']),\n",
    "                                           max_depth = int(grid_param[j]['max_depth']),\n",
    "                                           learning_rate = float(grid_param[j]['learning_rate']),\n",
    "                                           n_estimators = int(grid_param[j]['n_estimators']),\n",
    "                                           warm_start = True)\n",
    "\n",
    "        # Training the model:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Performance metrics on validation data:\n",
    "        val_roc_auc.append(roc_auc_score(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "        val_avg_prec_score.append(average_precision_score(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "        val_brier_score.append(brier_score_loss(y_val, [p[1] for p in model.predict_proba(X_val)]))\n",
    "\n",
    "    end_time_estimation = datetime.now()\n",
    "        \n",
    "    # Dictionary with information on model structure and performance:\n",
    "    model_assessment_GBM[estimation_id] = {\n",
    "        'hyper_parameters': {\n",
    "            'subsample': str(grid_param[j]['subsample']),\n",
    "            'max_depth': str(grid_param[j]['max_depth']),\n",
    "            'learning_rate': str(grid_param[j]['learning_rate']),\n",
    "            'n_estimators': str(grid_param[j]['n_estimators'])\n",
    "        },\n",
    "        'n_estimations': n_estimations,\n",
    "        'performance_metrics': {\n",
    "            'application': 'validation',\n",
    "            'avg_roc_auc': np.nanmean(val_roc_auc),\n",
    "            'avg_avg_prec_score': np.nanmean(val_avg_prec_score),\n",
    "            'avg_brier_score': np.nanmean(val_brier_score),\n",
    "            'std_roc_auc': np.nanstd(val_roc_auc),\n",
    "            'std_avg_prec_score': np.nanstd(val_avg_prec_score),\n",
    "            'std_brier_score': np.nanstd(val_brier_score)\n",
    "        },\n",
    "        'running_time': str(round(((end_time_estimation - start_time_estimation).seconds)/60, 2)) + ' minutes',\n",
    "        \"comment\": 'Defining hyper-parameters.'\n",
    "    }\n",
    "\n",
    "    if export:\n",
    "        with open('Datasets/model_assessment_GBM.json', 'w') as json_file:\n",
    "            json.dump(model_assessment_GBM, json_file, indent=2)\n",
    "    \n",
    "    test_bar.update(j+1)\n",
    "    sleep(0.01)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimation_id</th>\n",
       "      <th>subsample</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>avg_roc_auc</th>\n",
       "      <th>std_roc_auc</th>\n",
       "      <th>avg_prec</th>\n",
       "      <th>std_prec</th>\n",
       "      <th>ratio_roc_auc</th>\n",
       "      <th>ratio_prec</th>\n",
       "      <th>running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1615557195</td>\n",
       "      <td>0.7118400417035669</td>\n",
       "      <td>4</td>\n",
       "      <td>0.04679578634247878</td>\n",
       "      <td>884</td>\n",
       "      <td>0.949177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.491773e+06</td>\n",
       "      <td>4.521096e+06</td>\n",
       "      <td>30.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1615553321</td>\n",
       "      <td>0.6427877387298072</td>\n",
       "      <td>2</td>\n",
       "      <td>0.08584237614370978</td>\n",
       "      <td>562</td>\n",
       "      <td>0.947162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.471622e+06</td>\n",
       "      <td>4.751130e+06</td>\n",
       "      <td>9.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1615565252</td>\n",
       "      <td>0.9456088856900078</td>\n",
       "      <td>5</td>\n",
       "      <td>0.038361126043384555</td>\n",
       "      <td>248</td>\n",
       "      <td>0.946713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.467129e+06</td>\n",
       "      <td>4.447707e+06</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1615555108</td>\n",
       "      <td>0.8784779222684376</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0805863642157635</td>\n",
       "      <td>351</td>\n",
       "      <td>0.945808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.458079e+06</td>\n",
       "      <td>4.306749e+06</td>\n",
       "      <td>9.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1615560640</td>\n",
       "      <td>0.7855770369179904</td>\n",
       "      <td>4</td>\n",
       "      <td>0.06224100898924935</td>\n",
       "      <td>779</td>\n",
       "      <td>0.945650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.456505e+06</td>\n",
       "      <td>3.881479e+06</td>\n",
       "      <td>25.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1615559047</td>\n",
       "      <td>0.8243354273385988</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08135834905699557</td>\n",
       "      <td>464</td>\n",
       "      <td>0.945471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.454714e+06</td>\n",
       "      <td>4.581762e+06</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1615556968</td>\n",
       "      <td>0.9843951879119975</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03479861890483245</td>\n",
       "      <td>782</td>\n",
       "      <td>0.945458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.454578e+06</td>\n",
       "      <td>4.770387e+06</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1615553870</td>\n",
       "      <td>0.9331082174344221</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07758269430849254</td>\n",
       "      <td>499</td>\n",
       "      <td>0.945003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.450030e+06</td>\n",
       "      <td>4.196772e+06</td>\n",
       "      <td>15.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1615563747</td>\n",
       "      <td>0.5803623178080404</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06391181917384191</td>\n",
       "      <td>343</td>\n",
       "      <td>0.944974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.449740e+06</td>\n",
       "      <td>4.732111e+06</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1615556666</td>\n",
       "      <td>0.5638141361469999</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06946536769903416</td>\n",
       "      <td>308</td>\n",
       "      <td>0.944828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.448282e+06</td>\n",
       "      <td>4.561436e+06</td>\n",
       "      <td>5.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1615551936</td>\n",
       "      <td>0.9598030901135345</td>\n",
       "      <td>5</td>\n",
       "      <td>0.09422746014371519</td>\n",
       "      <td>523</td>\n",
       "      <td>0.944514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.445141e+06</td>\n",
       "      <td>3.866423e+06</td>\n",
       "      <td>23.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1615564073</td>\n",
       "      <td>0.8238057852390793</td>\n",
       "      <td>3</td>\n",
       "      <td>0.09175757852856524</td>\n",
       "      <td>569</td>\n",
       "      <td>0.943022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.381280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.430222e+06</td>\n",
       "      <td>3.812800e+06</td>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1615554827</td>\n",
       "      <td>0.5124606686955917</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06157220704773959</td>\n",
       "      <td>163</td>\n",
       "      <td>0.941203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.412026e+06</td>\n",
       "      <td>4.412838e+06</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1615562183</td>\n",
       "      <td>0.564935835303451</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055321526018248884</td>\n",
       "      <td>124</td>\n",
       "      <td>0.940699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.406991e+06</td>\n",
       "      <td>4.259636e+06</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1615564775</td>\n",
       "      <td>0.5244708846524835</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08690297576499696</td>\n",
       "      <td>423</td>\n",
       "      <td>0.938005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.380045e+06</td>\n",
       "      <td>3.698449e+06</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1615562390</td>\n",
       "      <td>0.7675979851138063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013202692164942886</td>\n",
       "      <td>867</td>\n",
       "      <td>0.936763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.367627e+06</td>\n",
       "      <td>4.217376e+06</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1615564995</td>\n",
       "      <td>0.6771139033502985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04972154405699894</td>\n",
       "      <td>144</td>\n",
       "      <td>0.931397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.313971e+06</td>\n",
       "      <td>3.717999e+06</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1615562711</td>\n",
       "      <td>0.53509441732124</td>\n",
       "      <td>3</td>\n",
       "      <td>0.09899364476127188</td>\n",
       "      <td>745</td>\n",
       "      <td>0.930768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.307678e+06</td>\n",
       "      <td>3.572960e+06</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1615559695</td>\n",
       "      <td>0.7475108703503186</td>\n",
       "      <td>5</td>\n",
       "      <td>0.09830069047690719</td>\n",
       "      <td>373</td>\n",
       "      <td>0.929567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.295669e+06</td>\n",
       "      <td>3.203030e+06</td>\n",
       "      <td>15.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1615565064</td>\n",
       "      <td>0.725339871557563</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012866437337883873</td>\n",
       "      <td>209</td>\n",
       "      <td>0.923794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.237943e+06</td>\n",
       "      <td>3.763986e+06</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimation_id           subsample max_depth         learning_rate  \\\n",
       "7     1615557195  0.7118400417035669         4   0.04679578634247878   \n",
       "1     1615553321  0.6427877387298072         2   0.08584237614370978   \n",
       "19    1615565252  0.9456088856900078         5  0.038361126043384555   \n",
       "4     1615555108  0.8784779222684376         4    0.0805863642157635   \n",
       "10    1615560640  0.7855770369179904         4   0.06224100898924935   \n",
       "8     1615559047  0.8243354273385988         3   0.08135834905699557   \n",
       "6     1615556968  0.9843951879119975         1   0.03479861890483245   \n",
       "2     1615553870  0.9331082174344221         4   0.07758269430849254   \n",
       "14    1615563747  0.5803623178080404         2   0.06391181917384191   \n",
       "5     1615556666  0.5638141361469999         2   0.06946536769903416   \n",
       "0     1615551936  0.9598030901135345         5   0.09422746014371519   \n",
       "15    1615564073  0.8238057852390793         3   0.09175757852856524   \n",
       "3     1615554827  0.5124606686955917         3   0.06157220704773959   \n",
       "11    1615562183   0.564935835303451         3  0.055321526018248884   \n",
       "16    1615564775  0.5244708846524835         1   0.08690297576499696   \n",
       "12    1615562390  0.7675979851138063         1  0.013202692164942886   \n",
       "17    1615564995  0.6771139033502985         1   0.04972154405699894   \n",
       "13    1615562711    0.53509441732124         3   0.09899364476127188   \n",
       "9     1615559695  0.7475108703503186         5   0.09830069047690719   \n",
       "18    1615565064   0.725339871557563         2  0.012866437337883873   \n",
       "\n",
       "   n_estimators  avg_roc_auc  std_roc_auc  avg_prec  std_prec  ratio_roc_auc  \\\n",
       "7           884     0.949177          0.0  0.452110       0.0   9.491773e+06   \n",
       "1           562     0.947162          0.0  0.475113       0.0   9.471622e+06   \n",
       "19          248     0.946713          0.0  0.444771       0.0   9.467129e+06   \n",
       "4           351     0.945808          0.0  0.430675       0.0   9.458079e+06   \n",
       "10          779     0.945650          0.0  0.388148       0.0   9.456505e+06   \n",
       "8           464     0.945471          0.0  0.458176       0.0   9.454714e+06   \n",
       "6           782     0.945458          0.0  0.477039       0.0   9.454578e+06   \n",
       "2           499     0.945003          0.0  0.419677       0.0   9.450030e+06   \n",
       "14          343     0.944974          0.0  0.473211       0.0   9.449740e+06   \n",
       "5           308     0.944828          0.0  0.456144       0.0   9.448282e+06   \n",
       "0           523     0.944514          0.0  0.386642       0.0   9.445141e+06   \n",
       "15          569     0.943022          0.0  0.381280       0.0   9.430222e+06   \n",
       "3           163     0.941203          0.0  0.441284       0.0   9.412026e+06   \n",
       "11          124     0.940699          0.0  0.425964       0.0   9.406991e+06   \n",
       "16          423     0.938005          0.0  0.369845       0.0   9.380045e+06   \n",
       "12          867     0.936763          0.0  0.421738       0.0   9.367627e+06   \n",
       "17          144     0.931397          0.0  0.371800       0.0   9.313971e+06   \n",
       "13          745     0.930768          0.0  0.357296       0.0   9.307678e+06   \n",
       "9           373     0.929567          0.0  0.320303       0.0   9.295669e+06   \n",
       "18          209     0.923794          0.0  0.376399       0.0   9.237943e+06   \n",
       "\n",
       "      ratio_prec  running_time  \n",
       "7   4.521096e+06         30.85  \n",
       "1   4.751130e+06          9.13  \n",
       "19  4.447707e+06         12.07  \n",
       "4   4.306749e+06          9.98  \n",
       "10  3.881479e+06         25.72  \n",
       "8   4.581762e+06         10.80  \n",
       "6   4.770387e+06          3.78  \n",
       "2   4.196772e+06         15.95  \n",
       "14  4.732111e+06          5.42  \n",
       "5   4.561436e+06          5.02  \n",
       "0   3.866423e+06         23.08  \n",
       "15  3.812800e+06         11.68  \n",
       "3   4.412838e+06          4.67  \n",
       "11  4.259636e+06          3.45  \n",
       "16  3.698449e+06          3.67  \n",
       "12  4.217376e+06          5.33  \n",
       "17  3.717999e+06          1.15  \n",
       "13  3.572960e+06         17.27  \n",
       "9   3.203030e+06         15.73  \n",
       "18  3.763986e+06          3.12  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimation_ids = []\n",
    "eta_list = []\n",
    "J_list = []\n",
    "v_list = []\n",
    "M_list = []\n",
    "avg_roc_auc = []\n",
    "std_roc_auc = []\n",
    "avg_prec = []\n",
    "std_prec = []\n",
    "ratio_roc_auc = []\n",
    "ratio_prec = []\n",
    "running_time = []\n",
    "\n",
    "# Loop over estimations:\n",
    "for e in [model_assessment_GBM[e] for e in model_assessment_GBM.keys() if\n",
    "          ('Defining hyper-parameters.' in model_assessment_GBM[e]['comment'])]:\n",
    "    estimation_ids.append(list(model_assessment_GBM.keys())[list(model_assessment_GBM.values()).index(e)])\n",
    "    eta_list.append(e['hyper_parameters']['subsample'])\n",
    "    J_list.append(e['hyper_parameters']['max_depth'])\n",
    "    v_list.append(e['hyper_parameters']['learning_rate'])\n",
    "    M_list.append(e['hyper_parameters']['n_estimators'])\n",
    "    avg_roc_auc.append(e['performance_metrics']['avg_roc_auc'])\n",
    "    std_roc_auc.append(e['performance_metrics']['std_roc_auc'])\n",
    "    avg_prec.append(e['performance_metrics']['avg_avg_prec_score'])\n",
    "    std_prec.append(e['performance_metrics']['std_avg_prec_score'])\n",
    "    ratio_roc_auc.append(e['performance_metrics']['avg_roc_auc']/(e['performance_metrics']['std_roc_auc'] + 1e-7))\n",
    "    ratio_prec.append(e['performance_metrics']['avg_avg_prec_score']/(e['performance_metrics']['std_avg_prec_score'] + 1e-7))\n",
    "    running_time.append(float(e['running_time'].split(' minutes')[0]))\n",
    "    \n",
    "# Dataframe with performance metrics by mini-batch size:\n",
    "metrics = pd.DataFrame(data={\n",
    "    'estimation_id': estimation_ids,\n",
    "    'subsample': eta_list,\n",
    "    'max_depth': J_list,\n",
    "    'learning_rate': v_list,\n",
    "    'n_estimators': M_list,\n",
    "    'avg_roc_auc': avg_roc_auc,\n",
    "    'std_roc_auc': std_roc_auc,\n",
    "    'avg_prec': avg_prec,\n",
    "    'std_prec': std_prec,\n",
    "    'ratio_roc_auc': ratio_roc_auc,\n",
    "    'ratio_prec': ratio_prec,\n",
    "    'running_time': running_time\n",
    "})\n",
    "\n",
    "metrics.sort_values('avg_roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gbm_estimation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data from dataframes into nd-arrays:\n",
    "X_train = df_train_scaled.drop(drop_vars, axis=1).values\n",
    "y_train = df_train_scaled['y'].values\n",
    "\n",
    "X_val = df_val_scaled.drop(drop_vars, axis=1).values\n",
    "y_val = df_val_scaled['y'].values\n",
    "\n",
    "X_test = df_test_scaled.drop(drop_vars, axis=1).values\n",
    "y_test = df_test_scaled['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of estimations:\n",
    "n_estimations = 100\n",
    "\n",
    "# Best value for the hyper-parameters:\n",
    "grid_param = {\n",
    "    'subsample': 0.6427877387298072,\n",
    "    'max_depth': 2,\n",
    "    'learning_rate': 0.08584237614370978,\n",
    "    'n_estimators': 562\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "\u001b[1mOverall running time:\u001b[0m 771.3 minutes.\n",
      "Start time: 2021-03-12, 17:16:24\n",
      "End time: 2021-03-13, 06:07:42\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "estimation_id = str(int(time.time()))\n",
    "\n",
    "start_time_estimation = datetime.now()\n",
    "\n",
    "# Lists to store results:\n",
    "test_roc_auc = []\n",
    "test_avg_prec_score = []\n",
    "test_brier_score = []\n",
    "\n",
    "for t in range(n_estimations):\n",
    "    # Creating the model object:\n",
    "    model = GradientBoostingClassifier(subsample = float(grid_param['subsample']),\n",
    "                                       max_depth = int(grid_param['max_depth']),\n",
    "                                       learning_rate = float(grid_param['learning_rate']),\n",
    "                                       n_estimators = int(grid_param['n_estimators']),\n",
    "                                       warm_start = True)\n",
    "\n",
    "    # Training the model:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Performance metrics on validation data:\n",
    "    test_roc_auc.append(roc_auc_score(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "    test_avg_prec_score.append(average_precision_score(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "    test_brier_score.append(brier_score_loss(y_test, [p[1] for p in model.predict_proba(X_test)]))\n",
    "\n",
    "end_time_estimation = datetime.now()\n",
    "\n",
    "# Dictionary with information on model structure and performance:\n",
    "model_assessment_GBM[estimation_id] = {\n",
    "    'hyper_parameters': {\n",
    "        'subsample': str(grid_param['subsample']),\n",
    "        'max_depth': str(grid_param['max_depth']),\n",
    "        'learning_rate': str(grid_param['learning_rate']),\n",
    "        'n_estimators': str(grid_param['n_estimators'])\n",
    "    },\n",
    "    'n_estimations': n_estimations,\n",
    "    'performance_metrics': {\n",
    "        'application': 'test',\n",
    "        'avg_roc_auc': np.nanmean(test_roc_auc),\n",
    "        'avg_avg_prec_score': np.nanmean(test_avg_prec_score),\n",
    "        'avg_brier_score': np.nanmean(test_brier_score),\n",
    "        'std_roc_auc': np.nanstd(test_roc_auc),\n",
    "        'std_avg_prec_score': np.nanstd(test_avg_prec_score),\n",
    "        'std_brier_score': np.nanstd(test_brier_score),\n",
    "    },\n",
    "    'running_time': str(round(((end_time_estimation - start_time_estimation).seconds)/60, 2)) + ' minutes',\n",
    "    \"comment\": 'Final estimation.'\n",
    "}\n",
    "\n",
    "if export:\n",
    "    with open('Datasets/model_assessment_GBM.json', 'w') as json_file:\n",
    "        json.dump(model_assessment_GBM, json_file, indent=2)\n",
    "\n",
    "# Assessing running time:\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('------------------------------------')\n",
    "print('\\033[1mOverall running time:\\033[0m ' + str(round(((end_time - start_time).seconds)/60, 2)) +\n",
    "      ' minutes.')\n",
    "print('Start time: ' + start_time.strftime('%Y-%m-%d') + ', ' + start_time.strftime('%H:%M:%S'))\n",
    "print('End time: ' + end_time.strftime('%Y-%m-%d') + ', ' + end_time.strftime('%H:%M:%S'))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
